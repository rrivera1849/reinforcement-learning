{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gym\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "if \"../\" not in sys.path:\n",
    "  sys.path.append(\"../\")\n",
    "\n",
    "from lib import plotting\n",
    "from collections import deque, namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-17 11:47:50,506] Making new env: Breakout-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.envs.make(\"Breakout-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Atari Actions: 0 (noop), 1 (fire), 2 (left) and 3 (right) are valid actions\n",
    "VALID_ACTIONS = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StateProcessor():\n",
    "    \"\"\"\n",
    "    Processes a raw Atari iamges. Resizes it and converts it to grayscale.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Build the TF Graph for the StateProcessor.\n",
    "           input_state[210x160x3] -> output[84x84x1]\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"state_processor\"):\n",
    "            self.input_state = tf.placeholder(shape=[210, 160, 3], dtype=tf.uint8)\n",
    "            self.output = tf.image.rgb_to_grayscale(self.input_state)\n",
    "            self.output = tf.image.crop_to_bounding_box(self.output, 34, 0, 160, 160)\n",
    "            self.output = tf.image.resize_images(\n",
    "                self.output, [84, 84], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "            self.output = tf.squeeze(self.output)\n",
    "\n",
    "    def process(self, sess, state):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sess: A Tensorflow session object\n",
    "            state: A [210, 160, 3] Atari RGB State\n",
    "\n",
    "        Returns:\n",
    "            A processed [84, 84, 1] state representing grayscale values.\n",
    "        \"\"\"\n",
    "        return sess.run(self.output, { self.input_state: state })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Estimator():\n",
    "    \"\"\"Q-Value Estimator neural network.\n",
    "\n",
    "    This network is used for both the Q-Network and the Target Network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scope=\"estimator\", summaries_dir=None):\n",
    "        \"\"\"Builds the TF Graph and sets up summaries in order to monitor\n",
    "           our progress. \n",
    "           \n",
    "        Keyword Arguments:\n",
    "            scope: TF Scope name for the estimator graph\n",
    "            summaries_dir: where to store TF summaries\n",
    "        \"\"\"\n",
    "        self.scope = scope\n",
    "        # Writes Tensorboard summaries to disk\n",
    "        self.summary_writer = None\n",
    "        with tf.variable_scope(scope):\n",
    "            # Build the graph\n",
    "            self._build_model()\n",
    "            \n",
    "            # If we passed a summary dir then attempt to create it\n",
    "            # if it doesn't exist and create a new summary_writer\n",
    "            if summaries_dir:\n",
    "                summary_dir = os.path.join(summaries_dir, \"summaries_{}\".format(scope))\n",
    "                if not os.path.exists(summary_dir):\n",
    "                    os.makedirs(summary_dir)\n",
    "                self.summary_writer = tf.summary.FileWriter(summary_dir)\n",
    "\n",
    "    def _build_model(self):\n",
    "        \"\"\"\n",
    "        Builds the Tensorflow graph.\n",
    "        \"\"\"\n",
    "\n",
    "        # Placeholders for our input\n",
    "        # Our input are 4 RGB frames of shape 160, 160 each\n",
    "        # Four RGB frames are needed in order to get an estimate of the direction\n",
    "        # that the ball is heading to as well.\n",
    "        self.X_pl = tf.placeholder(shape=[None, 84, 84, 4], dtype=tf.uint8, name=\"X\")\n",
    "        # The TD target value\n",
    "        self.y_pl = tf.placeholder(shape=[None], dtype=tf.float32, name=\"y\")\n",
    "        # Integer id of which action was selected\n",
    "        self.actions_pl = tf.placeholder(shape=[None], dtype=tf.int32, name=\"actions\")\n",
    "\n",
    "        X = tf.to_float(self.X_pl) / 255.0\n",
    "        batch_size = tf.shape(self.X_pl)[0]\n",
    "\n",
    "        # Three convolutional layers\n",
    "        # Arguments to tf.contrib.layers.conv2d: (X, output_filters, kernel_size, stride)\n",
    "        # Conv[8x8/4][32] -> Conv[4x4/2][64] -> Conv[3x3/1][64] \n",
    "        conv1 = tf.contrib.layers.conv2d(\n",
    "            X, 32, 8, 4, activation_fn=tf.nn.relu)\n",
    "        conv2 = tf.contrib.layers.conv2d(\n",
    "            conv1, 64, 4, 2, activation_fn=tf.nn.relu)\n",
    "        conv3 = tf.contrib.layers.conv2d(\n",
    "            conv2, 64, 3, 1, activation_fn=tf.nn.relu)\n",
    "\n",
    "        # Fully connected layers\n",
    "        # Flatten our convolutions to [batch_size, k]\n",
    "        flattened = tf.contrib.layers.flatten(conv3)\n",
    "        # FC1[k,512]\n",
    "        fc1 = tf.contrib.layers.fully_connected(flattened, 512)\n",
    "        # Predictions[512,VALID_ACTIONS]\n",
    "        self.predictions = tf.contrib.layers.fully_connected(fc1, len(VALID_ACTIONS))\n",
    "\n",
    "        # Now here comes the tricky part, when calculating the loss we must\n",
    "        # take into account what actions were taken. Intuitively, the TD target\n",
    "        # is just a number so our target should be a number as well.\n",
    "        \n",
    "        # Get the predictions for the chosen actions only\n",
    "        # gather_indices: contains the indices of the FLATTENED predictions array\n",
    "        #                 for the actions we took\n",
    "        gather_indices = tf.range(batch_size) * tf.shape(self.predictions)[1] + self.actions_pl\n",
    "        \n",
    "        # Now we just flatten our predictions array and gather all the values\n",
    "        # using TF.gather.\n",
    "        self.action_predictions = tf.gather(tf.reshape(self.predictions, [-1]), gather_indices)\n",
    "\n",
    "        # Calcualte the loss\n",
    "        self.losses = tf.squared_difference(self.y_pl, self.action_predictions)\n",
    "        self.loss = tf.reduce_mean(self.losses)\n",
    "\n",
    "        # Optimizer Parameters from original paper\n",
    "        # Parameters: (LR, decay, momentum, epsilon)\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(0.00025, 0.99, 0.0, 1e-6)\n",
    "        self.train_op = self.optimizer.minimize(self.loss, global_step=tf.contrib.framework.get_global_step())\n",
    "\n",
    "        # Summaries for Tensorboard\n",
    "        self.summaries = tf.summary.merge([\n",
    "            tf.summary.scalar(\"loss\", self.loss),\n",
    "            tf.summary.histogram(\"loss_hist\", self.losses),\n",
    "            tf.summary.histogram(\"q_values_hist\", self.predictions),\n",
    "            tf.summary.scalar(\"max_q_value\", tf.reduce_max(self.predictions))\n",
    "        ])\n",
    "\n",
    "\n",
    "    def predict(self, sess, s):\n",
    "        \"\"\"\n",
    "        Predicts action values.\n",
    "\n",
    "        Args:\n",
    "          sess: Tensorflow session\n",
    "          s: State input of shape [batch_size, 4, 160, 160, 3]\n",
    "\n",
    "        Returns:\n",
    "          Tensor of shape [batch_size, NUM_VALID_ACTIONS] containing the estimated \n",
    "          action values.\n",
    "        \"\"\"\n",
    "        return sess.run(self.predictions, { self.X_pl: s })\n",
    "\n",
    "    def update(self, sess, s, a, y):\n",
    "        \"\"\"\n",
    "        Updates the estimator towards the given targets.\n",
    "\n",
    "        Args:\n",
    "          sess: Tensorflow session object\n",
    "          s: State input of shape [batch_size, 4, 160, 160, 3]\n",
    "          a: Chosen actions of shape [batch_size]\n",
    "          y: Targets of shape [batch_size]\n",
    "\n",
    "        Returns:\n",
    "          The calculated loss on the batch.\n",
    "        \"\"\"\n",
    "        feed_dict = { self.X_pl: s, self.y_pl: y, self.actions_pl: a }\n",
    "        summaries, global_step, _, loss = sess.run(\n",
    "            [self.summaries, tf.contrib.framework.get_global_step(), self.train_op, self.loss],\n",
    "            feed_dict)\n",
    "        if self.summary_writer:\n",
    "            self.summary_writer.add_summary(summaries, global_step)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riverasoto1/venv/3.6.1/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.02172653  0.04793787  0.        ]\n",
      " [ 0.          0.02172653  0.04793787  0.        ]]\n",
      "99.783\n"
     ]
    }
   ],
   "source": [
    "# For Testing....\n",
    "\n",
    "tf.reset_default_graph()\n",
    "global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "e = Estimator(scope=\"test\")\n",
    "sp = StateProcessor()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Example observation batch\n",
    "    observation = env.reset()\n",
    "    \n",
    "    observation_p = sp.process(sess, observation)\n",
    "    observation = np.stack([observation_p] * 4, axis=2)\n",
    "    observations = np.array([observation] * 2)\n",
    "    \n",
    "    # Test Prediction\n",
    "    print(e.predict(sess, observations))\n",
    "\n",
    "    # Test training step\n",
    "    y = np.array([10.0, 10.0])\n",
    "    a = np.array([1, 3])\n",
    "    print(e.update(sess, observations, a, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_model_parameters(sess, estimator1, estimator2):\n",
    "    \"\"\"\n",
    "    Copies the model parameters of one estimator to another.\n",
    "\n",
    "    Args:\n",
    "      sess: Tensorflow session instance\n",
    "      estimator1: Estimator to copy the paramters from\n",
    "      estimator2: Estimator to copy the parameters to\n",
    "    \"\"\"\n",
    "    e1_params = [t for t in tf.trainable_variables() if t.name.startswith(estimator1.scope)]\n",
    "    e1_params = sorted(e1_params, key=lambda v: v.name)\n",
    "    e2_params = [t for t in tf.trainable_variables() if t.name.startswith(estimator2.scope)]\n",
    "    e2_params = sorted(e2_params, key=lambda v: v.name)\n",
    "\n",
    "    update_ops = []\n",
    "    for e1_v, e2_v in zip(e1_params, e2_params):\n",
    "        # A very TF-like thing where we create operations\n",
    "        # before running them\n",
    "        op = e2_v.assign(e1_v)\n",
    "        update_ops.append(op)\n",
    "\n",
    "    # This is where the real work is being done\n",
    "    sess.run(update_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(estimator, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon.\n",
    "\n",
    "    Args:\n",
    "        estimator: An estimator that returns q values for a given state\n",
    "        nA: Number of actions in the environment.\n",
    "\n",
    "    Returns:\n",
    "        A function that takes the (sess, observation, epsilon) as an argument and returns\n",
    "        the probabilities for each action in the form of a numpy array of length nA.\n",
    "\n",
    "    \"\"\"\n",
    "    def policy_fn(sess, observation, epsilon):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        # Observation is [84,84,4] so we expand to be [1,84,84,4]\n",
    "        # that way in can run through the prediction\n",
    "        q_values = estimator.predict(sess, np.expand_dims(observation, 0))[0]\n",
    "        best_action = np.argmax(q_values)\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deep_q_learning(sess,\n",
    "                    env,\n",
    "                    q_estimator,\n",
    "                    target_estimator,\n",
    "                    state_processor,\n",
    "                    num_episodes,\n",
    "                    experiment_dir,\n",
    "                    replay_memory_size=500000,\n",
    "                    replay_memory_init_size=50000,\n",
    "                    update_target_estimator_every=10000,\n",
    "                    discount_factor=0.99,\n",
    "                    epsilon_start=1.0,\n",
    "                    epsilon_end=0.1,\n",
    "                    epsilon_decay_steps=500000,\n",
    "                    batch_size=32,\n",
    "                    record_video_every=50):\n",
    "    \"\"\"\n",
    "    Q-Learning algorithm for fff-policy TD control using Function Approximation.\n",
    "    Finds the optimal greedy policy while following an epsilon-greedy policy.\n",
    "\n",
    "    Args:\n",
    "        sess: Tensorflow Session object\n",
    "        env: OpenAI environment\n",
    "        q_estimator: Estimator object used for the q values\n",
    "        target_estimator: Estimator object used for the targets\n",
    "        state_processor: A StateProcessor object\n",
    "        num_episodes: Number of episodes to run for\n",
    "        experiment_dir: Directory to save Tensorflow summaries in\n",
    "        replay_memory_size: Size of the replay memory\n",
    "        replay_memory_init_size: Number of random experiences to sample when initializing \n",
    "          the replay memory.\n",
    "        update_target_estimator_every: Copy parameters from the Q estimator to the \n",
    "          target estimator every N steps\n",
    "        discount_factor: Lambda time discount factor\n",
    "        epsilon_start: Chance to sample a random action when taking an action.\n",
    "          Epsilon is decayed over time and this is the start value\n",
    "        epsilon_end: The final minimum value of epsilon after decaying is done\n",
    "        epsilon_decay_steps: Number of steps to decay epsilon over\n",
    "        batch_size: Size of batches to sample from the replay memory\n",
    "        record_video_every: Record a video every N episodes\n",
    "\n",
    "    Returns:\n",
    "        An EpisodeStats object with two numpy arrays for episode_lengths and episode_rewards.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Very cute pythonic way of naming some tuple lol\n",
    "    Transition = namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "\n",
    "    # The replay memory\n",
    "    replay_memory = []\n",
    "\n",
    "    # Keeps track of useful statistics\n",
    "    stats = plotting.EpisodeStats(\n",
    "        episode_lengths=np.zeros(num_episodes),\n",
    "        episode_rewards=np.zeros(num_episodes))\n",
    "\n",
    "    # Create directories for checkpoints and summaries\n",
    "    checkpoint_dir = os.path.join(experiment_dir, \"checkpoints\")\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, \"model\")\n",
    "    monitor_path = os.path.join(experiment_dir, \"monitor\")\n",
    "\n",
    "    # Create checkpoint directories and monitor directories\n",
    "    # if they don't exist\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    if not os.path.exists(monitor_path):\n",
    "        os.makedirs(monitor_path)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    # Load a previous checkpoint if we find one\n",
    "    # Automagically find checkpoint and load it\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if latest_checkpoint:\n",
    "        print(\"Loading model checkpoint {}...\\n\".format(latest_checkpoint))\n",
    "        saver.restore(sess, latest_checkpoint)\n",
    "    \n",
    "    # Get the current time step\n",
    "    total_t = sess.run(tf.contrib.framework.get_global_step())\n",
    "\n",
    "    # The epsilon decay schedule\n",
    "    # Create decay schedule using linspace which just gets us from start\n",
    "    # to end in a certain number of steps\n",
    "    epsilons = np.linspace(epsilon_start, epsilon_end, epsilon_decay_steps)\n",
    "\n",
    "    # The policy we're following\n",
    "    policy = make_epsilon_greedy_policy(\n",
    "        q_estimator,\n",
    "        len(VALID_ACTIONS))\n",
    "\n",
    "    # Populate the replay memory with initial experience\n",
    "    print(\"Populating replay memory...\")\n",
    "    state = env.reset()\n",
    "    state = state_processor.process(sess, state)\n",
    "    state = np.stack([state] * 4, axis=2)\n",
    "    for i in range(replay_memory_init_size):\n",
    "        # total_t: represents the total number of timesteps our network\n",
    "        #          has ben run\n",
    "        probs = policy(sess, state, epsilons[min(total_t, epsilon_decay_steps-1)])\n",
    "        action = np.random.choice(np.arange(len(probs)), p=probs)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Convert state to grayscale and do some numpy magic to\n",
    "        # append state as the last seen frame\n",
    "        next_state = state_processor.process(sess, next_state)\n",
    "        next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)\n",
    "\n",
    "        # Transitions are a namedtuple defined above\n",
    "        replay_memory.append(Transition(state, action, reward, next_state, done))\n",
    "        \n",
    "        if done:\n",
    "            # We are done so reset the environment and stack the same\n",
    "            # frame four times\n",
    "            state = env.reset()\n",
    "            state = state_processor.process(sess, state)\n",
    "            state = np.stack([state] * 4, axis=2)\n",
    "        else: \n",
    "            state = next_state\n",
    "\n",
    "    # Record videos\n",
    "    # env.monitor.start(monitor_path,\n",
    "                      # resume=True,\n",
    "                      # video_callable=lambda count: count % record_video_every == 0)\n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "\n",
    "        # Save the current checkpoint\n",
    "        saver.save(tf.get_default_session(), checkpoint_path)\n",
    "\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        state = state_processor.process(sess, state)\n",
    "        state = np.stack([state] * 4, axis=2)\n",
    "        loss = None\n",
    "\n",
    "        # One step in the environment\n",
    "        # itertools.count() here just makes sure we do t += 1\n",
    "        for t in itertools.count():\n",
    "            \"\"\"In this loop we simply go through our episode as normal with\n",
    "               a slight caveat. Meanwhile we're following our episode until\n",
    "               termination, we also sample a minibatch from our replay memory.\n",
    "               \n",
    "               We remove something from the replay memory if it is full and append\n",
    "               a new state. In this case, the state is the current one that we're on.\n",
    "            \"\"\"\n",
    "\n",
    "            # Epsilon for this time step\n",
    "            epsilon = epsilons[min(total_t, epsilon_decay_steps-1)]\n",
    "\n",
    "            # Some updates to our summaries\n",
    "            episode_summary = tf.Summary()\n",
    "            episode_summary.value.add(simple_value=epsilon, tag=\"epsilon\")\n",
    "            q_estimator.summary_writer.add_summary(episode_summary, total_t)\n",
    "\n",
    "            # TODO: Maybe update the target estimator\n",
    "            if total_t % update_target_estimator_every == 0:\n",
    "                # This is just as simple as updating the weights of our\n",
    "                # target estimator and done!\n",
    "                copy_model_parameters(sess, q_estimator, target_estimator)\n",
    "\n",
    "            # Print out which step we're on, useful for debugging.\n",
    "            print(\"\\rStep {} ({}) @ Episode {}/{}, loss: {}\".format(\n",
    "                    t, total_t, i_episode + 1, num_episodes, loss), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            # Take a step in the environment\n",
    "            probs = policy(sess, state, epsilon)\n",
    "            action = np.random.choice(np.arange(len(probs)), p=probs)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            # If our replay memory is full, pop the first element\n",
    "            if len(replay_memory) == replay_memory_size:\n",
    "                replay_memory.pop(0)\n",
    "\n",
    "            # TODO: Save transition to replay memory\n",
    "            next_state = state_processor.process(sess, next_state)\n",
    "            next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)\n",
    "            replay_memory.append(Transition(state, action, reward, next_state, done))\n",
    "\n",
    "            # Update statistics\n",
    "            stats.episode_rewards[i_episode] += reward\n",
    "            stats.episode_lengths[i_episode] = t\n",
    "\n",
    "            # TODO: Sample a minibatch from the replay memory\n",
    "            # RARS - Must sample the whole minibatch, random.sample works nicely for this\n",
    "            transitions = random.sample(replay_memory, batch_size)\n",
    "            # RARS - Map, applies np.array to the output of zip thus\n",
    "            #        now we have numpy arrays all accross\n",
    "            s_batch, a_batch, r_batch, ns_batch, d_batch = map(np.array, zip(*transitions))\n",
    "            \n",
    "            # TODO: Calculate q values and targets\n",
    "            q_target_values = target_estimator.predict(sess, ns_batch)\n",
    "            \n",
    "            target = r_batch + \\\n",
    "                    np.invert(done).astype(np.float32) * \\\n",
    "                    discount_factor * \\\n",
    "                    np.amax(q_target_values, axis=1)\n",
    "            \n",
    "            # TODO Perform gradient descent update\n",
    "            # RARS - Need to do this in order to convert from map\n",
    "            s_batch = np.array(s_batch)\n",
    "            loss = q_estimator.update(sess, s_batch, a_batch, target)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            state = next_state\n",
    "            total_t += 1\n",
    "\n",
    "        # Add summaries to tensorboard\n",
    "        episode_summary = tf.Summary()\n",
    "        episode_summary.value.add(simple_value=stats.episode_rewards[i_episode], node_name=\"episode_reward\", tag=\"episode_reward\")\n",
    "        episode_summary.value.add(simple_value=stats.episode_lengths[i_episode], node_name=\"episode_length\", tag=\"episode_length\")\n",
    "        q_estimator.summary_writer.add_summary(episode_summary, total_t)\n",
    "        q_estimator.summary_writer.flush()\n",
    "\n",
    "        yield total_t, plotting.EpisodeStats(\n",
    "            episode_lengths=stats.episode_lengths[:i_episode+1],\n",
    "            episode_rewards=stats.episode_rewards[:i_episode+1])\n",
    "\n",
    "    env.monitor.close()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riverasoto1/venv/3.6.1/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating replay memory...\n",
      "Step 205 (205) @ Episode 1/10000, loss: 0.00035014655441045763\n",
      "Episode Reward: 1.0\n",
      "Step 234 (439) @ Episode 2/10000, loss: 0.03314521163702011923\n",
      "Episode Reward: 1.0\n",
      "Step 371 (810) @ Episode 3/10000, loss: 0.00044526866986416285\n",
      "Episode Reward: 4.0\n",
      "Step 158 (968) @ Episode 4/10000, loss: 0.00038672258961014454\n",
      "Episode Reward: 0.0\n",
      "Step 256 (1224) @ Episode 5/10000, loss: 0.00033945223549380966\n",
      "Episode Reward: 1.0\n",
      "Step 346 (1570) @ Episode 6/10000, loss: 0.00049587246030569085\n",
      "Episode Reward: 3.0\n",
      "Step 206 (1776) @ Episode 7/10000, loss: 0.03152327984571457407\n",
      "Episode Reward: 1.0\n",
      "Step 272 (2048) @ Episode 8/10000, loss: 0.03009570948779583054\n",
      "Episode Reward: 2.0\n",
      "Step 226 (2274) @ Episode 9/10000, loss: 6.037607818143442e-055\n",
      "Episode Reward: 1.0\n",
      "Step 445 (2719) @ Episode 10/10000, loss: 4.8983056331053376e-05\n",
      "Episode Reward: 5.0\n",
      "Step 281 (3000) @ Episode 11/10000, loss: 2.314084667887073e-055\n",
      "Episode Reward: 2.0\n",
      "Step 209 (3209) @ Episode 12/10000, loss: 3.346690573380329e-055\n",
      "Episode Reward: 1.0\n",
      "Step 176 (3385) @ Episode 13/10000, loss: 5.075567969470285e-052\n",
      "Episode Reward: 0.0\n",
      "Step 175 (3560) @ Episode 14/10000, loss: 7.489668496418744e-052\n",
      "Episode Reward: 0.0\n",
      "Step 230 (3790) @ Episode 15/10000, loss: 0.03100958280265331305\n",
      "Episode Reward: 1.0\n",
      "Step 177 (3967) @ Episode 16/10000, loss: 1.392036210745573e-055\n",
      "Episode Reward: 0.0\n",
      "Step 268 (4235) @ Episode 17/10000, loss: 5.086217788630165e-056\n",
      "Episode Reward: 2.0\n",
      "Step 175 (4410) @ Episode 18/10000, loss: 7.05941638443619e-0551\n",
      "Episode Reward: 0.0\n",
      "Step 179 (4589) @ Episode 19/10000, loss: 9.504321496933699e-065\n",
      "Episode Reward: 0.0\n",
      "Step 435 (5024) @ Episode 20/10000, loss: 4.3528278183657676e-05\n",
      "Episode Reward: 4.0\n",
      "Step 169 (5193) @ Episode 21/10000, loss: 2.9525179343181662e-05\n",
      "Episode Reward: 0.0\n",
      "Step 293 (5486) @ Episode 22/10000, loss: 1.0743866369011812e-05\n",
      "Episode Reward: 2.0\n",
      "Step 226 (5712) @ Episode 23/10000, loss: 1.6089774362626486e-05\n",
      "Episode Reward: 1.0\n",
      "Step 317 (6029) @ Episode 24/10000, loss: 3.522627957863733e-055\n",
      "Episode Reward: 2.0\n",
      "Step 177 (6206) @ Episode 25/10000, loss: 6.683535320917144e-055\n",
      "Episode Reward: 0.0\n",
      "Step 170 (6376) @ Episode 26/10000, loss: 1.8861290300264955e-05\n",
      "Episode Reward: 0.0\n",
      "Step 218 (6594) @ Episode 27/10000, loss: 3.492655741865747e-055\n",
      "Episode Reward: 0.0\n",
      "Step 309 (6903) @ Episode 28/10000, loss: 4.588781303027645e-053\n",
      "Episode Reward: 2.0\n",
      "Step 167 (7070) @ Episode 29/10000, loss: 2.1870953787583858e-05\n",
      "Episode Reward: 0.0\n",
      "Step 242 (7312) @ Episode 30/10000, loss: 0.03066049702465534205\n",
      "Episode Reward: 1.0\n",
      "Step 349 (7661) @ Episode 31/10000, loss: 3.556935553206131e-055\n",
      "Episode Reward: 3.0\n",
      "Step 281 (7942) @ Episode 32/10000, loss: 0.00019094254821538925\n",
      "Episode Reward: 2.0\n",
      "Step 259 (8201) @ Episode 33/10000, loss: 4.1188221075572073e-05\n",
      "Episode Reward: 2.0\n",
      "Step 224 (8425) @ Episode 34/10000, loss: 1.3748416677117348e-05\n",
      "Episode Reward: 1.0\n",
      "Step 169 (8594) @ Episode 35/10000, loss: 0.03114205226302147-05\n",
      "Episode Reward: 0.0\n",
      "Step 307 (8901) @ Episode 36/10000, loss: 4.754525434691459e-055\n",
      "Episode Reward: 2.0\n",
      "Step 334 (9235) @ Episode 37/10000, loss: 0.03093321621417999305\n",
      "Episode Reward: 3.0\n",
      "Step 172 (9407) @ Episode 38/10000, loss: 0.03109198808670044205\n",
      "Episode Reward: 0.0\n",
      "Step 214 (9621) @ Episode 39/10000, loss: 0.03134575858712196405\n",
      "Episode Reward: 1.0\n",
      "Step 163 (9784) @ Episode 40/10000, loss: 6.001572182867676e-055\n",
      "Episode Reward: 0.0\n",
      "Step 181 (9965) @ Episode 41/10000, loss: 3.203298183507286e-055\n",
      "Episode Reward: 0.0\n",
      "Step 241 (10206) @ Episode 42/10000, loss: 1.6757745470386e-05-05\n",
      "Episode Reward: 1.0\n",
      "Step 231 (10437) @ Episode 43/10000, loss: 1.4937246305635199e-05\n",
      "Episode Reward: 1.0\n",
      "Step 284 (10721) @ Episode 44/10000, loss: 6.179374759085476e-055\n",
      "Episode Reward: 2.0\n",
      "Step 161 (10882) @ Episode 45/10000, loss: 0.00010611020843498409\n",
      "Episode Reward: 0.0\n",
      "Step 205 (11087) @ Episode 46/10000, loss: 3.477179416222498e-052\n",
      "Episode Reward: 1.0\n",
      "Step 179 (11266) @ Episode 47/10000, loss: 0.03098721429705619856\n",
      "Episode Reward: 0.0\n",
      "Step 385 (11651) @ Episode 48/10000, loss: 1.666775278863497e-055\n",
      "Episode Reward: 4.0\n",
      "Step 241 (11892) @ Episode 49/10000, loss: 2.2931635612621903e-05\n",
      "Episode Reward: 1.0\n",
      "Step 240 (12132) @ Episode 50/10000, loss: 3.4600474464241415e-05\n",
      "Episode Reward: 1.0\n",
      "Step 167 (12299) @ Episode 51/10000, loss: 0.03106078878045082-05\n",
      "Episode Reward: 0.0\n",
      "Step 283 (12582) @ Episode 52/10000, loss: 0.03092179447412491-05\n",
      "Episode Reward: 2.0\n",
      "Step 208 (12790) @ Episode 53/10000, loss: 3.169562842231244e-055\n",
      "Episode Reward: 1.0\n",
      "Step 231 (13021) @ Episode 54/10000, loss: 3.572337664081715e-055\n",
      "Episode Reward: 1.0\n",
      "Step 333 (13354) @ Episode 55/10000, loss: 8.400205842917785e-065\n",
      "Episode Reward: 3.0\n",
      "Step 215 (13569) @ Episode 56/10000, loss: 2.323398439330049e-055\n",
      "Episode Reward: 1.0\n",
      "Step 205 (13774) @ Episode 57/10000, loss: 3.3803487895056605e-05\n",
      "Episode Reward: 1.0\n",
      "Step 172 (13946) @ Episode 58/10000, loss: 1.3020648111705668e-05\n",
      "Episode Reward: 0.0\n",
      "Step 278 (14224) @ Episode 59/10000, loss: 6.642377229582053e-065\n",
      "Episode Reward: 2.0\n",
      "Step 317 (14541) @ Episode 60/10000, loss: 0.03092884644865989705\n",
      "Episode Reward: 2.0\n",
      "Step 283 (14824) @ Episode 61/10000, loss: 7.054772140691057e-065\n",
      "Episode Reward: 2.0\n",
      "Step 265 (15089) @ Episode 62/10000, loss: 6.132628914201632e-055\n",
      "Episode Reward: 2.0\n",
      "Step 352 (15441) @ Episode 63/10000, loss: 3.940632814192213e-055\n",
      "Episode Reward: 3.0\n",
      "Step 591 (16032) @ Episode 64/10000, loss: 1.7871856471174397e-05\n",
      "Episode Reward: 10.0\n",
      "Step 476 (16508) @ Episode 65/10000, loss: 3.087434743065387e-055\n",
      "Episode Reward: 6.0\n",
      "Step 323 (16831) @ Episode 66/10000, loss: 2.026774745900184e-055\n",
      "Episode Reward: 3.0\n",
      "Step 212 (17043) @ Episode 67/10000, loss: 3.0783987313043326e-05\n",
      "Episode Reward: 1.0\n",
      "Step 332 (17375) @ Episode 68/10000, loss: 7.084863318596035e-055\n",
      "Episode Reward: 3.0\n",
      "Step 169 (17544) @ Episode 69/10000, loss: 0.06023094803094864426\n",
      "Episode Reward: 0.0\n",
      "Step 241 (17785) @ Episode 70/10000, loss: 3.073237894568592e-055\n",
      "Episode Reward: 1.0\n",
      "Step 247 (18032) @ Episode 71/10000, loss: 0.00011372484004823491\n",
      "Episode Reward: 1.0\n",
      "Step 407 (18439) @ Episode 72/10000, loss: 0.03118389844894409256\n",
      "Episode Reward: 4.0\n",
      "Step 163 (18602) @ Episode 73/10000, loss: 3.688858123496175e-055\n",
      "Episode Reward: 0.0\n",
      "Step 263 (18865) @ Episode 74/10000, loss: 2.048775968432892e-055\n",
      "Episode Reward: 2.0\n",
      "Step 172 (19037) @ Episode 75/10000, loss: 0.00016584689728915691\n",
      "Episode Reward: 0.0\n",
      "Step 301 (19338) @ Episode 76/10000, loss: 0.00011007383727701381\n",
      "Episode Reward: 3.0\n",
      "Step 173 (19511) @ Episode 77/10000, loss: 3.1876035791356117e-05\n",
      "Episode Reward: 0.0\n",
      "Step 172 (19683) @ Episode 78/10000, loss: 2.3701542886556126e-05\n",
      "Episode Reward: 0.0\n",
      "Step 184 (19867) @ Episode 79/10000, loss: 5.066660378361121e-055\n",
      "Episode Reward: 0.0\n",
      "Step 169 (20036) @ Episode 80/10000, loss: 0.03034692443907261055\n",
      "Episode Reward: 0.0\n",
      "Step 280 (20316) @ Episode 81/10000, loss: 6.183305686136009e-066\n",
      "Episode Reward: 2.0\n",
      "Step 363 (20679) @ Episode 82/10000, loss: 0.03121052123606205065\n",
      "Episode Reward: 4.0\n",
      "Step 267 (20946) @ Episode 83/10000, loss: 9.852176299318671e-054\n",
      "Episode Reward: 2.0\n",
      "Step 267 (21213) @ Episode 84/10000, loss: 0.03056222945451736535\n",
      "Episode Reward: 2.0\n",
      "Step 184 (21397) @ Episode 85/10000, loss: 2.0616706024156883e-05\n",
      "Episode Reward: 0.0\n",
      "Step 187 (21584) @ Episode 86/10000, loss: 2.5794961402425542e-05\n",
      "Episode Reward: 0.0\n",
      "Step 216 (21800) @ Episode 87/10000, loss: 4.072790761711076e-055\n",
      "Episode Reward: 1.0\n",
      "Step 167 (21967) @ Episode 88/10000, loss: 6.818465772084892e-059\n",
      "Episode Reward: 0.0\n",
      "Step 217 (22184) @ Episode 89/10000, loss: 9.22807666938752e-0555\n",
      "Episode Reward: 1.0\n",
      "Step 288 (22472) @ Episode 90/10000, loss: 7.883732905611396e-065\n",
      "Episode Reward: 2.0\n",
      "Step 233 (22705) @ Episode 91/10000, loss: 0.00015622607315890497\n",
      "Episode Reward: 1.0\n",
      "Step 330 (23035) @ Episode 92/10000, loss: 0.03114018589258194055\n",
      "Episode Reward: 3.0\n",
      "Step 235 (23270) @ Episode 93/10000, loss: 4.5516437239712104e-05\n",
      "Episode Reward: 1.0\n",
      "Step 399 (23669) @ Episode 94/10000, loss: 8.533376967534423e-055\n",
      "Episode Reward: 4.0\n",
      "Step 181 (23850) @ Episode 95/10000, loss: 5.3788880904903635e-06\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 170 (24020) @ Episode 96/10000, loss: 4.845025614486076e-052\n",
      "Episode Reward: 0.0\n",
      "Step 425 (24445) @ Episode 97/10000, loss: 9.250587936548982e-065\n",
      "Episode Reward: 5.0\n",
      "Step 346 (24791) @ Episode 98/10000, loss: 4.404157880344428e-055\n",
      "Episode Reward: 3.0\n",
      "Step 214 (25005) @ Episode 99/10000, loss: 0.03012499772012233755\n",
      "Episode Reward: 1.0\n",
      "Step 172 (25177) @ Episode 100/10000, loss: 3.377646498847753e-055\n",
      "Episode Reward: 0.0\n",
      "Step 501 (25678) @ Episode 101/10000, loss: 5.274887371342629e-051\n",
      "Episode Reward: 5.0\n",
      "Step 180 (25858) @ Episode 102/10000, loss: 9.223233791999519e-055\n",
      "Episode Reward: 0.0\n",
      "Step 258 (26116) @ Episode 103/10000, loss: 3.5661538277054206e-05\n",
      "Episode Reward: 2.0\n",
      "Step 246 (26362) @ Episode 104/10000, loss: 8.048547897487879e-055\n",
      "Episode Reward: 1.0\n",
      "Step 161 (26523) @ Episode 105/10000, loss: 1.895881723612547e-055\n",
      "Episode Reward: 0.0\n",
      "Step 203 (26726) @ Episode 106/10000, loss: 4.1532679460942745e-05\n",
      "Episode Reward: 0.0\n",
      "Step 239 (26965) @ Episode 107/10000, loss: 2.4573693735874258e-05\n",
      "Episode Reward: 1.0\n",
      "Step 321 (27286) @ Episode 108/10000, loss: 2.0938243324053474e-05\n",
      "Episode Reward: 2.0\n",
      "Step 274 (27560) @ Episode 109/10000, loss: 0.00027822615811601285\n",
      "Episode Reward: 2.0\n",
      "Step 164 (27724) @ Episode 110/10000, loss: 0.03087157942354679-05\n",
      "Episode Reward: 0.0\n",
      "Step 184 (27908) @ Episode 111/10000, loss: 1.7368613043799996e-05\n",
      "Episode Reward: 0.0\n",
      "Step 402 (28310) @ Episode 112/10000, loss: 2.4642755306558684e-05\n",
      "Episode Reward: 4.0\n",
      "Step 231 (28541) @ Episode 113/10000, loss: 0.03011884912848472655\n",
      "Episode Reward: 1.0\n",
      "Step 174 (28715) @ Episode 114/10000, loss: 0.00013725750613957644\n",
      "Episode Reward: 0.0\n",
      "Step 166 (28881) @ Episode 115/10000, loss: 7.89384648669511e-0655\n",
      "Episode Reward: 0.0\n",
      "Step 392 (29273) @ Episode 116/10000, loss: 0.03050065040588379405\n",
      "Episode Reward: 3.0\n",
      "Step 341 (29614) @ Episode 117/10000, loss: 0.03088669665157795505\n",
      "Episode Reward: 3.0\n",
      "Step 412 (30026) @ Episode 118/10000, loss: 0.00035951155587099495\n",
      "Episode Reward: 4.0\n",
      "Step 333 (30359) @ Episode 119/10000, loss: 2.1099102013977244e-05\n",
      "Episode Reward: 3.0\n",
      "Step 217 (30576) @ Episode 120/10000, loss: 0.03054847754538059263\n",
      "Episode Reward: 1.0\n",
      "Step 182 (30758) @ Episode 121/10000, loss: 1.7252097677555867e-05\n",
      "Episode Reward: 0.0\n",
      "Step 170 (30928) @ Episode 122/10000, loss: 2.2261676349444315e-05\n",
      "Episode Reward: 0.0\n",
      "Step 301 (31229) @ Episode 123/10000, loss: 5.7588142226450145e-05\n",
      "Episode Reward: 2.0\n",
      "Step 432 (31661) @ Episode 124/10000, loss: 0.03121718205511570563\n",
      "Episode Reward: 4.0\n",
      "Step 246 (31907) @ Episode 125/10000, loss: 0.00015014402742963284\n",
      "Episode Reward: 1.0\n",
      "Step 163 (32070) @ Episode 126/10000, loss: 0.03064379654824733705\n",
      "Episode Reward: 0.0\n",
      "Step 395 (32465) @ Episode 127/10000, loss: 0.02961356379091739753\n",
      "Episode Reward: 4.0\n",
      "Step 273 (32738) @ Episode 128/10000, loss: 0.0297152791172266-053\n",
      "Episode Reward: 2.0\n",
      "Step 164 (32902) @ Episode 129/10000, loss: 0.00015404015721287578\n",
      "Episode Reward: 0.0\n",
      "Step 169 (33071) @ Episode 130/10000, loss: 2.4816741643007845e-05\n",
      "Episode Reward: 0.0\n",
      "Step 313 (33384) @ Episode 131/10000, loss: 3.158379695378244e-052\n",
      "Episode Reward: 3.0\n",
      "Step 164 (33548) @ Episode 132/10000, loss: 1.422930472472217e-055\n",
      "Episode Reward: 0.0\n",
      "Step 167 (33715) @ Episode 133/10000, loss: 0.02932764030992984845\n",
      "Episode Reward: 0.0\n",
      "Step 311 (34026) @ Episode 134/10000, loss: 0.00022017395531293005\n",
      "Episode Reward: 2.0\n",
      "Step 167 (34193) @ Episode 135/10000, loss: 0.03103372454643249555\n",
      "Episode Reward: 0.0\n",
      "Step 176 (34369) @ Episode 136/10000, loss: 5.0158530939370394e-05\n",
      "Episode Reward: 0.0\n",
      "Step 250 (34619) @ Episode 137/10000, loss: 3.520520112942904e-052\n",
      "Episode Reward: 1.0\n",
      "Step 164 (34783) @ Episode 138/10000, loss: 0.02710074558854103354\n",
      "Episode Reward: 0.0\n",
      "Step 390 (35173) @ Episode 139/10000, loss: 2.0725696231238544e-05\n",
      "Episode Reward: 4.0\n",
      "Step 166 (35339) @ Episode 140/10000, loss: 0.00057038629893213519\n",
      "Episode Reward: 0.0\n",
      "Step 238 (35577) @ Episode 141/10000, loss: 9.695337212178856e-054\n",
      "Episode Reward: 1.0\n",
      "Step 248 (35825) @ Episode 142/10000, loss: 0.00011131829523947093\n",
      "Episode Reward: 1.0\n",
      "Step 203 (36028) @ Episode 143/10000, loss: 0.00020659001893363893\n",
      "Episode Reward: 1.0\n",
      "Step 234 (36262) @ Episode 144/10000, loss: 0.00013181514805182815\n",
      "Episode Reward: 1.0\n",
      "Step 256 (36518) @ Episode 145/10000, loss: 4.056375473737717e-055\n",
      "Episode Reward: 2.0\n",
      "Step 167 (36685) @ Episode 146/10000, loss: 0.00011441295646363869\n",
      "Episode Reward: 0.0\n",
      "Step 263 (36948) @ Episode 147/10000, loss: 0.00022380868904292583\n",
      "Episode Reward: 2.0\n",
      "Step 224 (37172) @ Episode 148/10000, loss: 0.02784729562699794857\n",
      "Episode Reward: 1.0\n",
      "Step 273 (37445) @ Episode 149/10000, loss: 0.00020894926274195313\n",
      "Episode Reward: 2.0\n",
      "Step 313 (37758) @ Episode 150/10000, loss: 0.00020700677123386413\n",
      "Episode Reward: 2.0\n",
      "Step 273 (38031) @ Episode 151/10000, loss: 0.00084215239621698868\n",
      "Episode Reward: 2.0\n",
      "Step 510 (38541) @ Episode 152/10000, loss: 0.02547355368733406567\n",
      "Episode Reward: 6.0\n",
      "Step 171 (38712) @ Episode 153/10000, loss: 0.02082381956279277886\n",
      "Episode Reward: 0.0\n",
      "Step 190 (38902) @ Episode 154/10000, loss: 6.0943948483327404e-05\n",
      "Episode Reward: 0.0\n",
      "Step 219 (39121) @ Episode 155/10000, loss: 0.01758908852934837363\n",
      "Episode Reward: 1.0\n",
      "Step 234 (39355) @ Episode 156/10000, loss: 0.00020448090799618512\n",
      "Episode Reward: 1.0\n",
      "Step 206 (39561) @ Episode 157/10000, loss: 0.02588818781077861855\n",
      "Episode Reward: 1.0\n",
      "Step 407 (39968) @ Episode 158/10000, loss: 0.00037854007678106427\n",
      "Episode Reward: 4.0\n",
      "Step 179 (40147) @ Episode 159/10000, loss: 0.00017026321438606828\n",
      "Episode Reward: 0.0\n",
      "Step 300 (40447) @ Episode 160/10000, loss: 0.00024708182900212705\n",
      "Episode Reward: 2.0\n",
      "Step 222 (40669) @ Episode 161/10000, loss: 0.02403838373720646744\n",
      "Episode Reward: 1.0\n",
      "Step 545 (41214) @ Episode 162/10000, loss: 0.00397072266787290626\n",
      "Episode Reward: 6.0\n",
      "Step 173 (41387) @ Episode 163/10000, loss: 0.00041061479714699096\n",
      "Episode Reward: 0.0\n",
      "Step 168 (41555) @ Episode 164/10000, loss: 0.00092553941067308195\n",
      "Episode Reward: 0.0\n",
      "Step 166 (41721) @ Episode 165/10000, loss: 0.00039232021663337946\n",
      "Episode Reward: 0.0\n",
      "Step 163 (41884) @ Episode 166/10000, loss: 0.00054302514763548976\n",
      "Episode Reward: 0.0\n",
      "Step 258 (42142) @ Episode 167/10000, loss: 0.01278899423778057156\n",
      "Episode Reward: 2.0\n",
      "Step 264 (42406) @ Episode 168/10000, loss: 0.00023416336625814438\n",
      "Episode Reward: 2.0\n",
      "Step 299 (42705) @ Episode 169/10000, loss: 0.00834664888679981267\n",
      "Episode Reward: 2.0\n",
      "Step 244 (42949) @ Episode 170/10000, loss: 0.00053310790099203598\n",
      "Episode Reward: 1.0\n",
      "Step 285 (43234) @ Episode 171/10000, loss: 5.886550934519619e-054\n",
      "Episode Reward: 2.0\n",
      "Step 245 (43479) @ Episode 172/10000, loss: 6.00181010668166e-0575\n",
      "Episode Reward: 1.0\n",
      "Step 220 (43699) @ Episode 173/10000, loss: 0.00020785161177627742\n",
      "Episode Reward: 1.0\n",
      "Step 174 (43873) @ Episode 174/10000, loss: 5.9693156799767166e-05\n",
      "Episode Reward: 0.0\n",
      "Step 223 (44096) @ Episode 175/10000, loss: 0.00060136395040899525\n",
      "Episode Reward: 1.0\n",
      "Step 167 (44263) @ Episode 176/10000, loss: 0.00077320978743955495\n",
      "Episode Reward: 0.0\n",
      "Step 199 (44462) @ Episode 177/10000, loss: 0.00151563750114291986\n",
      "Episode Reward: 0.0\n",
      "Step 187 (44649) @ Episode 178/10000, loss: 0.00256328238174319276\n",
      "Episode Reward: 0.0\n",
      "Step 232 (44881) @ Episode 179/10000, loss: 0.02303260937333107678\n",
      "Episode Reward: 1.0\n",
      "Step 299 (45180) @ Episode 180/10000, loss: 0.00180159194860607395\n",
      "Episode Reward: 2.0\n",
      "Step 216 (45396) @ Episode 181/10000, loss: 6.209647108335048e-052\n",
      "Episode Reward: 1.0\n",
      "Step 198 (45594) @ Episode 182/10000, loss: 0.00028794788522645837\n",
      "Episode Reward: 0.0\n",
      "Step 172 (45766) @ Episode 183/10000, loss: 0.00024202218628488489\n",
      "Episode Reward: 0.0\n",
      "Step 411 (46177) @ Episode 184/10000, loss: 6.88389191054739e-0554\n",
      "Episode Reward: 4.0\n",
      "Step 383 (46560) @ Episode 185/10000, loss: 4.26753431383986e-0525\n",
      "Episode Reward: 3.0\n",
      "Step 224 (46784) @ Episode 186/10000, loss: 8.383239037357271e-052\n",
      "Episode Reward: 1.0\n",
      "Step 174 (46958) @ Episode 187/10000, loss: 0.01669897697865963057\n",
      "Episode Reward: 0.0\n",
      "Step 175 (47133) @ Episode 188/10000, loss: 0.00023814450833015144\n",
      "Episode Reward: 0.0\n",
      "Step 212 (47345) @ Episode 189/10000, loss: 6.87245192239061e-0515\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 231 (47576) @ Episode 190/10000, loss: 7.434788858518004e-053\n",
      "Episode Reward: 1.0\n",
      "Step 273 (47849) @ Episode 191/10000, loss: 0.00029037136118859056\n",
      "Episode Reward: 2.0\n",
      "Step 166 (48015) @ Episode 192/10000, loss: 0.00107302283868193636\n",
      "Episode Reward: 0.0\n",
      "Step 340 (48355) @ Episode 193/10000, loss: 9.22090039239265e-0505\n",
      "Episode Reward: 3.0\n",
      "Step 176 (48531) @ Episode 194/10000, loss: 0.00122952146921306853\n",
      "Episode Reward: 0.0\n",
      "Step 271 (48802) @ Episode 195/10000, loss: 9.461704030400142e-054\n",
      "Episode Reward: 2.0\n",
      "Step 173 (48975) @ Episode 196/10000, loss: 0.00018338412337470853\n",
      "Episode Reward: 0.0\n",
      "Step 319 (49294) @ Episode 197/10000, loss: 0.00013743744057137528\n",
      "Episode Reward: 3.0\n",
      "Step 265 (49559) @ Episode 198/10000, loss: 0.00115204846952110531\n",
      "Episode Reward: 2.0\n",
      "Step 350 (49909) @ Episode 199/10000, loss: 0.00012475856055971235\n",
      "Episode Reward: 3.0\n",
      "Step 180 (50089) @ Episode 200/10000, loss: 0.00011957099195569754\n",
      "Episode Reward: 0.0\n",
      "Step 218 (50307) @ Episode 201/10000, loss: 0.00032663205638527879\n",
      "Episode Reward: 1.0\n",
      "Step 373 (50680) @ Episode 202/10000, loss: 9.844622400123626e-055\n",
      "Episode Reward: 3.0\n",
      "Step 176 (50856) @ Episode 203/10000, loss: 0.00010981009108945727\n",
      "Episode Reward: 0.0\n",
      "Step 306 (51162) @ Episode 204/10000, loss: 0.00016058274195529526\n",
      "Episode Reward: 3.0\n",
      "Step 249 (51411) @ Episode 205/10000, loss: 0.00018142258340958506\n",
      "Episode Reward: 1.0\n",
      "Step 181 (51592) @ Episode 206/10000, loss: 0.00055844354210421444\n",
      "Episode Reward: 0.0\n",
      "Step 211 (51803) @ Episode 207/10000, loss: 0.00515445973724126842\n",
      "Episode Reward: 1.0\n",
      "Step 180 (51983) @ Episode 208/10000, loss: 0.00063746498199179775\n",
      "Episode Reward: 0.0\n",
      "Step 298 (52281) @ Episode 209/10000, loss: 0.00020534975919872522\n",
      "Episode Reward: 2.0\n",
      "Step 272 (52553) @ Episode 210/10000, loss: 0.00036077620461583146\n",
      "Episode Reward: 2.0\n",
      "Step 162 (52715) @ Episode 211/10000, loss: 0.00096702598966658122\n",
      "Episode Reward: 0.0\n",
      "Step 283 (52998) @ Episode 212/10000, loss: 0.00444302242249250475\n",
      "Episode Reward: 2.0\n",
      "Step 284 (53282) @ Episode 213/10000, loss: 0.00106371892616152765\n",
      "Episode Reward: 2.0\n",
      "Step 166 (53448) @ Episode 214/10000, loss: 0.00562016479671001405\n",
      "Episode Reward: 0.0\n",
      "Step 171 (53619) @ Episode 215/10000, loss: 0.00039056112291291356\n",
      "Episode Reward: 0.0\n",
      "Step 233 (53852) @ Episode 216/10000, loss: 0.00032299986924044795\n",
      "Episode Reward: 1.0\n",
      "Step 256 (54108) @ Episode 217/10000, loss: 4.057154001202434e-055\n",
      "Episode Reward: 1.0\n",
      "Step 438 (54546) @ Episode 218/10000, loss: 0.00190984271466732034\n",
      "Episode Reward: 4.0\n",
      "Step 174 (54720) @ Episode 219/10000, loss: 0.00022733394871465862\n",
      "Episode Reward: 0.0\n",
      "Step 336 (55056) @ Episode 220/10000, loss: 0.00017711492546368398\n",
      "Episode Reward: 3.0\n",
      "Step 168 (55224) @ Episode 221/10000, loss: 0.00015816352970432498\n",
      "Episode Reward: 0.0\n",
      "Step 185 (55409) @ Episode 222/10000, loss: 8.327828982146457e-055\n",
      "Episode Reward: 0.0\n",
      "Step 316 (55725) @ Episode 223/10000, loss: 0.00054410810116678485\n",
      "Episode Reward: 3.0\n",
      "Step 169 (55894) @ Episode 224/10000, loss: 0.00084960757521912465\n",
      "Episode Reward: 0.0\n",
      "Step 286 (56180) @ Episode 225/10000, loss: 0.00010215437214355916\n",
      "Episode Reward: 2.0\n",
      "Step 272 (56452) @ Episode 226/10000, loss: 6.518725422210991e-056\n",
      "Episode Reward: 2.0\n",
      "Step 231 (56683) @ Episode 227/10000, loss: 0.00194947060663253075\n",
      "Episode Reward: 1.0\n",
      "Step 326 (57009) @ Episode 228/10000, loss: 9.931079694069922e-056\n",
      "Episode Reward: 3.0\n",
      "Step 210 (57219) @ Episode 229/10000, loss: 6.271843449212611e-052\n",
      "Episode Reward: 1.0\n",
      "Step 282 (57501) @ Episode 230/10000, loss: 0.00011634219845291227\n",
      "Episode Reward: 2.0\n",
      "Step 382 (57883) @ Episode 231/10000, loss: 0.00019438855815678835\n",
      "Episode Reward: 4.0\n",
      "Step 185 (58068) @ Episode 232/10000, loss: 0.00075692497193813325\n",
      "Episode Reward: 0.0\n",
      "Step 307 (58375) @ Episode 233/10000, loss: 0.00522479694336652765\n",
      "Episode Reward: 2.0\n",
      "Step 170 (58545) @ Episode 234/10000, loss: 0.00017021158419083804\n",
      "Episode Reward: 0.0\n",
      "Step 172 (58717) @ Episode 235/10000, loss: 8.07383912615478e-0532\n",
      "Episode Reward: 0.0\n",
      "Step 208 (58925) @ Episode 236/10000, loss: 3.5733879485633224e-05\n",
      "Episode Reward: 1.0\n",
      "Step 328 (59253) @ Episode 237/10000, loss: 0.00309924595057964323\n",
      "Episode Reward: 3.0\n",
      "Step 158 (59411) @ Episode 238/10000, loss: 0.00019158603390678763\n",
      "Episode Reward: 0.0\n",
      "Step 194 (59605) @ Episode 239/10000, loss: 5.1143462769687176e-05\n",
      "Episode Reward: 0.0\n",
      "Step 409 (60014) @ Episode 240/10000, loss: 0.00085597089491784576\n",
      "Episode Reward: 4.0\n",
      "Step 245 (60259) @ Episode 241/10000, loss: 0.00127860740758478648\n",
      "Episode Reward: 1.0\n",
      "Step 281 (60540) @ Episode 242/10000, loss: 3.6247609386919066e-05\n",
      "Episode Reward: 2.0\n",
      "Step 319 (60859) @ Episode 243/10000, loss: 0.00025228253798559314\n",
      "Episode Reward: 3.0\n",
      "Step 202 (61061) @ Episode 244/10000, loss: 0.00019546801922842867\n",
      "Episode Reward: 0.0\n",
      "Step 338 (61399) @ Episode 245/10000, loss: 0.00021299134823493663\n",
      "Episode Reward: 4.0\n",
      "Step 290 (61689) @ Episode 246/10000, loss: 8.396506018470973e-055\n",
      "Episode Reward: 3.0\n",
      "Step 305 (61994) @ Episode 247/10000, loss: 0.00176596711389720442\n",
      "Episode Reward: 3.0\n",
      "Step 271 (62265) @ Episode 248/10000, loss: 0.00037717775558121586\n",
      "Episode Reward: 2.0\n",
      "Step 178 (62443) @ Episode 249/10000, loss: 3.2160442060558125e-05\n",
      "Episode Reward: 0.0\n",
      "Step 234 (62677) @ Episode 250/10000, loss: 0.00353571656160056605\n",
      "Episode Reward: 1.0\n",
      "Step 291 (62968) @ Episode 251/10000, loss: 0.00777847971767187153\n",
      "Episode Reward: 2.0\n",
      "Step 249 (63217) @ Episode 252/10000, loss: 0.00134840002283453946\n",
      "Episode Reward: 1.0\n",
      "Step 178 (63395) @ Episode 253/10000, loss: 0.00019903221982531255\n",
      "Episode Reward: 0.0\n",
      "Step 173 (63568) @ Episode 254/10000, loss: 4.835396248381585e-056\n",
      "Episode Reward: 0.0\n",
      "Step 347 (63915) @ Episode 255/10000, loss: 0.00141418166458606727\n",
      "Episode Reward: 3.0\n",
      "Step 244 (64159) @ Episode 256/10000, loss: 0.00080454890849068763\n",
      "Episode Reward: 1.0\n",
      "Step 232 (64391) @ Episode 257/10000, loss: 7.467275281669572e-055\n",
      "Episode Reward: 1.0\n",
      "Step 184 (64575) @ Episode 258/10000, loss: 0.00022818830620963126\n",
      "Episode Reward: 0.0\n",
      "Step 249 (64824) @ Episode 259/10000, loss: 5.128404882270843e-052\n",
      "Episode Reward: 1.0\n",
      "Step 271 (65095) @ Episode 260/10000, loss: 0.00065590318990871315\n",
      "Episode Reward: 2.0\n",
      "Step 175 (65270) @ Episode 261/10000, loss: 0.00017929021851159632\n",
      "Episode Reward: 0.0\n",
      "Step 209 (65479) @ Episode 262/10000, loss: 0.00020633198437280953\n",
      "Episode Reward: 1.0\n",
      "Step 307 (65786) @ Episode 263/10000, loss: 0.00299767078831791885\n",
      "Episode Reward: 2.0\n",
      "Step 320 (66106) @ Episode 264/10000, loss: 4.81542811030522e-0505\n",
      "Episode Reward: 3.0\n",
      "Step 235 (66341) @ Episode 265/10000, loss: 5.744866211898625e-056\n",
      "Episode Reward: 1.0\n",
      "Step 333 (66674) @ Episode 266/10000, loss: 0.00021851013298146427\n",
      "Episode Reward: 3.0\n",
      "Step 284 (66958) @ Episode 267/10000, loss: 0.00228180829435586935\n",
      "Episode Reward: 2.0\n",
      "Step 175 (67133) @ Episode 268/10000, loss: 5.966653043287806e-058\n",
      "Episode Reward: 0.0\n",
      "Step 377 (67510) @ Episode 269/10000, loss: 5.0998620281461626e-05\n",
      "Episode Reward: 4.0\n",
      "Step 187 (67697) @ Episode 270/10000, loss: 2.650366150191985e-054\n",
      "Episode Reward: 0.0\n",
      "Step 218 (67915) @ Episode 271/10000, loss: 0.00031177364871837212\n",
      "Episode Reward: 1.0\n",
      "Step 196 (68111) @ Episode 272/10000, loss: 0.00268887379206717275\n",
      "Episode Reward: 0.0\n",
      "Step 213 (68324) @ Episode 273/10000, loss: 0.00024441821733489635\n",
      "Episode Reward: 1.0\n",
      "Step 221 (68545) @ Episode 274/10000, loss: 0.00076487404294312325\n",
      "Episode Reward: 1.0\n",
      "Step 246 (68791) @ Episode 275/10000, loss: 4.2813764594029635e-05\n",
      "Episode Reward: 1.0\n",
      "Step 390 (69181) @ Episode 276/10000, loss: 3.978435415774584e-051\n",
      "Episode Reward: 4.0\n",
      "Step 168 (69349) @ Episode 277/10000, loss: 4.526754128164612e-053\n",
      "Episode Reward: 0.0\n",
      "Step 272 (69621) @ Episode 278/10000, loss: 4.150984386797063e-057\n",
      "Episode Reward: 2.0\n",
      "Step 205 (69826) @ Episode 279/10000, loss: 0.00212135934270918375\n",
      "Episode Reward: 1.0\n",
      "Step 287 (70113) @ Episode 280/10000, loss: 0.00059655983932316353\n",
      "Episode Reward: 2.0\n",
      "Step 280 (70393) @ Episode 281/10000, loss: 0.00205795885995030424\n",
      "Episode Reward: 2.0\n",
      "Step 293 (70686) @ Episode 282/10000, loss: 0.00016061450878623873\n",
      "Episode Reward: 2.0\n",
      "Step 176 (70862) @ Episode 283/10000, loss: 8.75832192832604e-0523\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 273 (71135) @ Episode 284/10000, loss: 0.00048117898404598236\n",
      "Episode Reward: 2.0\n",
      "Step 274 (71409) @ Episode 285/10000, loss: 6.667975685559213e-054\n",
      "Episode Reward: 2.0\n",
      "Step 191 (71600) @ Episode 286/10000, loss: 0.00419952347874641424\n",
      "Episode Reward: 0.0\n",
      "Step 241 (71841) @ Episode 287/10000, loss: 0.00015072307724040002\n",
      "Episode Reward: 1.0\n",
      "Step 217 (72058) @ Episode 288/10000, loss: 0.00019580312073230743\n",
      "Episode Reward: 1.0\n",
      "Step 310 (72368) @ Episode 289/10000, loss: 0.00018159260798711335\n",
      "Episode Reward: 2.0\n",
      "Step 346 (72714) @ Episode 290/10000, loss: 0.00522595364600422416\n",
      "Episode Reward: 3.0\n",
      "Step 228 (72942) @ Episode 291/10000, loss: 0.00146656366996467115\n",
      "Episode Reward: 1.0\n",
      "Step 269 (73211) @ Episode 292/10000, loss: 5.0282142183277756e-05\n",
      "Episode Reward: 2.0\n",
      "Step 221 (73432) @ Episode 293/10000, loss: 0.00105478346813470136\n",
      "Episode Reward: 1.0\n",
      "Step 172 (73604) @ Episode 294/10000, loss: 0.00036682264180853963\n",
      "Episode Reward: 0.0\n",
      "Step 168 (73772) @ Episode 295/10000, loss: 8.286810043500736e-055\n",
      "Episode Reward: 0.0\n",
      "Step 169 (73941) @ Episode 296/10000, loss: 0.00050501985242590315\n",
      "Episode Reward: 0.0\n",
      "Step 416 (74357) @ Episode 297/10000, loss: 5.842738028150052e-053\n",
      "Episode Reward: 4.0\n",
      "Step 299 (74656) @ Episode 298/10000, loss: 0.00039010957698337734\n",
      "Episode Reward: 2.0\n",
      "Step 185 (74841) @ Episode 299/10000, loss: 9.581274935044348e-056\n",
      "Episode Reward: 0.0\n",
      "Step 273 (75114) @ Episode 300/10000, loss: 0.00143425900023430593\n",
      "Episode Reward: 2.0\n",
      "Step 269 (75383) @ Episode 301/10000, loss: 0.00025931303389370445\n",
      "Episode Reward: 2.0\n",
      "Step 328 (75711) @ Episode 302/10000, loss: 0.00036407299921847885\n",
      "Episode Reward: 3.0\n",
      "Step 267 (75978) @ Episode 303/10000, loss: 0.00021003406436648225\n",
      "Episode Reward: 2.0\n",
      "Step 283 (76261) @ Episode 304/10000, loss: 9.644103556638584e-057\n",
      "Episode Reward: 2.0\n",
      "Step 245 (76506) @ Episode 305/10000, loss: 5.9187419537920505e-05\n",
      "Episode Reward: 1.0\n",
      "Step 348 (76854) @ Episode 306/10000, loss: 0.00016782109742052853\n",
      "Episode Reward: 3.0\n",
      "Step 252 (77106) @ Episode 307/10000, loss: 4.588414230966009e-055\n",
      "Episode Reward: 1.0\n",
      "Step 237 (77343) @ Episode 308/10000, loss: 0.01370789203792810447\n",
      "Episode Reward: 1.0\n",
      "Step 226 (77569) @ Episode 309/10000, loss: 0.00483822124078869896\n",
      "Episode Reward: 1.0\n",
      "Step 243 (77812) @ Episode 310/10000, loss: 6.846753240097314e-059\n",
      "Episode Reward: 1.0\n",
      "Step 177 (77989) @ Episode 311/10000, loss: 0.00047493132296949625\n",
      "Episode Reward: 0.0\n",
      "Step 166 (78155) @ Episode 312/10000, loss: 0.00032332132104784255\n",
      "Episode Reward: 0.0\n",
      "Step 182 (78337) @ Episode 313/10000, loss: 0.00064394174842163925\n",
      "Episode Reward: 0.0\n",
      "Step 237 (78574) @ Episode 314/10000, loss: 0.00010066167305922136\n",
      "Episode Reward: 1.0\n",
      "Step 288 (78862) @ Episode 315/10000, loss: 0.00139777176082134255\n",
      "Episode Reward: 2.0\n",
      "Step 318 (79180) @ Episode 316/10000, loss: 0.00169795495457947255\n",
      "Episode Reward: 2.0\n",
      "Step 183 (79363) @ Episode 317/10000, loss: 5.298630640027113e-056\n",
      "Episode Reward: 0.0\n",
      "Step 298 (79661) @ Episode 318/10000, loss: 0.00015285791596397758\n",
      "Episode Reward: 2.0\n",
      "Step 232 (79893) @ Episode 319/10000, loss: 0.00369599624536931582\n",
      "Episode Reward: 1.0\n",
      "Step 251 (80144) @ Episode 320/10000, loss: 0.00708145601674914423\n",
      "Episode Reward: 1.0\n",
      "Step 214 (80358) @ Episode 321/10000, loss: 0.00019913539290428162\n",
      "Episode Reward: 1.0\n",
      "Step 244 (80602) @ Episode 322/10000, loss: 0.00065311777871102157\n",
      "Episode Reward: 1.0\n",
      "Step 446 (81048) @ Episode 323/10000, loss: 0.00106058397796005513\n",
      "Episode Reward: 5.0\n",
      "Step 176 (81224) @ Episode 324/10000, loss: 0.00012802644050680156\n",
      "Episode Reward: 0.0\n",
      "Step 275 (81499) @ Episode 325/10000, loss: 5.3517149353865534e-05\n",
      "Episode Reward: 2.0\n",
      "Step 231 (81730) @ Episode 326/10000, loss: 0.00045023605343885726\n",
      "Episode Reward: 1.0\n",
      "Step 186 (81916) @ Episode 327/10000, loss: 5.0835617003031075e-05\n",
      "Episode Reward: 0.0\n",
      "Step 276 (82192) @ Episode 328/10000, loss: 0.00023380623315460985\n",
      "Episode Reward: 2.0\n",
      "Step 172 (82364) @ Episode 329/10000, loss: 0.00096613861387595535\n",
      "Episode Reward: 0.0\n",
      "Step 169 (82533) @ Episode 330/10000, loss: 3.0392322514671832e-05\n",
      "Episode Reward: 0.0\n",
      "Step 181 (82714) @ Episode 331/10000, loss: 3.4262367989867926e-05\n",
      "Episode Reward: 0.0\n",
      "Step 277 (82991) @ Episode 332/10000, loss: 0.00097328459378331965\n",
      "Episode Reward: 2.0\n",
      "Step 321 (83312) @ Episode 333/10000, loss: 2.0506589862634428e-05\n",
      "Episode Reward: 2.0\n",
      "Step 382 (83694) @ Episode 334/10000, loss: 0.00013640153338201344\n",
      "Episode Reward: 4.0\n",
      "Step 181 (83875) @ Episode 335/10000, loss: 3.3904798328876495e-05\n",
      "Episode Reward: 0.0\n",
      "Step 261 (84136) @ Episode 336/10000, loss: 0.00102141220122575766\n",
      "Episode Reward: 1.0\n",
      "Step 199 (84335) @ Episode 337/10000, loss: 0.00067587057128548624\n",
      "Episode Reward: 1.0\n",
      "Step 183 (84518) @ Episode 338/10000, loss: 7.076279143802822e-055\n",
      "Episode Reward: 0.0\n",
      "Step 260 (84778) @ Episode 339/10000, loss: 0.00032228542841039654\n",
      "Episode Reward: 1.0\n",
      "Step 164 (84942) @ Episode 340/10000, loss: 8.010736928554252e-055\n",
      "Episode Reward: 0.0\n",
      "Step 179 (85121) @ Episode 341/10000, loss: 4.527651617536321e-053\n",
      "Episode Reward: 0.0\n",
      "Step 169 (85290) @ Episode 342/10000, loss: 0.00011419155634939674\n",
      "Episode Reward: 0.0\n",
      "Step 229 (85519) @ Episode 343/10000, loss: 0.00015917132259346545\n",
      "Episode Reward: 1.0\n",
      "Step 303 (85822) @ Episode 344/10000, loss: 0.00040029140654951334\n",
      "Episode Reward: 2.0\n",
      "Step 548 (86370) @ Episode 345/10000, loss: 0.00118607131298631436\n",
      "Episode Reward: 6.0\n",
      "Step 247 (86617) @ Episode 346/10000, loss: 0.00129601778462529187\n",
      "Episode Reward: 1.0\n",
      "Step 162 (86779) @ Episode 347/10000, loss: 0.00023610367497894913\n",
      "Episode Reward: 0.0\n",
      "Step 292 (87071) @ Episode 348/10000, loss: 0.00016046260134316982\n",
      "Episode Reward: 2.0\n",
      "Step 202 (87273) @ Episode 349/10000, loss: 0.00013173693150747567\n",
      "Episode Reward: 1.0\n",
      "Step 191 (87464) @ Episode 350/10000, loss: 4.662556239054538e-052\n",
      "Episode Reward: 0.0\n",
      "Step 333 (87797) @ Episode 351/10000, loss: 0.00023536737717222422\n",
      "Episode Reward: 3.0\n",
      "Step 195 (87992) @ Episode 352/10000, loss: 0.00065883935894817113\n",
      "Episode Reward: 0.0\n",
      "Step 183 (88175) @ Episode 353/10000, loss: 0.00030279858037829458\n",
      "Episode Reward: 0.0\n",
      "Step 502 (88677) @ Episode 354/10000, loss: 3.283090336481109e-055\n",
      "Episode Reward: 5.0\n",
      "Step 291 (88968) @ Episode 355/10000, loss: 0.00070150452665984637\n",
      "Episode Reward: 2.0\n",
      "Step 306 (89274) @ Episode 356/10000, loss: 0.00058612803695723418\n",
      "Episode Reward: 2.0\n",
      "Step 167 (89441) @ Episode 357/10000, loss: 0.00031405748450197285\n",
      "Episode Reward: 0.0\n",
      "Step 224 (89665) @ Episode 358/10000, loss: 0.00013743646559305495\n",
      "Episode Reward: 1.0\n",
      "Step 271 (89936) @ Episode 359/10000, loss: 0.00093046459369361405\n",
      "Episode Reward: 2.0\n",
      "Step 248 (90184) @ Episode 360/10000, loss: 0.00098480633459985266\n",
      "Episode Reward: 1.0\n",
      "Step 217 (90401) @ Episode 361/10000, loss: 0.00022597052156925201\n",
      "Episode Reward: 1.0\n",
      "Step 276 (90677) @ Episode 362/10000, loss: 0.00045177244464866817\n",
      "Episode Reward: 2.0\n",
      "Step 296 (90973) @ Episode 363/10000, loss: 0.00225392170250415833\n",
      "Episode Reward: 2.0\n",
      "Step 335 (91308) @ Episode 364/10000, loss: 0.00361799658276140705\n",
      "Episode Reward: 3.0\n",
      "Step 284 (91592) @ Episode 365/10000, loss: 0.00464492943137884166\n",
      "Episode Reward: 2.0\n",
      "Step 336 (91928) @ Episode 366/10000, loss: 0.00262049632146954546\n",
      "Episode Reward: 3.0\n",
      "Step 237 (92165) @ Episode 367/10000, loss: 0.00060979841509833934\n",
      "Episode Reward: 1.0\n",
      "Step 177 (92342) @ Episode 368/10000, loss: 0.00349648040719330396\n",
      "Episode Reward: 0.0\n",
      "Step 184 (92526) @ Episode 369/10000, loss: 0.00102861062623560433\n",
      "Episode Reward: 0.0\n",
      "Step 201 (92727) @ Episode 370/10000, loss: 0.00078812619904056197\n",
      "Episode Reward: 0.0\n",
      "Step 174 (92901) @ Episode 371/10000, loss: 0.00026588514447212229\n",
      "Episode Reward: 0.0\n",
      "Step 177 (93078) @ Episode 372/10000, loss: 0.00023992873320821673\n",
      "Episode Reward: 0.0\n",
      "Step 186 (93264) @ Episode 373/10000, loss: 0.00904851313680410414\n",
      "Episode Reward: 0.0\n",
      "Step 169 (93433) @ Episode 374/10000, loss: 0.00324561074376106265\n",
      "Episode Reward: 0.0\n",
      "Step 258 (93691) @ Episode 375/10000, loss: 8.061371045187116e-055\n",
      "Episode Reward: 2.0\n",
      "Step 255 (93946) @ Episode 376/10000, loss: 4.741753946291283e-056\n",
      "Episode Reward: 1.0\n",
      "Step 165 (94111) @ Episode 377/10000, loss: 9.016133844852448e-057\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 199 (94310) @ Episode 378/10000, loss: 0.00204327423125505454\n",
      "Episode Reward: 0.0\n",
      "Step 177 (94487) @ Episode 379/10000, loss: 5.0852966523962095e-05\n",
      "Episode Reward: 0.0\n",
      "Step 389 (94876) @ Episode 380/10000, loss: 0.00057720579206943515\n",
      "Episode Reward: 3.0\n",
      "Step 275 (95151) @ Episode 381/10000, loss: 0.00026379665359854764\n",
      "Episode Reward: 2.0\n",
      "Step 304 (95455) @ Episode 382/10000, loss: 0.00066008180147036913\n",
      "Episode Reward: 3.0\n",
      "Step 171 (95626) @ Episode 383/10000, loss: 0.00028988771373406055\n",
      "Episode Reward: 0.0\n",
      "Step 256 (95882) @ Episode 384/10000, loss: 0.00014585866301786155\n",
      "Episode Reward: 1.0\n",
      "Step 271 (96153) @ Episode 385/10000, loss: 0.00327455624938011178\n",
      "Episode Reward: 1.0\n",
      "Step 279 (96432) @ Episode 386/10000, loss: 0.00174046377651393415\n",
      "Episode Reward: 2.0\n",
      "Step 321 (96753) @ Episode 387/10000, loss: 0.00062379892915487295\n",
      "Episode Reward: 2.0\n",
      "Step 178 (96931) @ Episode 388/10000, loss: 0.00190415198449045428\n",
      "Episode Reward: 0.0\n",
      "Step 186 (97117) @ Episode 389/10000, loss: 0.00104200001806020745\n",
      "Episode Reward: 0.0\n",
      "Step 175 (97292) @ Episode 390/10000, loss: 0.00304011441767215739\n",
      "Episode Reward: 0.0\n",
      "Step 308 (97600) @ Episode 391/10000, loss: 0.00014902596012689173\n",
      "Episode Reward: 2.0\n",
      "Step 299 (97899) @ Episode 392/10000, loss: 1.657804023125209e-057\n",
      "Episode Reward: 2.0\n",
      "Step 164 (98063) @ Episode 393/10000, loss: 0.00145289814099669465\n",
      "Episode Reward: 0.0\n",
      "Step 265 (98328) @ Episode 394/10000, loss: 0.00024493076489306986\n",
      "Episode Reward: 1.0\n",
      "Step 212 (98540) @ Episode 395/10000, loss: 0.00040188152343034744\n",
      "Episode Reward: 1.0\n",
      "Step 178 (98718) @ Episode 396/10000, loss: 0.00155384396202862264\n",
      "Episode Reward: 0.0\n",
      "Step 173 (98891) @ Episode 397/10000, loss: 8.043138950597495e-056\n",
      "Episode Reward: 0.0\n",
      "Step 217 (99108) @ Episode 398/10000, loss: 4.457718023331836e-051\n",
      "Episode Reward: 1.0\n",
      "Step 228 (99336) @ Episode 399/10000, loss: 0.00026888921274803583\n",
      "Episode Reward: 1.0\n",
      "Step 317 (99653) @ Episode 400/10000, loss: 5.667018558597192e-055\n",
      "Episode Reward: 2.0\n",
      "Step 264 (99917) @ Episode 401/10000, loss: 0.00096977542852982884\n",
      "Episode Reward: 2.0\n",
      "Step 305 (100222) @ Episode 402/10000, loss: 0.00014664669288322339\n",
      "Episode Reward: 2.0\n",
      "Step 182 (100404) @ Episode 403/10000, loss: 0.00339304376393556688\n",
      "Episode Reward: 0.0\n",
      "Step 189 (100593) @ Episode 404/10000, loss: 0.00057727261446416385\n",
      "Episode Reward: 0.0\n",
      "Step 217 (100810) @ Episode 405/10000, loss: 9.967120422516018e-053\n",
      "Episode Reward: 1.0\n",
      "Step 245 (101055) @ Episode 406/10000, loss: 0.00012812102795578546\n",
      "Episode Reward: 1.0\n",
      "Step 244 (101299) @ Episode 407/10000, loss: 0.00067085080081596978\n",
      "Episode Reward: 1.0\n",
      "Step 277 (101576) @ Episode 408/10000, loss: 5.427842552307993e-056\n",
      "Episode Reward: 2.0\n",
      "Step 312 (101888) @ Episode 409/10000, loss: 0.00076291424920782454\n",
      "Episode Reward: 3.0\n",
      "Step 171 (102059) @ Episode 410/10000, loss: 0.00063054560450837029\n",
      "Episode Reward: 0.0\n",
      "Step 182 (102241) @ Episode 411/10000, loss: 0.00032498213113285635\n",
      "Episode Reward: 0.0\n",
      "Step 253 (102494) @ Episode 412/10000, loss: 4.633950811694376e-057\n",
      "Episode Reward: 1.0\n",
      "Step 230 (102724) @ Episode 413/10000, loss: 3.3379634260199964e-05\n",
      "Episode Reward: 1.0\n",
      "Step 277 (103001) @ Episode 414/10000, loss: 4.536740743787959e-053\n",
      "Episode Reward: 2.0\n",
      "Step 248 (103249) @ Episode 415/10000, loss: 0.00143767229747027164\n",
      "Episode Reward: 1.0\n",
      "Step 206 (103455) @ Episode 416/10000, loss: 6.284255505306646e-055\n",
      "Episode Reward: 1.0\n",
      "Step 280 (103735) @ Episode 417/10000, loss: 0.00098769110627472465\n",
      "Episode Reward: 2.0\n",
      "Step 168 (103903) @ Episode 418/10000, loss: 0.00032424862729385495\n",
      "Episode Reward: 0.0\n",
      "Step 169 (104072) @ Episode 419/10000, loss: 8.736659947317094e-055\n",
      "Episode Reward: 0.0\n",
      "Step 166 (104238) @ Episode 420/10000, loss: 0.00013877695892006163\n",
      "Episode Reward: 0.0\n",
      "Step 310 (104548) @ Episode 421/10000, loss: 6.866059266030788e-055\n",
      "Episode Reward: 2.0\n",
      "Step 181 (104729) @ Episode 422/10000, loss: 0.00014545048179570585\n",
      "Episode Reward: 0.0\n",
      "Step 555 (105284) @ Episode 423/10000, loss: 0.00038792524719610816\n",
      "Episode Reward: 6.0\n",
      "Step 176 (105460) @ Episode 424/10000, loss: 8.016919309739023e-055\n",
      "Episode Reward: 0.0\n",
      "Step 272 (105732) @ Episode 425/10000, loss: 7.80965929152444e-0552\n",
      "Episode Reward: 2.0\n",
      "Step 185 (105917) @ Episode 426/10000, loss: 0.00273549812845885755\n",
      "Episode Reward: 0.0\n",
      "Step 176 (106093) @ Episode 427/10000, loss: 0.00033789186272770166\n",
      "Episode Reward: 0.0\n",
      "Step 170 (106263) @ Episode 428/10000, loss: 0.00732849491760134703\n",
      "Episode Reward: 0.0\n",
      "Step 179 (106442) @ Episode 429/10000, loss: 0.00012984986824449152\n",
      "Episode Reward: 0.0\n",
      "Step 174 (106616) @ Episode 430/10000, loss: 2.3250348021974787e-05\n",
      "Episode Reward: 0.0\n",
      "Step 366 (106982) @ Episode 431/10000, loss: 0.00107906211633235223\n",
      "Episode Reward: 3.0\n",
      "Step 271 (107253) @ Episode 432/10000, loss: 5.039546522311866e-058\n",
      "Episode Reward: 2.0\n",
      "Step 170 (107423) @ Episode 433/10000, loss: 0.00242623430676758367\n",
      "Episode Reward: 0.0\n",
      "Step 168 (107591) @ Episode 434/10000, loss: 0.00017078284872695804\n",
      "Episode Reward: 0.0\n",
      "Step 280 (107871) @ Episode 435/10000, loss: 0.00080199370859190824\n",
      "Episode Reward: 2.0\n",
      "Step 170 (108041) @ Episode 436/10000, loss: 0.00014404952526092532\n",
      "Episode Reward: 0.0\n",
      "Step 276 (108317) @ Episode 437/10000, loss: 0.00021040417777840048\n",
      "Episode Reward: 2.0\n",
      "Step 213 (108530) @ Episode 438/10000, loss: 0.00294896261766552933\n",
      "Episode Reward: 1.0\n",
      "Step 234 (108764) @ Episode 439/10000, loss: 0.00063498003873974085\n",
      "Episode Reward: 1.0\n",
      "Step 271 (109035) @ Episode 440/10000, loss: 0.00023725428036414087\n",
      "Episode Reward: 2.0\n",
      "Step 181 (109216) @ Episode 441/10000, loss: 7.101192022673786e-059\n",
      "Episode Reward: 0.0\n",
      "Step 339 (109555) @ Episode 442/10000, loss: 2.673836388566997e-055\n",
      "Episode Reward: 3.0\n",
      "Step 188 (109743) @ Episode 443/10000, loss: 0.00118644244503229866\n",
      "Episode Reward: 0.0\n",
      "Step 203 (109946) @ Episode 444/10000, loss: 0.00078217813279479747\n",
      "Episode Reward: 0.0\n",
      "Step 253 (110199) @ Episode 445/10000, loss: 0.00293340347707271587\n",
      "Episode Reward: 1.0\n",
      "Step 186 (110385) @ Episode 446/10000, loss: 0.00163727905601263054\n",
      "Episode Reward: 0.0\n",
      "Step 232 (110617) @ Episode 447/10000, loss: 0.00035637675318866979\n",
      "Episode Reward: 1.0\n",
      "Step 204 (110821) @ Episode 448/10000, loss: 0.00034778250847011805\n",
      "Episode Reward: 1.0\n",
      "Step 278 (111099) @ Episode 449/10000, loss: 9.674281318439171e-055\n",
      "Episode Reward: 2.0\n",
      "Step 303 (111402) @ Episode 450/10000, loss: 9.671247971709818e-052\n",
      "Episode Reward: 2.0\n",
      "Step 336 (111738) @ Episode 451/10000, loss: 0.05509423837065697654\n",
      "Episode Reward: 3.0\n",
      "Step 294 (112032) @ Episode 452/10000, loss: 0.00021088421635795385\n",
      "Episode Reward: 2.0\n",
      "Step 254 (112286) @ Episode 453/10000, loss: 0.00341509631834924291\n",
      "Episode Reward: 2.0\n",
      "Step 181 (112467) @ Episode 454/10000, loss: 5.252073606243357e-059\n",
      "Episode Reward: 0.0\n",
      "Step 278 (112745) @ Episode 455/10000, loss: 8.848011930240318e-054\n",
      "Episode Reward: 1.0\n",
      "Step 170 (112915) @ Episode 456/10000, loss: 0.00027848206809721887\n",
      "Episode Reward: 0.0\n",
      "Step 246 (113161) @ Episode 457/10000, loss: 0.00166553596500307324\n",
      "Episode Reward: 1.0\n",
      "Step 177 (113338) @ Episode 458/10000, loss: 0.00352501776069402723\n",
      "Episode Reward: 0.0\n",
      "Step 374 (113712) @ Episode 459/10000, loss: 0.00201548356562852864\n",
      "Episode Reward: 3.0\n",
      "Step 172 (113884) @ Episode 460/10000, loss: 0.00012662784138228744\n",
      "Episode Reward: 0.0\n",
      "Step 332 (114216) @ Episode 461/10000, loss: 0.00020533851056825376\n",
      "Episode Reward: 3.0\n",
      "Step 279 (114495) @ Episode 462/10000, loss: 3.7572113797068596e-05\n",
      "Episode Reward: 2.0\n",
      "Step 354 (114849) @ Episode 463/10000, loss: 0.00059812533436343077\n",
      "Episode Reward: 3.0\n",
      "Step 235 (115084) @ Episode 464/10000, loss: 6.596717139473185e-055\n",
      "Episode Reward: 1.0\n",
      "Step 342 (115426) @ Episode 465/10000, loss: 8.287989476229995e-055\n",
      "Episode Reward: 3.0\n",
      "Step 229 (115655) @ Episode 466/10000, loss: 0.00027306261472404003\n",
      "Episode Reward: 1.0\n",
      "Step 179 (115834) @ Episode 467/10000, loss: 0.00061170069966465237\n",
      "Episode Reward: 0.0\n",
      "Step 168 (116002) @ Episode 468/10000, loss: 0.00097005703719332813\n",
      "Episode Reward: 0.0\n",
      "Step 277 (116279) @ Episode 469/10000, loss: 0.00337293581105768755\n",
      "Episode Reward: 2.0\n",
      "Step 175 (116454) @ Episode 470/10000, loss: 0.00036202947376295924\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 228 (116682) @ Episode 471/10000, loss: 0.00042644474888220433\n",
      "Episode Reward: 1.0\n",
      "Step 195 (116877) @ Episode 472/10000, loss: 0.00114816846325993547\n",
      "Episode Reward: 0.0\n",
      "Step 201 (117078) @ Episode 473/10000, loss: 0.00081537704681977635\n",
      "Episode Reward: 0.0\n",
      "Step 187 (117265) @ Episode 474/10000, loss: 0.00021595100406557322\n",
      "Episode Reward: 0.0\n",
      "Step 322 (117587) @ Episode 475/10000, loss: 0.00022673298371955752\n",
      "Episode Reward: 2.0\n",
      "Step 296 (117883) @ Episode 476/10000, loss: 2.3967742890818045e-05\n",
      "Episode Reward: 2.0\n",
      "Step 199 (118082) @ Episode 477/10000, loss: 0.00035660300636664033\n",
      "Episode Reward: 0.0\n",
      "Step 241 (118323) @ Episode 478/10000, loss: 5.075911394669674e-055\n",
      "Episode Reward: 1.0\n",
      "Step 241 (118564) @ Episode 479/10000, loss: 0.00018020349671132863\n",
      "Episode Reward: 1.0\n",
      "Step 233 (118797) @ Episode 480/10000, loss: 0.00029268607613630593\n",
      "Episode Reward: 1.0\n",
      "Step 174 (118971) @ Episode 481/10000, loss: 0.00153561623301357031\n",
      "Episode Reward: 0.0\n",
      "Step 166 (119137) @ Episode 482/10000, loss: 0.00130698620341718205\n",
      "Episode Reward: 0.0\n",
      "Step 174 (119311) @ Episode 483/10000, loss: 0.00050161714898422364\n",
      "Episode Reward: 0.0\n",
      "Step 194 (119505) @ Episode 484/10000, loss: 0.00012450112262740733\n",
      "Episode Reward: 0.0\n",
      "Step 224 (119729) @ Episode 485/10000, loss: 0.00234667328186333246\n",
      "Episode Reward: 1.0\n",
      "Step 247 (119976) @ Episode 486/10000, loss: 0.00042968100751750173\n",
      "Episode Reward: 1.0\n",
      "Step 184 (120160) @ Episode 487/10000, loss: 0.00089607510017231115\n",
      "Episode Reward: 0.0\n",
      "Step 170 (120330) @ Episode 488/10000, loss: 0.00093528785509988678\n",
      "Episode Reward: 0.0\n",
      "Step 287 (120617) @ Episode 489/10000, loss: 0.00160997302737087015\n",
      "Episode Reward: 2.0\n",
      "Step 360 (120977) @ Episode 490/10000, loss: 0.00041212426731362947\n",
      "Episode Reward: 3.0\n",
      "Step 295 (121272) @ Episode 491/10000, loss: 0.00304442597553133965\n",
      "Episode Reward: 2.0\n",
      "Step 162 (121434) @ Episode 492/10000, loss: 0.00069176149554550654\n",
      "Episode Reward: 0.0\n",
      "Step 452 (121886) @ Episode 493/10000, loss: 0.01473399996757507346\n",
      "Episode Reward: 5.0\n",
      "Step 185 (122071) @ Episode 494/10000, loss: 0.00067276362096890813\n",
      "Episode Reward: 0.0\n",
      "Step 310 (122381) @ Episode 495/10000, loss: 0.00422581424936652283\n",
      "Episode Reward: 3.0\n",
      "Step 276 (122657) @ Episode 496/10000, loss: 0.00013594748452305794\n",
      "Episode Reward: 2.0\n",
      "Step 213 (122870) @ Episode 497/10000, loss: 0.00021687902335543185\n",
      "Episode Reward: 1.0\n",
      "Step 350 (123220) @ Episode 498/10000, loss: 0.00079451146302744755\n",
      "Episode Reward: 3.0\n",
      "Step 171 (123391) @ Episode 499/10000, loss: 3.4209391742479056e-05\n",
      "Episode Reward: 0.0\n",
      "Step 274 (123665) @ Episode 500/10000, loss: 0.00031250796746462584\n",
      "Episode Reward: 2.0\n",
      "Step 234 (123899) @ Episode 501/10000, loss: 0.00121759879402816305\n",
      "Episode Reward: 1.0\n",
      "Step 217 (124116) @ Episode 502/10000, loss: 0.00127827865071594727\n",
      "Episode Reward: 1.0\n",
      "Step 199 (124315) @ Episode 503/10000, loss: 0.00224262243136763574\n",
      "Episode Reward: 0.0\n",
      "Step 227 (124542) @ Episode 504/10000, loss: 0.00034411394153721635\n",
      "Episode Reward: 1.0\n",
      "Step 249 (124791) @ Episode 505/10000, loss: 0.00058467773487791427\n",
      "Episode Reward: 1.0\n",
      "Step 171 (124962) @ Episode 506/10000, loss: 7.439261389663443e-054\n",
      "Episode Reward: 0.0\n",
      "Step 202 (125164) @ Episode 507/10000, loss: 0.00045413774205371743\n",
      "Episode Reward: 0.0\n",
      "Step 585 (125749) @ Episode 508/10000, loss: 0.00026984285796061167\n",
      "Episode Reward: 8.0\n",
      "Step 308 (126057) @ Episode 509/10000, loss: 0.00109101692214608287\n",
      "Episode Reward: 2.0\n",
      "Step 372 (126429) @ Episode 510/10000, loss: 8.18134139990434e-0554\n",
      "Episode Reward: 3.0\n",
      "Step 360 (126789) @ Episode 511/10000, loss: 0.00050482060760259633\n",
      "Episode Reward: 3.0\n",
      "Step 358 (127147) @ Episode 512/10000, loss: 0.00013915164163336158\n",
      "Episode Reward: 3.0\n",
      "Step 358 (127505) @ Episode 513/10000, loss: 0.00121909717563539747\n",
      "Episode Reward: 4.0\n",
      "Step 315 (127820) @ Episode 514/10000, loss: 0.00033217217423953116\n",
      "Episode Reward: 2.0\n",
      "Step 408 (128228) @ Episode 515/10000, loss: 0.00153899216093122965\n",
      "Episode Reward: 5.0\n",
      "Step 254 (128482) @ Episode 516/10000, loss: 0.00028009412926621735\n",
      "Episode Reward: 1.0\n",
      "Step 340 (128822) @ Episode 517/10000, loss: 0.00106499216053634886\n",
      "Episode Reward: 3.0\n",
      "Step 265 (129087) @ Episode 518/10000, loss: 0.00012412617797963322\n",
      "Episode Reward: 2.0\n",
      "Step 198 (129285) @ Episode 519/10000, loss: 0.00022977449407335375\n",
      "Episode Reward: 0.0\n",
      "Step 226 (129511) @ Episode 520/10000, loss: 5.7303986977785826e-05\n",
      "Episode Reward: 1.0\n",
      "Step 187 (129698) @ Episode 521/10000, loss: 0.00031414494151249537\n",
      "Episode Reward: 0.0\n",
      "Step 172 (129870) @ Episode 522/10000, loss: 0.00063768116524443036\n",
      "Episode Reward: 0.0\n",
      "Step 212 (130082) @ Episode 523/10000, loss: 0.00211502704769372948\n",
      "Episode Reward: 0.0\n",
      "Step 175 (130257) @ Episode 524/10000, loss: 0.00011637044372037053\n",
      "Episode Reward: 0.0\n",
      "Step 211 (130468) @ Episode 525/10000, loss: 0.00084377621533349167\n",
      "Episode Reward: 1.0\n",
      "Step 174 (130642) @ Episode 526/10000, loss: 0.00025854061823338275\n",
      "Episode Reward: 0.0\n",
      "Step 188 (130830) @ Episode 527/10000, loss: 0.00175656878855079415\n",
      "Episode Reward: 0.0\n",
      "Step 175 (131005) @ Episode 528/10000, loss: 6.651977309957147e-053\n",
      "Episode Reward: 0.0\n",
      "Step 211 (131216) @ Episode 529/10000, loss: 0.00027316116029396653\n",
      "Episode Reward: 1.0\n",
      "Step 356 (131572) @ Episode 530/10000, loss: 0.00120185082778334623\n",
      "Episode Reward: 4.0\n",
      "Step 240 (131812) @ Episode 531/10000, loss: 8.179889846360311e-058\n",
      "Episode Reward: 1.0\n",
      "Step 276 (132088) @ Episode 532/10000, loss: 0.00019857035658787936\n",
      "Episode Reward: 2.0\n",
      "Step 168 (132256) @ Episode 533/10000, loss: 0.00042693686555139724\n",
      "Episode Reward: 0.0\n",
      "Step 232 (132488) @ Episode 534/10000, loss: 0.00035283394390717157\n",
      "Episode Reward: 1.0\n",
      "Step 328 (132816) @ Episode 535/10000, loss: 0.00014959546388126911\n",
      "Episode Reward: 2.0\n",
      "Step 245 (133061) @ Episode 536/10000, loss: 0.00041727023199200635\n",
      "Episode Reward: 1.0\n",
      "Step 342 (133403) @ Episode 537/10000, loss: 0.00058574788272380835\n",
      "Episode Reward: 3.0\n",
      "Step 185 (133588) @ Episode 538/10000, loss: 0.00012849920312874026\n",
      "Episode Reward: 0.0\n",
      "Step 288 (133876) @ Episode 539/10000, loss: 0.00030981219606474046\n",
      "Episode Reward: 2.0\n",
      "Step 272 (134148) @ Episode 540/10000, loss: 0.00037400602013804022\n",
      "Episode Reward: 1.0\n",
      "Step 183 (134331) @ Episode 541/10000, loss: 0.00066632701782509683\n",
      "Episode Reward: 0.0\n",
      "Step 269 (134600) @ Episode 542/10000, loss: 0.00102964253164827824\n",
      "Episode Reward: 2.0\n",
      "Step 208 (134808) @ Episode 543/10000, loss: 0.00056134886108338836\n",
      "Episode Reward: 1.0\n",
      "Step 178 (134986) @ Episode 544/10000, loss: 0.00039164489135146144\n",
      "Episode Reward: 0.0\n",
      "Step 270 (135256) @ Episode 545/10000, loss: 0.00034274172503501177\n",
      "Episode Reward: 2.0\n",
      "Step 282 (135538) @ Episode 546/10000, loss: 0.00022103029186837375\n",
      "Episode Reward: 2.0\n",
      "Step 192 (135730) @ Episode 547/10000, loss: 0.00062767806230112914\n",
      "Episode Reward: 0.0\n",
      "Step 173 (135903) @ Episode 548/10000, loss: 5.250881440588273e-056\n",
      "Episode Reward: 0.0\n",
      "Step 239 (136142) @ Episode 549/10000, loss: 0.00027070171199738984\n",
      "Episode Reward: 1.0\n",
      "Step 370 (136512) @ Episode 550/10000, loss: 0.00028509131516329944\n",
      "Episode Reward: 4.0\n",
      "Step 191 (136703) @ Episode 551/10000, loss: 7.143990660551935e-057\n",
      "Episode Reward: 0.0\n",
      "Step 241 (136944) @ Episode 552/10000, loss: 0.00011311686830595136\n",
      "Episode Reward: 2.0\n",
      "Step 377 (137321) @ Episode 553/10000, loss: 0.00050163967534899716\n",
      "Episode Reward: 4.0\n",
      "Step 217 (137538) @ Episode 554/10000, loss: 0.00072204694151878366\n",
      "Episode Reward: 1.0\n",
      "Step 167 (137705) @ Episode 555/10000, loss: 0.00232189311645925056\n",
      "Episode Reward: 0.0\n",
      "Step 344 (138049) @ Episode 556/10000, loss: 0.00221888907253742233\n",
      "Episode Reward: 3.0\n",
      "Step 270 (138319) @ Episode 557/10000, loss: 0.00231530820019543175\n",
      "Episode Reward: 2.0\n",
      "Step 165 (138484) @ Episode 558/10000, loss: 0.00058158504543825985\n",
      "Episode Reward: 0.0\n",
      "Step 184 (138668) @ Episode 559/10000, loss: 0.00013344263425096875\n",
      "Episode Reward: 0.0\n",
      "Step 261 (138929) @ Episode 560/10000, loss: 0.00313010439276695253\n",
      "Episode Reward: 2.0\n",
      "Step 341 (139270) @ Episode 561/10000, loss: 0.00015762439579702914\n",
      "Episode Reward: 3.0\n",
      "Step 175 (139445) @ Episode 562/10000, loss: 0.00014616097905673087\n",
      "Episode Reward: 0.0\n",
      "Step 187 (139632) @ Episode 563/10000, loss: 0.00013261441199574626\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 435 (140067) @ Episode 564/10000, loss: 0.01093116588890552584\n",
      "Episode Reward: 5.0\n",
      "Step 281 (140348) @ Episode 565/10000, loss: 0.00066695315763354372\n",
      "Episode Reward: 2.0\n",
      "Step 407 (140755) @ Episode 566/10000, loss: 0.00090006156824529173\n",
      "Episode Reward: 4.0\n",
      "Step 277 (141032) @ Episode 567/10000, loss: 0.00082562537863850593\n",
      "Episode Reward: 2.0\n",
      "Step 173 (141205) @ Episode 568/10000, loss: 0.00025212450418621336\n",
      "Episode Reward: 0.0\n",
      "Step 317 (141522) @ Episode 569/10000, loss: 0.00045542709995061165\n",
      "Episode Reward: 3.0\n",
      "Step 211 (141733) @ Episode 570/10000, loss: 4.642140993382782e-053\n",
      "Episode Reward: 1.0\n",
      "Step 172 (141905) @ Episode 571/10000, loss: 0.00014885253040120006\n",
      "Episode Reward: 0.0\n",
      "Step 185 (142090) @ Episode 572/10000, loss: 0.00010206873412244022\n",
      "Episode Reward: 0.0\n",
      "Step 308 (142398) @ Episode 573/10000, loss: 5.873216287000105e-052\n",
      "Episode Reward: 2.0\n",
      "Step 323 (142721) @ Episode 574/10000, loss: 0.00012650698772631586\n",
      "Episode Reward: 3.0\n",
      "Step 179 (142900) @ Episode 575/10000, loss: 3.8110942114144564e-05\n",
      "Episode Reward: 0.0\n",
      "Step 229 (143129) @ Episode 576/10000, loss: 0.00021543877664953477\n",
      "Episode Reward: 1.0\n",
      "Step 166 (143295) @ Episode 577/10000, loss: 0.00059328862698748712\n",
      "Episode Reward: 0.0\n",
      "Step 470 (143765) @ Episode 578/10000, loss: 0.00065158901270478965\n",
      "Episode Reward: 5.0\n",
      "Step 291 (144056) @ Episode 579/10000, loss: 0.00034647074062377214\n",
      "Episode Reward: 2.0\n",
      "Step 299 (144355) @ Episode 580/10000, loss: 0.00011632009409368038\n",
      "Episode Reward: 3.0\n",
      "Step 246 (144601) @ Episode 581/10000, loss: 0.00074012059485539797\n",
      "Episode Reward: 1.0\n",
      "Step 257 (144858) @ Episode 582/10000, loss: 0.00017746936646290123\n",
      "Episode Reward: 2.0\n",
      "Step 174 (145032) @ Episode 583/10000, loss: 0.00014549310435540974\n",
      "Episode Reward: 0.0\n",
      "Step 164 (145196) @ Episode 584/10000, loss: 0.00106924748979508885\n",
      "Episode Reward: 0.0\n",
      "Step 206 (145402) @ Episode 585/10000, loss: 0.00058400817215442667\n",
      "Episode Reward: 1.0\n",
      "Step 168 (145570) @ Episode 586/10000, loss: 0.00015712328604422518\n",
      "Episode Reward: 0.0\n",
      "Step 242 (145812) @ Episode 587/10000, loss: 0.00029521904070861647\n",
      "Episode Reward: 1.0\n",
      "Step 181 (145993) @ Episode 588/10000, loss: 0.00026036892086267477\n",
      "Episode Reward: 0.0\n",
      "Step 251 (146244) @ Episode 589/10000, loss: 6.495854904642329e-055\n",
      "Episode Reward: 1.0\n",
      "Step 169 (146413) @ Episode 590/10000, loss: 0.00047336763236671686\n",
      "Episode Reward: 0.0\n",
      "Step 269 (146682) @ Episode 591/10000, loss: 0.00017896472127176823\n",
      "Episode Reward: 2.0\n",
      "Step 241 (146923) @ Episode 592/10000, loss: 0.00012389311450533573\n",
      "Episode Reward: 1.0\n",
      "Step 178 (147101) @ Episode 593/10000, loss: 0.00055589142721146353\n",
      "Episode Reward: 0.0\n",
      "Step 174 (147275) @ Episode 594/10000, loss: 0.00408189417794346857\n",
      "Episode Reward: 0.0\n",
      "Step 217 (147492) @ Episode 595/10000, loss: 0.00083209708100184826\n",
      "Episode Reward: 1.0\n",
      "Step 237 (147729) @ Episode 596/10000, loss: 7.449353870470077e-054\n",
      "Episode Reward: 1.0\n",
      "Step 351 (148080) @ Episode 597/10000, loss: 0.00049810338532552128\n",
      "Episode Reward: 3.0\n",
      "Step 210 (148290) @ Episode 598/10000, loss: 0.00013618358934763825\n",
      "Episode Reward: 1.0\n",
      "Step 179 (148469) @ Episode 599/10000, loss: 0.00013685091107618064\n",
      "Episode Reward: 0.0\n",
      "Step 340 (148809) @ Episode 600/10000, loss: 4.193749191472307e-055\n",
      "Episode Reward: 3.0\n",
      "Step 336 (149145) @ Episode 601/10000, loss: 4.726579936686903e-059\n",
      "Episode Reward: 3.0\n",
      "Step 181 (149326) @ Episode 602/10000, loss: 0.00029881554655730724\n",
      "Episode Reward: 0.0\n",
      "Step 470 (149796) @ Episode 603/10000, loss: 0.00423092953860759715\n",
      "Episode Reward: 5.0\n",
      "Step 231 (150027) @ Episode 604/10000, loss: 0.00071102980291470895\n",
      "Episode Reward: 1.0\n",
      "Step 244 (150271) @ Episode 605/10000, loss: 6.584738730452955e-055\n",
      "Episode Reward: 1.0\n",
      "Step 285 (150556) @ Episode 606/10000, loss: 0.00021587288938462734\n",
      "Episode Reward: 2.0\n",
      "Step 170 (150726) @ Episode 607/10000, loss: 0.00188659783452749255\n",
      "Episode Reward: 0.0\n",
      "Step 255 (150981) @ Episode 608/10000, loss: 0.00054809974972158677\n",
      "Episode Reward: 1.0\n",
      "Step 181 (151162) @ Episode 609/10000, loss: 0.00021297229977790266\n",
      "Episode Reward: 0.0\n",
      "Step 168 (151330) @ Episode 610/10000, loss: 0.00046455505071207884\n",
      "Episode Reward: 0.0\n",
      "Step 273 (151603) @ Episode 611/10000, loss: 0.00074042507912963634\n",
      "Episode Reward: 2.0\n",
      "Step 239 (151842) @ Episode 612/10000, loss: 0.00022144708782434464\n",
      "Episode Reward: 1.0\n",
      "Step 300 (152142) @ Episode 613/10000, loss: 0.00049051351379603151\n",
      "Episode Reward: 2.0\n",
      "Step 292 (152434) @ Episode 614/10000, loss: 5.858274380443618e-053\n",
      "Episode Reward: 2.0\n",
      "Step 224 (152658) @ Episode 615/10000, loss: 7.269956404343247e-057\n",
      "Episode Reward: 1.0\n",
      "Step 210 (152868) @ Episode 616/10000, loss: 0.00295677990652620856\n",
      "Episode Reward: 1.0\n",
      "Step 202 (153070) @ Episode 617/10000, loss: 0.00043799908598884943\n",
      "Episode Reward: 1.0\n",
      "Step 262 (153332) @ Episode 618/10000, loss: 0.00017112684145104148\n",
      "Episode Reward: 2.0\n",
      "Step 240 (153572) @ Episode 619/10000, loss: 7.783639011904597e-055\n",
      "Episode Reward: 1.0\n",
      "Step 338 (153910) @ Episode 620/10000, loss: 0.00062645110301673417\n",
      "Episode Reward: 3.0\n",
      "Step 178 (154088) @ Episode 621/10000, loss: 0.00020378825138323017\n",
      "Episode Reward: 0.0\n",
      "Step 171 (154259) @ Episode 622/10000, loss: 0.00054197973804548386\n",
      "Episode Reward: 0.0\n",
      "Step 170 (154429) @ Episode 623/10000, loss: 0.00021796653163619344\n",
      "Episode Reward: 0.0\n",
      "Step 178 (154607) @ Episode 624/10000, loss: 5.8709287259262055e-05\n",
      "Episode Reward: 0.0\n",
      "Step 225 (154832) @ Episode 625/10000, loss: 0.00023202304146252573\n",
      "Episode Reward: 1.0\n",
      "Step 236 (155068) @ Episode 626/10000, loss: 0.00012187412357889116\n",
      "Episode Reward: 1.0\n",
      "Step 583 (155651) @ Episode 627/10000, loss: 5.341326323105022e-057\n",
      "Episode Reward: 7.0\n",
      "Step 176 (155827) @ Episode 628/10000, loss: 0.00035147165181115272\n",
      "Episode Reward: 0.0\n",
      "Step 206 (156033) @ Episode 629/10000, loss: 0.00020820720237679785\n",
      "Episode Reward: 1.0\n",
      "Step 179 (156212) @ Episode 630/10000, loss: 0.00142775091808289332\n",
      "Episode Reward: 0.0\n",
      "Step 275 (156487) @ Episode 631/10000, loss: 5.006288120057434e-052\n",
      "Episode Reward: 1.0\n",
      "Step 244 (156731) @ Episode 632/10000, loss: 8.70406292960979e-0575\n",
      "Episode Reward: 2.0\n",
      "Step 238 (156969) @ Episode 633/10000, loss: 0.00033217918826267123\n",
      "Episode Reward: 1.0\n",
      "Step 303 (157272) @ Episode 634/10000, loss: 8.786792022874579e-058\n",
      "Episode Reward: 2.0\n",
      "Step 179 (157451) @ Episode 635/10000, loss: 0.00010375068086432293\n",
      "Episode Reward: 0.0\n",
      "Step 178 (157629) @ Episode 636/10000, loss: 0.00069232273381203414\n",
      "Episode Reward: 0.0\n",
      "Step 366 (157995) @ Episode 637/10000, loss: 7.131513848435134e-052\n",
      "Episode Reward: 3.0\n",
      "Step 264 (158259) @ Episode 638/10000, loss: 0.00142621877603232866\n",
      "Episode Reward: 2.0\n",
      "Step 291 (158550) @ Episode 639/10000, loss: 0.00023745567887090147\n",
      "Episode Reward: 2.0\n",
      "Step 181 (158731) @ Episode 640/10000, loss: 0.00065111403819173575\n",
      "Episode Reward: 0.0\n",
      "Step 253 (158984) @ Episode 641/10000, loss: 0.00047555618220940235\n",
      "Episode Reward: 1.0\n",
      "Step 313 (159297) @ Episode 642/10000, loss: 0.00016481382772326474\n",
      "Episode Reward: 3.0\n",
      "Step 328 (159625) @ Episode 643/10000, loss: 0.00018201614147983491\n",
      "Episode Reward: 3.0\n",
      "Step 292 (159917) @ Episode 644/10000, loss: 0.00053319777362048635\n",
      "Episode Reward: 2.0\n",
      "Step 199 (160116) @ Episode 645/10000, loss: 0.00071720266714692122\n",
      "Episode Reward: 0.0\n",
      "Step 259 (160375) @ Episode 646/10000, loss: 0.00041163232526741925\n",
      "Episode Reward: 2.0\n",
      "Step 219 (160594) @ Episode 647/10000, loss: 0.00044509139843285084\n",
      "Episode Reward: 1.0\n",
      "Step 273 (160867) @ Episode 648/10000, loss: 0.00143875298090279155\n",
      "Episode Reward: 2.0\n",
      "Step 187 (161054) @ Episode 649/10000, loss: 0.00033107941271737226\n",
      "Episode Reward: 0.0\n",
      "Step 353 (161407) @ Episode 650/10000, loss: 0.00020393996965140104\n",
      "Episode Reward: 3.0\n",
      "Step 379 (161786) @ Episode 651/10000, loss: 6.65662664687261e-0555\n",
      "Episode Reward: 4.0\n",
      "Step 181 (161967) @ Episode 652/10000, loss: 0.00045474563376046717\n",
      "Episode Reward: 0.0\n",
      "Step 201 (162168) @ Episode 653/10000, loss: 0.00025137097691185775\n",
      "Episode Reward: 0.0\n",
      "Step 192 (162360) @ Episode 654/10000, loss: 0.00314002251252532123\n",
      "Episode Reward: 0.0\n",
      "Step 167 (162527) @ Episode 655/10000, loss: 0.00010328229109290987\n",
      "Episode Reward: 0.0\n",
      "Step 214 (162741) @ Episode 656/10000, loss: 0.00010047118121292442\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 163 (162904) @ Episode 657/10000, loss: 0.00065735582029446965\n",
      "Episode Reward: 0.0\n",
      "Step 173 (163077) @ Episode 658/10000, loss: 0.00024130381643772125\n",
      "Episode Reward: 0.0\n",
      "Step 236 (163313) @ Episode 659/10000, loss: 0.00047097413334995511\n",
      "Episode Reward: 1.0\n",
      "Step 231 (163544) @ Episode 660/10000, loss: 0.00033195805735886097\n",
      "Episode Reward: 1.0\n",
      "Step 213 (163757) @ Episode 661/10000, loss: 0.00049826328177005055\n",
      "Episode Reward: 1.0\n",
      "Step 235 (163992) @ Episode 662/10000, loss: 0.00025834154803305864\n",
      "Episode Reward: 1.0\n",
      "Step 218 (164210) @ Episode 663/10000, loss: 0.00044466875260695815\n",
      "Episode Reward: 1.0\n",
      "Step 444 (164654) @ Episode 664/10000, loss: 0.00038593274075537922\n",
      "Episode Reward: 5.0\n",
      "Step 331 (164985) @ Episode 665/10000, loss: 0.00018194282893091442\n",
      "Episode Reward: 3.0\n",
      "Step 383 (165368) @ Episode 666/10000, loss: 0.00080100749619305132\n",
      "Episode Reward: 3.0\n",
      "Step 169 (165537) @ Episode 667/10000, loss: 0.00150854547973722223\n",
      "Episode Reward: 0.0\n",
      "Step 240 (165777) @ Episode 668/10000, loss: 0.00024122699687723073\n",
      "Episode Reward: 1.0\n",
      "Step 166 (165943) @ Episode 669/10000, loss: 0.00035959284286946066\n",
      "Episode Reward: 0.0\n",
      "Step 185 (166128) @ Episode 670/10000, loss: 0.00112875911872833975\n",
      "Episode Reward: 0.0\n",
      "Step 205 (166333) @ Episode 671/10000, loss: 0.00021003567962907255\n",
      "Episode Reward: 1.0\n",
      "Step 239 (166572) @ Episode 672/10000, loss: 0.00137480511330068117\n",
      "Episode Reward: 1.0\n",
      "Step 174 (166746) @ Episode 673/10000, loss: 0.00105781434103846555\n",
      "Episode Reward: 0.0\n",
      "Step 177 (166923) @ Episode 674/10000, loss: 0.00033840778633020822\n",
      "Episode Reward: 0.0\n",
      "Step 253 (167176) @ Episode 675/10000, loss: 0.00024981261231005194\n",
      "Episode Reward: 1.0\n",
      "Step 273 (167449) @ Episode 676/10000, loss: 0.00083112291758880025\n",
      "Episode Reward: 2.0\n",
      "Step 223 (167672) @ Episode 677/10000, loss: 0.00023636291734874249\n",
      "Episode Reward: 1.0\n",
      "Step 271 (167943) @ Episode 678/10000, loss: 0.00152397202327847482\n",
      "Episode Reward: 2.0\n",
      "Step 210 (168153) @ Episode 679/10000, loss: 0.00021245001698844135\n",
      "Episode Reward: 1.0\n",
      "Step 180 (168333) @ Episode 680/10000, loss: 0.00183640513569116628\n",
      "Episode Reward: 0.0\n",
      "Step 177 (168510) @ Episode 681/10000, loss: 0.00300775468349456803\n",
      "Episode Reward: 0.0\n",
      "Step 243 (168753) @ Episode 682/10000, loss: 0.00061231903964653615\n",
      "Episode Reward: 1.0\n",
      "Step 180 (168933) @ Episode 683/10000, loss: 6.463837053161114e-057\n",
      "Episode Reward: 0.0\n",
      "Step 163 (169096) @ Episode 684/10000, loss: 0.00016241722914855927\n",
      "Episode Reward: 0.0\n",
      "Step 212 (169308) @ Episode 685/10000, loss: 0.00369204324670135974\n",
      "Episode Reward: 1.0\n",
      "Step 247 (169555) @ Episode 686/10000, loss: 0.00061130849644541747\n",
      "Episode Reward: 1.0\n",
      "Step 232 (169787) @ Episode 687/10000, loss: 0.00024951636441983287\n",
      "Episode Reward: 1.0\n",
      "Step 329 (170116) @ Episode 688/10000, loss: 0.00080032343976199633\n",
      "Episode Reward: 3.0\n",
      "Step 182 (170298) @ Episode 689/10000, loss: 0.00101211457513272768\n",
      "Episode Reward: 0.0\n",
      "Step 253 (170551) @ Episode 690/10000, loss: 0.00199001817964017476\n",
      "Episode Reward: 1.0\n",
      "Step 286 (170837) @ Episode 691/10000, loss: 0.00084546062862500553\n",
      "Episode Reward: 2.0\n",
      "Step 237 (171074) @ Episode 692/10000, loss: 0.00154701084829866896\n",
      "Episode Reward: 1.0\n",
      "Step 222 (171296) @ Episode 693/10000, loss: 0.00140750792343169454\n",
      "Episode Reward: 1.0\n",
      "Step 191 (171487) @ Episode 694/10000, loss: 0.00562482327222824193\n",
      "Episode Reward: 0.0\n",
      "Step 229 (171716) @ Episode 695/10000, loss: 0.00029759638709947467\n",
      "Episode Reward: 1.0\n",
      "Step 195 (171911) @ Episode 696/10000, loss: 0.00025345585891045635\n",
      "Episode Reward: 0.0\n",
      "Step 170 (172081) @ Episode 697/10000, loss: 5.819485159008764e-056\n",
      "Episode Reward: 0.0\n",
      "Step 187 (172268) @ Episode 698/10000, loss: 0.00071826035855337987\n",
      "Episode Reward: 0.0\n",
      "Step 178 (172446) @ Episode 699/10000, loss: 0.00072435097536072132\n",
      "Episode Reward: 0.0\n",
      "Step 302 (172748) @ Episode 700/10000, loss: 0.00246820785105228426\n",
      "Episode Reward: 2.0\n",
      "Step 346 (173094) @ Episode 701/10000, loss: 0.00014853569155093282\n",
      "Episode Reward: 3.0\n",
      "Step 192 (173286) @ Episode 702/10000, loss: 0.00027026515454053887\n",
      "Episode Reward: 0.0\n",
      "Step 163 (173449) @ Episode 703/10000, loss: 0.00090778263984248043\n",
      "Episode Reward: 0.0\n",
      "Step 351 (173800) @ Episode 704/10000, loss: 0.00127275695558637386\n",
      "Episode Reward: 3.0\n",
      "Step 369 (174169) @ Episode 705/10000, loss: 6.297043728409335e-056\n",
      "Episode Reward: 3.0\n",
      "Step 208 (174377) @ Episode 706/10000, loss: 0.00190078525338321926\n",
      "Episode Reward: 1.0\n",
      "Step 332 (174709) @ Episode 707/10000, loss: 0.00020883719844277948\n",
      "Episode Reward: 3.0\n",
      "Step 238 (174947) @ Episode 708/10000, loss: 0.00031260726973414425\n",
      "Episode Reward: 1.0\n",
      "Step 306 (175253) @ Episode 709/10000, loss: 0.00044597475789487365\n",
      "Episode Reward: 2.0\n",
      "Step 231 (175484) @ Episode 710/10000, loss: 0.00102115550544112926\n",
      "Episode Reward: 1.0\n",
      "Step 193 (175677) @ Episode 711/10000, loss: 0.00029921036912128332\n",
      "Episode Reward: 0.0\n",
      "Step 183 (175860) @ Episode 712/10000, loss: 0.00087631697533652194\n",
      "Episode Reward: 0.0\n",
      "Step 250 (176110) @ Episode 713/10000, loss: 0.00019027740927413106\n",
      "Episode Reward: 1.0\n",
      "Step 207 (176317) @ Episode 714/10000, loss: 0.00032820232445374134\n",
      "Episode Reward: 1.0\n",
      "Step 230 (176547) @ Episode 715/10000, loss: 0.00020101202244404703\n",
      "Episode Reward: 1.0\n",
      "Step 237 (176784) @ Episode 716/10000, loss: 0.00011664476187434047\n",
      "Episode Reward: 1.0\n",
      "Step 353 (177137) @ Episode 717/10000, loss: 0.00033907688339240857\n",
      "Episode Reward: 4.0\n",
      "Step 242 (177379) @ Episode 718/10000, loss: 0.00031242883414961435\n",
      "Episode Reward: 1.0\n",
      "Step 236 (177615) @ Episode 719/10000, loss: 0.00042999762808904055\n",
      "Episode Reward: 1.0\n",
      "Step 177 (177792) @ Episode 720/10000, loss: 0.00020833383314311504\n",
      "Episode Reward: 0.0\n",
      "Step 174 (177966) @ Episode 721/10000, loss: 0.00017516374646220356\n",
      "Episode Reward: 0.0\n",
      "Step 231 (178197) @ Episode 722/10000, loss: 0.00079866178566589958\n",
      "Episode Reward: 1.0\n",
      "Step 355 (178552) @ Episode 723/10000, loss: 0.00104450306389480836\n",
      "Episode Reward: 3.0\n",
      "Step 210 (178762) @ Episode 724/10000, loss: 0.00010888202814385295\n",
      "Episode Reward: 1.0\n",
      "Step 233 (178995) @ Episode 725/10000, loss: 0.00047529075527563694\n",
      "Episode Reward: 1.0\n",
      "Step 204 (179199) @ Episode 726/10000, loss: 0.00012264013639651246\n",
      "Episode Reward: 1.0\n",
      "Step 371 (179570) @ Episode 727/10000, loss: 0.00024202093482017517\n",
      "Episode Reward: 4.0\n",
      "Step 232 (179802) @ Episode 728/10000, loss: 5.259850877337158e-056\n",
      "Episode Reward: 1.0\n",
      "Step 234 (180036) @ Episode 729/10000, loss: 0.00080218550283461817\n",
      "Episode Reward: 1.0\n",
      "Step 214 (180250) @ Episode 730/10000, loss: 0.00023006048286333686\n",
      "Episode Reward: 1.0\n",
      "Step 193 (180443) @ Episode 731/10000, loss: 6.682638922939077e-051\n",
      "Episode Reward: 0.0\n",
      "Step 256 (180699) @ Episode 732/10000, loss: 0.00090171169722452765\n",
      "Episode Reward: 2.0\n",
      "Step 234 (180933) @ Episode 733/10000, loss: 0.00037544174119830136\n",
      "Episode Reward: 1.0\n",
      "Step 219 (181152) @ Episode 734/10000, loss: 0.00011700752656906843\n",
      "Episode Reward: 1.0\n",
      "Step 261 (181413) @ Episode 735/10000, loss: 0.00039129657670855525\n",
      "Episode Reward: 2.0\n",
      "Step 266 (181679) @ Episode 736/10000, loss: 0.00071394420228898535\n",
      "Episode Reward: 2.0\n",
      "Step 224 (181903) @ Episode 737/10000, loss: 0.00090254499809816486\n",
      "Episode Reward: 1.0\n",
      "Step 244 (182147) @ Episode 738/10000, loss: 0.00033335026819258937\n",
      "Episode Reward: 1.0\n",
      "Step 291 (182438) @ Episode 739/10000, loss: 0.00012958105071447797\n",
      "Episode Reward: 2.0\n",
      "Step 188 (182626) @ Episode 740/10000, loss: 0.00010116466728504747\n",
      "Episode Reward: 0.0\n",
      "Step 179 (182805) @ Episode 741/10000, loss: 0.00175304734148085127\n",
      "Episode Reward: 0.0\n",
      "Step 175 (182980) @ Episode 742/10000, loss: 0.00012469649664126337\n",
      "Episode Reward: 0.0\n",
      "Step 194 (183174) @ Episode 743/10000, loss: 0.00120354851242154845\n",
      "Episode Reward: 0.0\n",
      "Step 220 (183394) @ Episode 744/10000, loss: 0.00018252129666507244\n",
      "Episode Reward: 1.0\n",
      "Step 302 (183696) @ Episode 745/10000, loss: 0.00125714926980435854\n",
      "Episode Reward: 2.0\n",
      "Step 172 (183868) @ Episode 746/10000, loss: 0.00034875023993663496\n",
      "Episode Reward: 0.0\n",
      "Step 174 (184042) @ Episode 747/10000, loss: 0.00046324462164193398\n",
      "Episode Reward: 0.0\n",
      "Step 166 (184208) @ Episode 748/10000, loss: 0.00041569874156266458\n",
      "Episode Reward: 0.0\n",
      "Step 229 (184437) @ Episode 749/10000, loss: 7.459939661202952e-057\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 227 (184664) @ Episode 750/10000, loss: 0.00017433428729418665\n",
      "Episode Reward: 1.0\n",
      "Step 253 (184917) @ Episode 751/10000, loss: 0.00025478345924057066\n",
      "Episode Reward: 2.0\n",
      "Step 231 (185148) @ Episode 752/10000, loss: 8.797793998382986e-053\n",
      "Episode Reward: 1.0\n",
      "Step 253 (185401) @ Episode 753/10000, loss: 0.00216341810300946246\n",
      "Episode Reward: 2.0\n",
      "Step 383 (185784) @ Episode 754/10000, loss: 3.8204871088964865e-05\n",
      "Episode Reward: 4.0\n",
      "Step 302 (186086) @ Episode 755/10000, loss: 0.00122876686509698632\n",
      "Episode Reward: 2.0\n",
      "Step 172 (186258) @ Episode 756/10000, loss: 0.00310863275080919278\n",
      "Episode Reward: 0.0\n",
      "Step 235 (186493) @ Episode 757/10000, loss: 0.00081572355702519423\n",
      "Episode Reward: 1.0\n",
      "Step 235 (186728) @ Episode 758/10000, loss: 9.671870793681592e-053\n",
      "Episode Reward: 1.0\n",
      "Step 302 (187030) @ Episode 759/10000, loss: 0.00065891997655853633\n",
      "Episode Reward: 3.0\n",
      "Step 280 (187310) @ Episode 760/10000, loss: 0.00166765437461435874\n",
      "Episode Reward: 2.0\n",
      "Step 214 (187524) @ Episode 761/10000, loss: 0.00049354496877640492\n",
      "Episode Reward: 1.0\n",
      "Step 236 (187760) @ Episode 762/10000, loss: 0.00046460938756354153\n",
      "Episode Reward: 1.0\n",
      "Step 180 (187940) @ Episode 763/10000, loss: 0.00056323828175663954\n",
      "Episode Reward: 0.0\n",
      "Step 184 (188124) @ Episode 764/10000, loss: 0.00027094077086076143\n",
      "Episode Reward: 0.0\n",
      "Step 210 (188334) @ Episode 765/10000, loss: 0.00058354408247396353\n",
      "Episode Reward: 1.0\n",
      "Step 208 (188542) @ Episode 766/10000, loss: 0.00034329164191149175\n",
      "Episode Reward: 1.0\n",
      "Step 312 (188854) @ Episode 767/10000, loss: 0.00032617099350318316\n",
      "Episode Reward: 2.0\n",
      "Step 340 (189194) @ Episode 768/10000, loss: 0.00034174404572695494\n",
      "Episode Reward: 3.0\n",
      "Step 174 (189368) @ Episode 769/10000, loss: 0.00028240052051842215\n",
      "Episode Reward: 0.0\n",
      "Step 225 (189593) @ Episode 770/10000, loss: 0.00076335755875334146\n",
      "Episode Reward: 1.0\n",
      "Step 179 (189772) @ Episode 771/10000, loss: 0.00022185087436810136\n",
      "Episode Reward: 0.0\n",
      "Step 477 (190249) @ Episode 772/10000, loss: 0.00072959926910698415\n",
      "Episode Reward: 5.0\n",
      "Step 176 (190425) @ Episode 773/10000, loss: 0.00050946895498782442\n",
      "Episode Reward: 0.0\n",
      "Step 165 (190590) @ Episode 774/10000, loss: 0.00236832676455378535\n",
      "Episode Reward: 0.0\n",
      "Step 181 (190771) @ Episode 775/10000, loss: 0.00084643927402794362\n",
      "Episode Reward: 0.0\n",
      "Step 223 (190994) @ Episode 776/10000, loss: 0.00036990342778153725\n",
      "Episode Reward: 1.0\n",
      "Step 305 (191299) @ Episode 777/10000, loss: 0.00107430340722203256\n",
      "Episode Reward: 2.0\n",
      "Step 200 (191499) @ Episode 778/10000, loss: 6.770670734113082e-055\n",
      "Episode Reward: 0.0\n",
      "Step 313 (191812) @ Episode 779/10000, loss: 0.00166558509226888425\n",
      "Episode Reward: 3.0\n",
      "Step 171 (191983) @ Episode 780/10000, loss: 0.00014112780627328902\n",
      "Episode Reward: 0.0\n",
      "Step 257 (192240) @ Episode 781/10000, loss: 0.00058083538897335535\n",
      "Episode Reward: 2.0\n",
      "Step 229 (192469) @ Episode 782/10000, loss: 0.00090238777920603756\n",
      "Episode Reward: 1.0\n",
      "Step 295 (192764) @ Episode 783/10000, loss: 2.5005479983519763e-05\n",
      "Episode Reward: 2.0\n",
      "Step 315 (193079) @ Episode 784/10000, loss: 0.00079487485345453028\n",
      "Episode Reward: 3.0\n",
      "Step 301 (193380) @ Episode 785/10000, loss: 0.00024287603446282446\n",
      "Episode Reward: 2.0\n",
      "Step 174 (193554) @ Episode 786/10000, loss: 0.00048294279258698225\n",
      "Episode Reward: 0.0\n",
      "Step 238 (193792) @ Episode 787/10000, loss: 0.00013379380106925964\n",
      "Episode Reward: 1.0\n",
      "Step 381 (194173) @ Episode 788/10000, loss: 6.982388003962114e-058\n",
      "Episode Reward: 4.0\n",
      "Step 206 (194379) @ Episode 789/10000, loss: 0.00014488355373032398\n",
      "Episode Reward: 1.0\n",
      "Step 180 (194559) @ Episode 790/10000, loss: 0.00013091169239487553\n",
      "Episode Reward: 0.0\n",
      "Step 185 (194744) @ Episode 791/10000, loss: 0.00040605917456559837\n",
      "Episode Reward: 0.0\n",
      "Step 240 (194984) @ Episode 792/10000, loss: 0.00289453053846955337\n",
      "Episode Reward: 1.0\n",
      "Step 313 (195297) @ Episode 793/10000, loss: 0.00035237803240306675\n",
      "Episode Reward: 3.0\n",
      "Step 334 (195631) @ Episode 794/10000, loss: 0.00032202884904108943\n",
      "Episode Reward: 3.0\n",
      "Step 213 (195844) @ Episode 795/10000, loss: 6.618344195885584e-054\n",
      "Episode Reward: 1.0\n",
      "Step 183 (196027) @ Episode 796/10000, loss: 0.00042690799455158415\n",
      "Episode Reward: 0.0\n",
      "Step 227 (196254) @ Episode 797/10000, loss: 6.284724076977e-058755\n",
      "Episode Reward: 1.0\n",
      "Step 244 (196498) @ Episode 798/10000, loss: 0.00267447880469262657\n",
      "Episode Reward: 1.0\n",
      "Step 250 (196748) @ Episode 799/10000, loss: 8.98480648174882e-0526\n",
      "Episode Reward: 1.0\n",
      "Step 224 (196972) @ Episode 800/10000, loss: 0.00016535252507310365\n",
      "Episode Reward: 1.0\n",
      "Step 240 (197212) @ Episode 801/10000, loss: 0.00011819296196335927\n",
      "Episode Reward: 1.0\n",
      "Step 324 (197536) @ Episode 802/10000, loss: 0.00013459447654895484\n",
      "Episode Reward: 3.0\n",
      "Step 406 (197942) @ Episode 803/10000, loss: 0.00076357671059668065\n",
      "Episode Reward: 4.0\n",
      "Step 185 (198127) @ Episode 804/10000, loss: 8.330824493896216e-054\n",
      "Episode Reward: 0.0\n",
      "Step 168 (198295) @ Episode 805/10000, loss: 6.082531763240695e-053\n",
      "Episode Reward: 0.0\n",
      "Step 171 (198466) @ Episode 806/10000, loss: 0.00016710186901036655\n",
      "Episode Reward: 0.0\n",
      "Step 335 (198801) @ Episode 807/10000, loss: 0.00094177591381594546\n",
      "Episode Reward: 3.0\n",
      "Step 215 (199016) @ Episode 808/10000, loss: 7.865013321861625e-057\n",
      "Episode Reward: 1.0\n",
      "Step 168 (199184) @ Episode 809/10000, loss: 0.00013936994946561754\n",
      "Episode Reward: 0.0\n",
      "Step 292 (199476) @ Episode 810/10000, loss: 0.00019671084010042254\n",
      "Episode Reward: 2.0\n",
      "Step 175 (199651) @ Episode 811/10000, loss: 0.00020929294987581675\n",
      "Episode Reward: 0.0\n",
      "Step 217 (199868) @ Episode 812/10000, loss: 0.00010514917084947228\n",
      "Episode Reward: 1.0\n",
      "Step 169 (200037) @ Episode 813/10000, loss: 0.00026150053599849343\n",
      "Episode Reward: 0.0\n",
      "Step 343 (200380) @ Episode 814/10000, loss: 0.00080762675497680913\n",
      "Episode Reward: 3.0\n",
      "Step 277 (200657) @ Episode 815/10000, loss: 0.00012144011270720512\n",
      "Episode Reward: 2.0\n",
      "Step 234 (200891) @ Episode 816/10000, loss: 0.00015144018107093876\n",
      "Episode Reward: 1.0\n",
      "Step 180 (201071) @ Episode 817/10000, loss: 0.00032170716440305114\n",
      "Episode Reward: 0.0\n",
      "Step 360 (201431) @ Episode 818/10000, loss: 0.00052459910511970524\n",
      "Episode Reward: 3.0\n",
      "Step 177 (201608) @ Episode 819/10000, loss: 0.00106389424763619956\n",
      "Episode Reward: 0.0\n",
      "Step 289 (201897) @ Episode 820/10000, loss: 0.00038300376036204444\n",
      "Episode Reward: 2.0\n",
      "Step 165 (202062) @ Episode 821/10000, loss: 0.00085374509217217568\n",
      "Episode Reward: 0.0\n",
      "Step 242 (202304) @ Episode 822/10000, loss: 0.00023358661564998334\n",
      "Episode Reward: 1.0\n",
      "Step 173 (202477) @ Episode 823/10000, loss: 0.00145533378235995778\n",
      "Episode Reward: 0.0\n",
      "Step 303 (202780) @ Episode 824/10000, loss: 0.00230117724277079135\n",
      "Episode Reward: 2.0\n",
      "Step 176 (202956) @ Episode 825/10000, loss: 0.00085417029913514853\n",
      "Episode Reward: 0.0\n",
      "Step 291 (203247) @ Episode 826/10000, loss: 0.00065983121749013663\n",
      "Episode Reward: 2.0\n",
      "Step 347 (203594) @ Episode 827/10000, loss: 0.00037770799826830626\n",
      "Episode Reward: 3.0\n",
      "Step 224 (203818) @ Episode 828/10000, loss: 0.00038302346365526324\n",
      "Episode Reward: 1.0\n",
      "Step 272 (204090) @ Episode 829/10000, loss: 0.00016227763262577355\n",
      "Episode Reward: 2.0\n",
      "Step 283 (204373) @ Episode 830/10000, loss: 7.204373105196282e-058\n",
      "Episode Reward: 2.0\n",
      "Step 236 (204609) @ Episode 831/10000, loss: 0.00034641305683180697\n",
      "Episode Reward: 1.0\n",
      "Step 256 (204865) @ Episode 832/10000, loss: 6.051359014236368e-056\n",
      "Episode Reward: 1.0\n",
      "Step 189 (205054) @ Episode 833/10000, loss: 0.00021663799998350441\n",
      "Episode Reward: 0.0\n",
      "Step 275 (205329) @ Episode 834/10000, loss: 0.00012976874131709337\n",
      "Episode Reward: 2.0\n",
      "Step 231 (205560) @ Episode 835/10000, loss: 0.00037887867074459796\n",
      "Episode Reward: 1.0\n",
      "Step 162 (205722) @ Episode 836/10000, loss: 0.00100311555434018376\n",
      "Episode Reward: 0.0\n",
      "Step 477 (206199) @ Episode 837/10000, loss: 0.00081207533366978173\n",
      "Episode Reward: 5.0\n",
      "Step 233 (206432) @ Episode 838/10000, loss: 0.00039594850386492915\n",
      "Episode Reward: 1.0\n",
      "Step 335 (206767) @ Episode 839/10000, loss: 5.257555312709883e-057\n",
      "Episode Reward: 3.0\n",
      "Step 304 (207071) @ Episode 840/10000, loss: 0.00231353426352143323\n",
      "Episode Reward: 2.0\n",
      "Step 173 (207244) @ Episode 841/10000, loss: 0.00043112755520269275\n",
      "Episode Reward: 0.0\n",
      "Step 197 (207441) @ Episode 842/10000, loss: 0.00021742212993558496\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 171 (207612) @ Episode 843/10000, loss: 0.00075507839210331443\n",
      "Episode Reward: 0.0\n",
      "Step 244 (207856) @ Episode 844/10000, loss: 6.871018558740616e-053\n",
      "Episode Reward: 1.0\n",
      "Step 180 (208036) @ Episode 845/10000, loss: 0.00046178349293768406\n",
      "Episode Reward: 0.0\n",
      "Step 355 (208391) @ Episode 846/10000, loss: 0.00012340172543190425\n",
      "Episode Reward: 3.0\n",
      "Step 163 (208554) @ Episode 847/10000, loss: 0.00028684452991001315\n",
      "Episode Reward: 0.0\n",
      "Step 176 (208730) @ Episode 848/10000, loss: 0.00015308283036574724\n",
      "Episode Reward: 0.0\n",
      "Step 173 (208903) @ Episode 849/10000, loss: 0.00049721123650670051\n",
      "Episode Reward: 0.0\n",
      "Step 183 (209086) @ Episode 850/10000, loss: 0.00036804398405365646\n",
      "Episode Reward: 0.0\n",
      "Step 178 (209264) @ Episode 851/10000, loss: 0.00011509993055369705\n",
      "Episode Reward: 0.0\n",
      "Step 506 (209770) @ Episode 852/10000, loss: 0.00090447824914008386\n",
      "Episode Reward: 6.0\n",
      "Step 171 (209941) @ Episode 853/10000, loss: 0.00036188319791108374\n",
      "Episode Reward: 0.0\n",
      "Step 171 (210112) @ Episode 854/10000, loss: 0.00104028172791004187\n",
      "Episode Reward: 0.0\n",
      "Step 232 (210344) @ Episode 855/10000, loss: 0.00089157978072762498\n",
      "Episode Reward: 1.0\n",
      "Step 236 (210580) @ Episode 856/10000, loss: 0.00089519727043807512\n",
      "Episode Reward: 1.0\n",
      "Step 179 (210759) @ Episode 857/10000, loss: 0.00032734283013269305\n",
      "Episode Reward: 0.0\n",
      "Step 305 (211064) @ Episode 858/10000, loss: 0.00012588793470058594\n",
      "Episode Reward: 2.0\n",
      "Step 449 (211513) @ Episode 859/10000, loss: 0.00045541959116235375\n",
      "Episode Reward: 5.0\n",
      "Step 257 (211770) @ Episode 860/10000, loss: 0.00020659950678236783\n",
      "Episode Reward: 1.0\n",
      "Step 303 (212073) @ Episode 861/10000, loss: 0.00029150833142921334\n",
      "Episode Reward: 3.0\n",
      "Step 322 (212395) @ Episode 862/10000, loss: 0.00041252499795518816\n",
      "Episode Reward: 3.0\n",
      "Step 255 (212650) @ Episode 863/10000, loss: 6.322150147752836e-053\n",
      "Episode Reward: 1.0\n",
      "Step 186 (212836) @ Episode 864/10000, loss: 0.00017917787772603333\n",
      "Episode Reward: 0.0\n",
      "Step 201 (213037) @ Episode 865/10000, loss: 0.00012269087892491377\n",
      "Episode Reward: 1.0\n",
      "Step 175 (213212) @ Episode 866/10000, loss: 6.090967508498579e-058\n",
      "Episode Reward: 0.0\n",
      "Step 178 (213390) @ Episode 867/10000, loss: 0.00016818667063489556\n",
      "Episode Reward: 0.0\n",
      "Step 237 (213627) @ Episode 868/10000, loss: 0.00015575760335195815\n",
      "Episode Reward: 1.0\n",
      "Step 175 (213802) @ Episode 869/10000, loss: 0.00010636779188644141\n",
      "Episode Reward: 0.0\n",
      "Step 231 (214033) @ Episode 870/10000, loss: 0.00035489856963977226\n",
      "Episode Reward: 1.0\n",
      "Step 405 (214438) @ Episode 871/10000, loss: 0.00036090382491238415\n",
      "Episode Reward: 4.0\n",
      "Step 181 (214619) @ Episode 872/10000, loss: 0.00033040565904229883\n",
      "Episode Reward: 0.0\n",
      "Step 308 (214927) @ Episode 873/10000, loss: 0.00015710950538050383\n",
      "Episode Reward: 2.0\n",
      "Step 297 (215224) @ Episode 874/10000, loss: 0.00030741351656615734\n",
      "Episode Reward: 2.0\n",
      "Step 316 (215540) @ Episode 875/10000, loss: 5.2624542149715126e-05\n",
      "Episode Reward: 3.0\n",
      "Step 313 (215853) @ Episode 876/10000, loss: 0.00021538746659643948\n",
      "Episode Reward: 2.0\n",
      "Step 171 (216024) @ Episode 877/10000, loss: 0.00037308118771761656\n",
      "Episode Reward: 0.0\n",
      "Step 285 (216309) @ Episode 878/10000, loss: 0.00010232756176264957\n",
      "Episode Reward: 2.0\n",
      "Step 282 (216591) @ Episode 879/10000, loss: 0.00089728593593463318\n",
      "Episode Reward: 2.0\n",
      "Step 231 (216822) @ Episode 880/10000, loss: 0.00022232298215385526\n",
      "Episode Reward: 1.0\n",
      "Step 252 (217074) @ Episode 881/10000, loss: 0.00011655253911158073\n",
      "Episode Reward: 1.0\n",
      "Step 266 (217340) @ Episode 882/10000, loss: 6.127849337644875e-057\n",
      "Episode Reward: 1.0\n",
      "Step 245 (217585) @ Episode 883/10000, loss: 0.00027495669201016426\n",
      "Episode Reward: 1.0\n",
      "Step 174 (217759) @ Episode 884/10000, loss: 0.00097698695026338128\n",
      "Episode Reward: 0.0\n",
      "Step 245 (218004) @ Episode 885/10000, loss: 0.00022971010184846818\n",
      "Episode Reward: 1.0\n",
      "Step 361 (218365) @ Episode 886/10000, loss: 0.00010624276183079928\n",
      "Episode Reward: 3.0\n",
      "Step 208 (218573) @ Episode 887/10000, loss: 0.00034670581226237121\n",
      "Episode Reward: 1.0\n",
      "Step 223 (218796) @ Episode 888/10000, loss: 0.00028745870804414153\n",
      "Episode Reward: 1.0\n",
      "Step 337 (219133) @ Episode 889/10000, loss: 0.00010150372690986842\n",
      "Episode Reward: 3.0\n",
      "Step 195 (219328) @ Episode 890/10000, loss: 2.8403599571902305e-05\n",
      "Episode Reward: 0.0\n",
      "Step 272 (219600) @ Episode 891/10000, loss: 0.00146568450145423417\n",
      "Episode Reward: 2.0\n",
      "Step 250 (219850) @ Episode 892/10000, loss: 6.704810948576778e-057\n",
      "Episode Reward: 1.0\n",
      "Step 398 (220248) @ Episode 893/10000, loss: 0.00058018072741106153\n",
      "Episode Reward: 4.0\n",
      "Step 243 (220491) @ Episode 894/10000, loss: 0.00071206362918019357\n",
      "Episode Reward: 1.0\n",
      "Step 232 (220723) @ Episode 895/10000, loss: 0.00013331710943020887\n",
      "Episode Reward: 1.0\n",
      "Step 208 (220931) @ Episode 896/10000, loss: 0.00017313359421677887\n",
      "Episode Reward: 1.0\n",
      "Step 212 (221143) @ Episode 897/10000, loss: 0.00030813302146270877\n",
      "Episode Reward: 1.0\n",
      "Step 271 (221414) @ Episode 898/10000, loss: 0.00112392799928784377\n",
      "Episode Reward: 2.0\n",
      "Step 183 (221597) @ Episode 899/10000, loss: 7.346048369072378e-056\n",
      "Episode Reward: 0.0\n",
      "Step 185 (221782) @ Episode 900/10000, loss: 0.00133403576910495764\n",
      "Episode Reward: 0.0\n",
      "Step 193 (221975) @ Episode 901/10000, loss: 0.00015064413310028613\n",
      "Episode Reward: 0.0\n",
      "Step 176 (222151) @ Episode 902/10000, loss: 0.00113853323273360735\n",
      "Episode Reward: 0.0\n",
      "Step 267 (222418) @ Episode 903/10000, loss: 0.00039569931686855853\n",
      "Episode Reward: 1.0\n",
      "Step 232 (222650) @ Episode 904/10000, loss: 9.939628944266587e-057\n",
      "Episode Reward: 1.0\n",
      "Step 180 (222830) @ Episode 905/10000, loss: 5.052308188169263e-054\n",
      "Episode Reward: 0.0\n",
      "Step 304 (223134) @ Episode 906/10000, loss: 0.00033145409543067217\n",
      "Episode Reward: 2.0\n",
      "Step 193 (223327) @ Episode 907/10000, loss: 0.00049681187374517328\n",
      "Episode Reward: 0.0\n",
      "Step 298 (223625) @ Episode 908/10000, loss: 0.00025710748741403224\n",
      "Episode Reward: 2.0\n",
      "Step 295 (223920) @ Episode 909/10000, loss: 0.00021701169316656888\n",
      "Episode Reward: 2.0\n",
      "Step 281 (224201) @ Episode 910/10000, loss: 0.00015255842299666256\n",
      "Episode Reward: 1.0\n",
      "Step 175 (224376) @ Episode 911/10000, loss: 9.728655277285725e-057\n",
      "Episode Reward: 0.0\n",
      "Step 186 (224562) @ Episode 912/10000, loss: 9.340571705251932e-057\n",
      "Episode Reward: 0.0\n",
      "Step 183 (224745) @ Episode 913/10000, loss: 0.00075624481542035943\n",
      "Episode Reward: 0.0\n",
      "Step 169 (224914) @ Episode 914/10000, loss: 0.00025392672978341584\n",
      "Episode Reward: 0.0\n",
      "Step 352 (225266) @ Episode 915/10000, loss: 0.00080164172686636455\n",
      "Episode Reward: 4.0\n",
      "Step 173 (225439) @ Episode 916/10000, loss: 0.00053058966295793656\n",
      "Episode Reward: 0.0\n",
      "Step 183 (225622) @ Episode 917/10000, loss: 0.00352651742286980158\n",
      "Episode Reward: 0.0\n",
      "Step 264 (225886) @ Episode 918/10000, loss: 0.00041039619827643037\n",
      "Episode Reward: 2.0\n",
      "Step 237 (226123) @ Episode 919/10000, loss: 0.00054112175712361937\n",
      "Episode Reward: 1.0\n",
      "Step 173 (226296) @ Episode 920/10000, loss: 0.00037132034776732326\n",
      "Episode Reward: 0.0\n",
      "Step 191 (226487) @ Episode 921/10000, loss: 0.00064769154414534575\n",
      "Episode Reward: 0.0\n",
      "Step 227 (226714) @ Episode 922/10000, loss: 0.00079374096821993594\n",
      "Episode Reward: 1.0\n",
      "Step 182 (226896) @ Episode 923/10000, loss: 0.00051371002336964012\n",
      "Episode Reward: 0.0\n",
      "Step 166 (227062) @ Episode 924/10000, loss: 8.852174505591393e-053\n",
      "Episode Reward: 0.0\n",
      "Step 328 (227390) @ Episode 925/10000, loss: 0.00020784424850717187\n",
      "Episode Reward: 3.0\n",
      "Step 308 (227698) @ Episode 926/10000, loss: 0.00012260446965228766\n",
      "Episode Reward: 2.0\n",
      "Step 335 (228033) @ Episode 927/10000, loss: 0.00060400355141609916\n",
      "Episode Reward: 3.0\n",
      "Step 175 (228208) @ Episode 928/10000, loss: 9.37047298066318e-0567\n",
      "Episode Reward: 0.0\n",
      "Step 228 (228436) @ Episode 929/10000, loss: 0.00178278470411896753\n",
      "Episode Reward: 1.0\n",
      "Step 172 (228608) @ Episode 930/10000, loss: 0.00023966388835106045\n",
      "Episode Reward: 0.0\n",
      "Step 213 (228821) @ Episode 931/10000, loss: 0.00020248997316230088\n",
      "Episode Reward: 1.0\n",
      "Step 386 (229207) @ Episode 932/10000, loss: 0.00063814385794103155\n",
      "Episode Reward: 4.0\n",
      "Step 347 (229554) @ Episode 933/10000, loss: 7.20587995601818e-0524\n",
      "Episode Reward: 3.0\n",
      "Step 238 (229792) @ Episode 934/10000, loss: 0.00041725745541043585\n",
      "Episode Reward: 1.0\n",
      "Step 350 (230142) @ Episode 935/10000, loss: 0.00010633080091793098\n",
      "Episode Reward: 3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 257 (230399) @ Episode 936/10000, loss: 0.00037053128471598034\n",
      "Episode Reward: 1.0\n",
      "Step 197 (230596) @ Episode 937/10000, loss: 0.00021451456996146594\n",
      "Episode Reward: 0.0\n",
      "Step 177 (230773) @ Episode 938/10000, loss: 0.00010985518747474998\n",
      "Episode Reward: 0.0\n",
      "Step 241 (231014) @ Episode 939/10000, loss: 3.63254475814756e-0553\n",
      "Episode Reward: 1.0\n",
      "Step 183 (231197) @ Episode 940/10000, loss: 9.204013622365892e-053\n",
      "Episode Reward: 0.0\n",
      "Step 254 (231451) @ Episode 941/10000, loss: 0.00027056061662733555\n",
      "Episode Reward: 2.0\n",
      "Step 228 (231679) @ Episode 942/10000, loss: 0.00188072375021874927\n",
      "Episode Reward: 1.0\n",
      "Step 304 (231983) @ Episode 943/10000, loss: 0.00095068442169576886\n",
      "Episode Reward: 3.0\n",
      "Step 258 (232241) @ Episode 944/10000, loss: 0.00067226291866973045\n",
      "Episode Reward: 2.0\n",
      "Step 208 (232449) @ Episode 945/10000, loss: 0.00033915298990905285\n",
      "Episode Reward: 0.0\n",
      "Step 171 (232620) @ Episode 946/10000, loss: 0.00040230751619674265\n",
      "Episode Reward: 0.0\n",
      "Step 323 (232943) @ Episode 947/10000, loss: 3.952482802560553e-055\n",
      "Episode Reward: 2.0\n",
      "Step 232 (233175) @ Episode 948/10000, loss: 0.00018175988225266337\n",
      "Episode Reward: 1.0\n",
      "Step 354 (233529) @ Episode 949/10000, loss: 0.00010952096636174247\n",
      "Episode Reward: 3.0\n",
      "Step 287 (233816) @ Episode 950/10000, loss: 0.00017725313955452293\n",
      "Episode Reward: 2.0\n",
      "Step 288 (234104) @ Episode 951/10000, loss: 0.00021532803657464683\n",
      "Episode Reward: 2.0\n",
      "Step 272 (234376) @ Episode 952/10000, loss: 0.00217777397483587276\n",
      "Episode Reward: 2.0\n",
      "Step 219 (234595) @ Episode 953/10000, loss: 0.00068571523297578105\n",
      "Episode Reward: 1.0\n",
      "Step 248 (234843) @ Episode 954/10000, loss: 0.00014573223597835754\n",
      "Episode Reward: 1.0\n",
      "Step 251 (235094) @ Episode 955/10000, loss: 0.00011279821046628058\n",
      "Episode Reward: 1.0\n",
      "Step 200 (235294) @ Episode 956/10000, loss: 0.00050005991943180567\n",
      "Episode Reward: 0.0\n",
      "Step 170 (235464) @ Episode 957/10000, loss: 3.686475974973291e-053\n",
      "Episode Reward: 0.0\n",
      "Step 303 (235767) @ Episode 958/10000, loss: 0.00152507959865033634\n",
      "Episode Reward: 2.0\n",
      "Step 378 (236145) @ Episode 959/10000, loss: 0.00038902991218492396\n",
      "Episode Reward: 4.0\n",
      "Step 243 (236388) @ Episode 960/10000, loss: 0.00017354037845507264\n",
      "Episode Reward: 1.0\n",
      "Step 276 (236664) @ Episode 961/10000, loss: 0.00011294796422589577\n",
      "Episode Reward: 2.0\n",
      "Step 263 (236927) @ Episode 962/10000, loss: 0.00014713424025103455\n",
      "Episode Reward: 1.0\n",
      "Step 181 (237108) @ Episode 963/10000, loss: 0.00011671006359392777\n",
      "Episode Reward: 0.0\n",
      "Step 171 (237279) @ Episode 964/10000, loss: 0.00016900568152777855\n",
      "Episode Reward: 0.0\n",
      "Step 403 (237682) @ Episode 965/10000, loss: 6.941887841094285e-055\n",
      "Episode Reward: 4.0\n",
      "Step 417 (238099) @ Episode 966/10000, loss: 0.00013413857959676534\n",
      "Episode Reward: 4.0\n",
      "Step 233 (238332) @ Episode 967/10000, loss: 0.00212550209835171782\n",
      "Episode Reward: 1.0\n",
      "Step 177 (238509) @ Episode 968/10000, loss: 0.00018210249254480004\n",
      "Episode Reward: 0.0\n",
      "Step 171 (238680) @ Episode 969/10000, loss: 0.00325536192394793034\n",
      "Episode Reward: 0.0\n",
      "Step 183 (238863) @ Episode 970/10000, loss: 0.00089142820797860622\n",
      "Episode Reward: 0.0\n",
      "Step 255 (239118) @ Episode 971/10000, loss: 0.00011258760787313804\n",
      "Episode Reward: 1.0\n",
      "Step 495 (239613) @ Episode 972/10000, loss: 2.359369318583049e-053\n",
      "Episode Reward: 7.0\n",
      "Step 233 (239846) @ Episode 973/10000, loss: 6.086616849643178e-056\n",
      "Episode Reward: 1.0\n",
      "Step 231 (240077) @ Episode 974/10000, loss: 0.00012625247472897172\n",
      "Episode Reward: 1.0\n",
      "Step 259 (240336) @ Episode 975/10000, loss: 7.25802528904751e-0582\n",
      "Episode Reward: 2.0\n",
      "Step 231 (240567) @ Episode 976/10000, loss: 0.00328337843529880059\n",
      "Episode Reward: 1.0\n",
      "Step 232 (240799) @ Episode 977/10000, loss: 0.00147924001794308424\n",
      "Episode Reward: 1.0\n",
      "Step 167 (240966) @ Episode 978/10000, loss: 0.00021257647313177586\n",
      "Episode Reward: 0.0\n",
      "Step 161 (241127) @ Episode 979/10000, loss: 0.00021266094699967653\n",
      "Episode Reward: 0.0\n",
      "Step 243 (241370) @ Episode 980/10000, loss: 0.00018566549988463525\n",
      "Episode Reward: 1.0\n",
      "Step 283 (241653) @ Episode 981/10000, loss: 7.683769217692316e-054\n",
      "Episode Reward: 2.0\n",
      "Step 233 (241886) @ Episode 982/10000, loss: 0.00098139559850096785\n",
      "Episode Reward: 1.0\n",
      "Step 276 (242162) @ Episode 983/10000, loss: 0.00311593268997967246\n",
      "Episode Reward: 2.0\n",
      "Step 285 (242447) @ Episode 984/10000, loss: 0.00096745515475049618\n",
      "Episode Reward: 2.0\n",
      "Step 319 (242766) @ Episode 985/10000, loss: 6.056498386897147e-053\n",
      "Episode Reward: 3.0\n",
      "Step 302 (243068) @ Episode 986/10000, loss: 0.00018569445819593966\n",
      "Episode Reward: 2.0\n",
      "Step 205 (243273) @ Episode 987/10000, loss: 0.00027924322057515383\n",
      "Episode Reward: 1.0\n",
      "Step 228 (243501) @ Episode 988/10000, loss: 0.00034124945523217325\n",
      "Episode Reward: 1.0\n",
      "Step 269 (243770) @ Episode 989/10000, loss: 0.00055046984925866136\n",
      "Episode Reward: 2.0\n",
      "Step 182 (243952) @ Episode 990/10000, loss: 0.00031434444827027627\n",
      "Episode Reward: 0.0\n",
      "Step 176 (244128) @ Episode 991/10000, loss: 0.00012858526315540075\n",
      "Episode Reward: 0.0\n",
      "Step 274 (244402) @ Episode 992/10000, loss: 0.00156933930702507546\n",
      "Episode Reward: 2.0\n",
      "Step 162 (244564) @ Episode 993/10000, loss: 0.00015842901484575123\n",
      "Episode Reward: 0.0\n",
      "Step 169 (244733) @ Episode 994/10000, loss: 0.00100901583209633831\n",
      "Episode Reward: 0.0\n",
      "Step 322 (245055) @ Episode 995/10000, loss: 0.00010609529999783263\n",
      "Episode Reward: 7.0\n",
      "Step 230 (245285) @ Episode 996/10000, loss: 0.00035218481207266455\n",
      "Episode Reward: 1.0\n",
      "Step 241 (245526) @ Episode 997/10000, loss: 0.00088941061403602368\n",
      "Episode Reward: 1.0\n",
      "Step 166 (245692) @ Episode 998/10000, loss: 0.00038538087392225866\n",
      "Episode Reward: 0.0\n",
      "Step 208 (245900) @ Episode 999/10000, loss: 3.904522964148782e-053\n",
      "Episode Reward: 1.0\n",
      "Step 300 (246200) @ Episode 1000/10000, loss: 0.00017109129112213855\n",
      "Episode Reward: 2.0\n",
      "Step 273 (246473) @ Episode 1001/10000, loss: 4.987511056242511e-053\n",
      "Episode Reward: 1.0\n",
      "Step 311 (246784) @ Episode 1002/10000, loss: 4.864432412432507e-055\n",
      "Episode Reward: 2.0\n",
      "Step 308 (247092) @ Episode 1003/10000, loss: 6.423487502615899e-055\n",
      "Episode Reward: 2.0\n",
      "Step 182 (247274) @ Episode 1004/10000, loss: 0.00020701269386336207\n",
      "Episode Reward: 0.0\n",
      "Step 312 (247586) @ Episode 1005/10000, loss: 0.00020806191605515778\n",
      "Episode Reward: 3.0\n",
      "Step 189 (247775) @ Episode 1006/10000, loss: 0.00066087068989872932\n",
      "Episode Reward: 0.0\n",
      "Step 202 (247977) @ Episode 1007/10000, loss: 0.00042596179991960526\n",
      "Episode Reward: 1.0\n",
      "Step 228 (248205) @ Episode 1008/10000, loss: 0.00013835450226906687\n",
      "Episode Reward: 1.0\n",
      "Step 209 (248414) @ Episode 1009/10000, loss: 0.00039530819049105055\n",
      "Episode Reward: 0.0\n",
      "Step 225 (248639) @ Episode 1010/10000, loss: 0.00030653047724626963\n",
      "Episode Reward: 1.0\n",
      "Step 211 (248850) @ Episode 1011/10000, loss: 0.00021103356266394258\n",
      "Episode Reward: 0.0\n",
      "Step 322 (249172) @ Episode 1012/10000, loss: 0.00099726405460387477\n",
      "Episode Reward: 2.0\n",
      "Step 196 (249368) @ Episode 1013/10000, loss: 0.00015410032938234508\n",
      "Episode Reward: 0.0\n",
      "Step 205 (249573) @ Episode 1014/10000, loss: 0.00018314321641810238\n",
      "Episode Reward: 1.0\n",
      "Step 182 (249755) @ Episode 1015/10000, loss: 0.00023740407777950168\n",
      "Episode Reward: 0.0\n",
      "Step 256 (250011) @ Episode 1016/10000, loss: 0.00018793676281347874\n",
      "Episode Reward: 1.0\n",
      "Step 334 (250345) @ Episode 1017/10000, loss: 0.00021931531955488026\n",
      "Episode Reward: 2.0\n",
      "Step 244 (250589) @ Episode 1018/10000, loss: 0.00051809009164571765\n",
      "Episode Reward: 1.0\n",
      "Step 240 (250829) @ Episode 1019/10000, loss: 0.01110493578016758314\n",
      "Episode Reward: 1.0\n",
      "Step 311 (251140) @ Episode 1020/10000, loss: 0.00014130337513051927\n",
      "Episode Reward: 2.0\n",
      "Step 231 (251371) @ Episode 1021/10000, loss: 0.00226301886141300265\n",
      "Episode Reward: 1.0\n",
      "Step 246 (251617) @ Episode 1022/10000, loss: 0.00042731783469207585\n",
      "Episode Reward: 1.0\n",
      "Step 342 (251959) @ Episode 1023/10000, loss: 0.00023583363508805633\n",
      "Episode Reward: 3.0\n",
      "Step 356 (252315) @ Episode 1024/10000, loss: 0.00084659765707328925\n",
      "Episode Reward: 4.0\n",
      "Step 245 (252560) @ Episode 1025/10000, loss: 9.028347994899377e-055\n",
      "Episode Reward: 1.0\n",
      "Step 321 (252881) @ Episode 1026/10000, loss: 0.00026846679975278676\n",
      "Episode Reward: 2.0\n",
      "Step 247 (253128) @ Episode 1027/10000, loss: 0.00067518412834033374\n",
      "Episode Reward: 2.0\n",
      "Step 185 (253313) @ Episode 1028/10000, loss: 0.00019803555915132165\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 177 (253490) @ Episode 1029/10000, loss: 0.01025628484785556866\n",
      "Episode Reward: 0.0\n",
      "Step 191 (253681) @ Episode 1030/10000, loss: 0.00041415102896280587\n",
      "Episode Reward: 0.0\n",
      "Step 176 (253857) @ Episode 1031/10000, loss: 0.00010928004485322163\n",
      "Episode Reward: 0.0\n",
      "Step 174 (254031) @ Episode 1032/10000, loss: 8.591704681748524e-054\n",
      "Episode Reward: 0.0\n",
      "Step 207 (254238) @ Episode 1033/10000, loss: 5.893930938327685e-054\n",
      "Episode Reward: 1.0\n",
      "Step 227 (254465) @ Episode 1034/10000, loss: 8.561936556361616e-058\n",
      "Episode Reward: 1.0\n",
      "Step 351 (254816) @ Episode 1035/10000, loss: 0.00027399259852245452\n",
      "Episode Reward: 3.0\n",
      "Step 275 (255091) @ Episode 1036/10000, loss: 0.00220012129284441479\n",
      "Episode Reward: 2.0\n",
      "Step 182 (255273) @ Episode 1037/10000, loss: 0.00433938438072800627\n",
      "Episode Reward: 0.0\n",
      "Step 173 (255446) @ Episode 1038/10000, loss: 0.00014100116095505655\n",
      "Episode Reward: 0.0\n",
      "Step 233 (255679) @ Episode 1039/10000, loss: 0.00049739674432203174\n",
      "Episode Reward: 1.0\n",
      "Step 172 (255851) @ Episode 1040/10000, loss: 0.00021319121879059821\n",
      "Episode Reward: 0.0\n",
      "Step 213 (256064) @ Episode 1041/10000, loss: 0.00025570060824975375\n",
      "Episode Reward: 1.0\n",
      "Step 283 (256347) @ Episode 1042/10000, loss: 0.00163867021910846234\n",
      "Episode Reward: 2.0\n",
      "Step 167 (256514) @ Episode 1043/10000, loss: 0.00010180415847571567\n",
      "Episode Reward: 0.0\n",
      "Step 245 (256759) @ Episode 1044/10000, loss: 0.00012011778017040342\n",
      "Episode Reward: 1.0\n",
      "Step 295 (257054) @ Episode 1045/10000, loss: 0.00012893805978819728\n",
      "Episode Reward: 1.0\n",
      "Step 189 (257243) @ Episode 1046/10000, loss: 0.00084713305113837124\n",
      "Episode Reward: 0.0\n",
      "Step 246 (257489) @ Episode 1047/10000, loss: 3.7976456951582804e-05\n",
      "Episode Reward: 1.0\n",
      "Step 241 (257730) @ Episode 1048/10000, loss: 3.593882865970954e-056\n",
      "Episode Reward: 1.0\n",
      "Step 312 (258042) @ Episode 1049/10000, loss: 6.49028952466324e-0517\n",
      "Episode Reward: 2.0\n",
      "Step 177 (258219) @ Episode 1050/10000, loss: 0.00247091893106699496\n",
      "Episode Reward: 0.0\n",
      "Step 220 (258439) @ Episode 1051/10000, loss: 8.62009619595483e-0563\n",
      "Episode Reward: 1.0\n",
      "Step 299 (258738) @ Episode 1052/10000, loss: 0.00025310617638751864\n",
      "Episode Reward: 3.0\n",
      "Step 209 (258947) @ Episode 1053/10000, loss: 0.00049008172936737545\n",
      "Episode Reward: 1.0\n",
      "Step 236 (259183) @ Episode 1054/10000, loss: 7.592876499984413e-055\n",
      "Episode Reward: 1.0\n",
      "Step 298 (259481) @ Episode 1055/10000, loss: 3.861951699946076e-055\n",
      "Episode Reward: 2.0\n",
      "Step 176 (259657) @ Episode 1056/10000, loss: 0.00193559820763766778\n",
      "Episode Reward: 0.0\n",
      "Step 214 (259871) @ Episode 1057/10000, loss: 9.859592682914808e-052\n",
      "Episode Reward: 0.0\n",
      "Step 282 (260153) @ Episode 1058/10000, loss: 0.00126980687491595757\n",
      "Episode Reward: 2.0\n",
      "Step 217 (260370) @ Episode 1059/10000, loss: 5.815067925141193e-052\n",
      "Episode Reward: 1.0\n",
      "Step 220 (260590) @ Episode 1060/10000, loss: 0.00015236210310831666\n",
      "Episode Reward: 1.0\n",
      "Step 238 (260828) @ Episode 1061/10000, loss: 5.0086877308785915e-05\n",
      "Episode Reward: 1.0\n",
      "Step 212 (261040) @ Episode 1062/10000, loss: 0.00576278055086731956\n",
      "Episode Reward: 1.0\n",
      "Step 269 (261309) @ Episode 1063/10000, loss: 0.00070425972808152448\n",
      "Episode Reward: 2.0\n",
      "Step 177 (261486) @ Episode 1064/10000, loss: 0.00033795856870710856\n",
      "Episode Reward: 0.0\n",
      "Step 321 (261807) @ Episode 1065/10000, loss: 8.663908374728635e-056\n",
      "Episode Reward: 2.0\n",
      "Step 244 (262051) @ Episode 1066/10000, loss: 0.00029418314807116985\n",
      "Episode Reward: 1.0\n",
      "Step 255 (262306) @ Episode 1067/10000, loss: 0.00081483059329912075\n",
      "Episode Reward: 1.0\n",
      "Step 183 (262489) @ Episode 1068/10000, loss: 0.00033133651595562696\n",
      "Episode Reward: 0.0\n",
      "Step 222 (262711) @ Episode 1069/10000, loss: 0.00080323673319071532\n",
      "Episode Reward: 1.0\n",
      "Step 249 (262960) @ Episode 1070/10000, loss: 0.00017355586169287562\n",
      "Episode Reward: 1.0\n",
      "Step 171 (263131) @ Episode 1071/10000, loss: 0.00019801032613031566\n",
      "Episode Reward: 0.0\n",
      "Step 309 (263440) @ Episode 1072/10000, loss: 0.00175136874895542862\n",
      "Episode Reward: 3.0\n",
      "Step 230 (263670) @ Episode 1073/10000, loss: 0.00036457466194406154\n",
      "Episode Reward: 1.0\n",
      "Step 218 (263888) @ Episode 1074/10000, loss: 0.00082570209633558995\n",
      "Episode Reward: 1.0\n",
      "Step 181 (264069) @ Episode 1075/10000, loss: 9.380534902447835e-055\n",
      "Episode Reward: 0.0\n",
      "Step 196 (264265) @ Episode 1076/10000, loss: 0.00779664330184459788\n",
      "Episode Reward: 0.0\n",
      "Step 243 (264508) @ Episode 1077/10000, loss: 0.00020660480367951095\n",
      "Episode Reward: 1.0\n",
      "Step 237 (264745) @ Episode 1078/10000, loss: 8.05495583335869e-0555\n",
      "Episode Reward: 1.0\n",
      "Step 299 (265044) @ Episode 1079/10000, loss: 0.00017138422117568552\n",
      "Episode Reward: 2.0\n",
      "Step 229 (265273) @ Episode 1080/10000, loss: 0.00104002328589558674\n",
      "Episode Reward: 1.0\n",
      "Step 192 (265465) @ Episode 1081/10000, loss: 0.00066715059801936156\n",
      "Episode Reward: 0.0\n",
      "Step 284 (265749) @ Episode 1082/10000, loss: 0.00126740150153636933\n",
      "Episode Reward: 2.0\n",
      "Step 168 (265917) @ Episode 1083/10000, loss: 0.00024051964282989502\n",
      "Episode Reward: 0.0\n",
      "Step 168 (266085) @ Episode 1084/10000, loss: 0.00025288178585469723\n",
      "Episode Reward: 0.0\n",
      "Step 319 (266404) @ Episode 1085/10000, loss: 0.00034275121288374066\n",
      "Episode Reward: 2.0\n",
      "Step 213 (266617) @ Episode 1086/10000, loss: 0.00048003537813201547\n",
      "Episode Reward: 1.0\n",
      "Step 227 (266844) @ Episode 1087/10000, loss: 0.00085072248475626118\n",
      "Episode Reward: 1.0\n",
      "Step 295 (267139) @ Episode 1088/10000, loss: 0.00018013358931057155\n",
      "Episode Reward: 2.0\n",
      "Step 286 (267425) @ Episode 1089/10000, loss: 9.193256846629083e-055\n",
      "Episode Reward: 2.0\n",
      "Step 219 (267644) @ Episode 1090/10000, loss: 0.00086444389307871467\n",
      "Episode Reward: 1.0\n",
      "Step 303 (267947) @ Episode 1091/10000, loss: 0.00151699385605752477\n",
      "Episode Reward: 2.0\n",
      "Step 293 (268240) @ Episode 1092/10000, loss: 0.00094186235219240196\n",
      "Episode Reward: 2.0\n",
      "Step 234 (268474) @ Episode 1093/10000, loss: 0.00023194735695142364\n",
      "Episode Reward: 1.0\n",
      "Step 360 (268834) @ Episode 1094/10000, loss: 0.00011140698188683018\n",
      "Episode Reward: 4.0\n",
      "Step 237 (269071) @ Episode 1095/10000, loss: 0.00024080838193185627\n",
      "Episode Reward: 1.0\n",
      "Step 216 (269287) @ Episode 1096/10000, loss: 7.992803875822574e-057\n",
      "Episode Reward: 1.0\n",
      "Step 190 (269477) @ Episode 1097/10000, loss: 0.00010643787391018122\n",
      "Episode Reward: 0.0\n",
      "Step 188 (269665) @ Episode 1098/10000, loss: 0.00018040757277049124\n",
      "Episode Reward: 0.0\n",
      "Step 343 (270008) @ Episode 1099/10000, loss: 0.00227744970470666965\n",
      "Episode Reward: 3.0\n",
      "Step 342 (270350) @ Episode 1100/10000, loss: 0.00015337129298131913\n",
      "Episode Reward: 3.0\n",
      "Step 236 (270586) @ Episode 1101/10000, loss: 0.00020585849415510893\n",
      "Episode Reward: 1.0\n",
      "Step 289 (270875) @ Episode 1102/10000, loss: 0.00313052767887711526\n",
      "Episode Reward: 2.0\n",
      "Step 208 (271083) @ Episode 1103/10000, loss: 0.00032330414978787303\n",
      "Episode Reward: 0.0\n",
      "Step 207 (271290) @ Episode 1104/10000, loss: 0.00016040998161770403\n",
      "Episode Reward: 0.0\n",
      "Step 243 (271533) @ Episode 1105/10000, loss: 0.00029394193552434444\n",
      "Episode Reward: 1.0\n",
      "Step 254 (271787) @ Episode 1106/10000, loss: 0.00074310472700744874\n",
      "Episode Reward: 1.0\n",
      "Step 167 (271954) @ Episode 1107/10000, loss: 0.00017591897631064057\n",
      "Episode Reward: 0.0\n",
      "Step 347 (272301) @ Episode 1108/10000, loss: 0.00070341635728254912\n",
      "Episode Reward: 3.0\n",
      "Step 310 (272611) @ Episode 1109/10000, loss: 0.00108644284773617987\n",
      "Episode Reward: 3.0\n",
      "Step 233 (272844) @ Episode 1110/10000, loss: 0.00219106860458850864\n",
      "Episode Reward: 1.0\n",
      "Step 161 (273005) @ Episode 1111/10000, loss: 0.00264143571257591255\n",
      "Episode Reward: 0.0\n",
      "Step 184 (273189) @ Episode 1112/10000, loss: 0.00070649152621626854\n",
      "Episode Reward: 0.0\n",
      "Step 249 (273438) @ Episode 1113/10000, loss: 0.00103810091968625784\n",
      "Episode Reward: 1.0\n",
      "Step 318 (273756) @ Episode 1114/10000, loss: 0.00139700702857226138\n",
      "Episode Reward: 2.0\n",
      "Step 177 (273933) @ Episode 1115/10000, loss: 0.00011994280794169754\n",
      "Episode Reward: 0.0\n",
      "Step 252 (274185) @ Episode 1116/10000, loss: 0.00027735298499464993\n",
      "Episode Reward: 1.0\n",
      "Step 287 (274472) @ Episode 1117/10000, loss: 0.00013483136717695743\n",
      "Episode Reward: 2.0\n",
      "Step 241 (274713) @ Episode 1118/10000, loss: 0.00023861830413807184\n",
      "Episode Reward: 1.0\n",
      "Step 231 (274944) @ Episode 1119/10000, loss: 0.00026084022829309106\n",
      "Episode Reward: 1.0\n",
      "Step 195 (275139) @ Episode 1120/10000, loss: 0.00012658770720008764\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 258 (275397) @ Episode 1121/10000, loss: 0.00192533305380493418\n",
      "Episode Reward: 1.0\n",
      "Step 325 (275722) @ Episode 1122/10000, loss: 0.00080172874731943012\n",
      "Episode Reward: 3.0\n",
      "Step 231 (275953) @ Episode 1123/10000, loss: 0.00077546335523948075\n",
      "Episode Reward: 1.0\n",
      "Step 355 (276308) @ Episode 1124/10000, loss: 0.00082306086551398045\n",
      "Episode Reward: 3.0\n",
      "Step 303 (276611) @ Episode 1125/10000, loss: 0.00066300685284659273\n",
      "Episode Reward: 2.0\n",
      "Step 185 (276796) @ Episode 1126/10000, loss: 0.00133568793535232545\n",
      "Episode Reward: 0.0\n",
      "Step 176 (276972) @ Episode 1127/10000, loss: 6.8506138632074e-05742\n",
      "Episode Reward: 0.0\n",
      "Step 380 (277352) @ Episode 1128/10000, loss: 0.00051399943185970196\n",
      "Episode Reward: 3.0\n",
      "Step 252 (277604) @ Episode 1129/10000, loss: 0.00040181068470701575\n",
      "Episode Reward: 2.0\n",
      "Step 217 (277821) @ Episode 1130/10000, loss: 0.00013300516002345836\n",
      "Episode Reward: 1.0\n",
      "Step 297 (278118) @ Episode 1131/10000, loss: 0.00013078816118650138\n",
      "Episode Reward: 2.0\n",
      "Step 218 (278336) @ Episode 1132/10000, loss: 0.00038521926035173246\n",
      "Episode Reward: 1.0\n",
      "Step 377 (278713) @ Episode 1133/10000, loss: 0.00122025830205529937\n",
      "Episode Reward: 4.0\n",
      "Step 376 (279089) @ Episode 1134/10000, loss: 0.00021024033776484435\n",
      "Episode Reward: 4.0\n",
      "Step 165 (279254) @ Episode 1135/10000, loss: 0.00034874276025220755\n",
      "Episode Reward: 0.0\n",
      "Step 172 (279426) @ Episode 1136/10000, loss: 0.00346756633371114737\n",
      "Episode Reward: 0.0\n",
      "Step 266 (279692) @ Episode 1137/10000, loss: 0.00011882402031915262\n",
      "Episode Reward: 2.0\n",
      "Step 217 (279909) @ Episode 1138/10000, loss: 0.00024575929273851216\n",
      "Episode Reward: 1.0\n",
      "Step 406 (280315) @ Episode 1139/10000, loss: 0.00122044805902987728\n",
      "Episode Reward: 4.0\n",
      "Step 344 (280659) @ Episode 1140/10000, loss: 0.00056126620620489126\n",
      "Episode Reward: 3.0\n",
      "Step 198 (280857) @ Episode 1141/10000, loss: 0.00032138076494447887\n",
      "Episode Reward: 0.0\n",
      "Step 170 (281027) @ Episode 1142/10000, loss: 0.00084281014278531073\n",
      "Episode Reward: 0.0\n",
      "Step 225 (281252) @ Episode 1143/10000, loss: 0.00032748575904406607\n",
      "Episode Reward: 0.0\n",
      "Step 314 (281566) @ Episode 1144/10000, loss: 0.00114568916615098716\n",
      "Episode Reward: 3.0\n",
      "Step 238 (281804) @ Episode 1145/10000, loss: 0.00361819798126816756\n",
      "Episode Reward: 1.0\n",
      "Step 212 (282016) @ Episode 1146/10000, loss: 0.00027776963543146855\n",
      "Episode Reward: 1.0\n",
      "Step 236 (282252) @ Episode 1147/10000, loss: 0.00067324267001822595\n",
      "Episode Reward: 1.0\n",
      "Step 269 (282521) @ Episode 1148/10000, loss: 0.00058058404829353095\n",
      "Episode Reward: 2.0\n",
      "Step 236 (282757) @ Episode 1149/10000, loss: 5.245286229182966e-054\n",
      "Episode Reward: 1.0\n",
      "Step 182 (282939) @ Episode 1150/10000, loss: 0.00055791647173464343\n",
      "Episode Reward: 0.0\n",
      "Step 376 (283315) @ Episode 1151/10000, loss: 0.00016845759819261735\n",
      "Episode Reward: 4.0\n",
      "Step 302 (283617) @ Episode 1152/10000, loss: 4.738463758258149e-057\n",
      "Episode Reward: 2.0\n",
      "Step 304 (283921) @ Episode 1153/10000, loss: 0.00268673151731491175\n",
      "Episode Reward: 2.0\n",
      "Step 231 (284152) @ Episode 1154/10000, loss: 0.00015619458281435072\n",
      "Episode Reward: 1.0\n",
      "Step 176 (284328) @ Episode 1155/10000, loss: 0.00039080198621377357\n",
      "Episode Reward: 0.0\n",
      "Step 265 (284593) @ Episode 1156/10000, loss: 0.00073460803832858857\n",
      "Episode Reward: 1.0\n",
      "Step 248 (284841) @ Episode 1157/10000, loss: 7.096637273207307e-055\n",
      "Episode Reward: 2.0\n",
      "Step 221 (285062) @ Episode 1158/10000, loss: 0.00018570291285868734\n",
      "Episode Reward: 0.0\n",
      "Step 213 (285275) @ Episode 1159/10000, loss: 0.00017890412709675733\n",
      "Episode Reward: 1.0\n",
      "Step 229 (285504) @ Episode 1160/10000, loss: 0.00135718658566474913\n",
      "Episode Reward: 1.0\n",
      "Step 274 (285778) @ Episode 1161/10000, loss: 0.00062934029847383557\n",
      "Episode Reward: 2.0\n",
      "Step 281 (286059) @ Episode 1162/10000, loss: 0.00018270152213517576\n",
      "Episode Reward: 1.0\n",
      "Step 189 (286248) @ Episode 1163/10000, loss: 0.00063315464649349454\n",
      "Episode Reward: 0.0\n",
      "Step 205 (286453) @ Episode 1164/10000, loss: 0.00083044747589156032\n",
      "Episode Reward: 0.0\n",
      "Step 199 (286652) @ Episode 1165/10000, loss: 3.593802102841437e-053\n",
      "Episode Reward: 0.0\n",
      "Step 302 (286954) @ Episode 1166/10000, loss: 6.864708848297596e-057\n",
      "Episode Reward: 2.0\n",
      "Step 168 (287122) @ Episode 1167/10000, loss: 0.00266337208449840553\n",
      "Episode Reward: 0.0\n",
      "Step 214 (287336) @ Episode 1168/10000, loss: 0.00092279340606182813\n",
      "Episode Reward: 1.0\n",
      "Step 192 (287528) @ Episode 1169/10000, loss: 0.00020066110300831497\n",
      "Episode Reward: 0.0\n",
      "Step 173 (287701) @ Episode 1170/10000, loss: 7.643793651368469e-054\n",
      "Episode Reward: 0.0\n",
      "Step 234 (287935) @ Episode 1171/10000, loss: 0.00025314436061307793\n",
      "Episode Reward: 0.0\n",
      "Step 227 (288162) @ Episode 1172/10000, loss: 0.00046222977107390765\n",
      "Episode Reward: 1.0\n",
      "Step 282 (288444) @ Episode 1173/10000, loss: 0.00020486502035055316\n",
      "Episode Reward: 2.0\n",
      "Step 430 (288874) @ Episode 1174/10000, loss: 0.00032629931229166687\n",
      "Episode Reward: 5.0\n",
      "Step 190 (289064) @ Episode 1175/10000, loss: 0.00012079328735126182\n",
      "Episode Reward: 0.0\n",
      "Step 199 (289263) @ Episode 1176/10000, loss: 2.182453499699477e-057\n",
      "Episode Reward: 0.0\n",
      "Step 272 (289535) @ Episode 1177/10000, loss: 0.00010842426854651421\n",
      "Episode Reward: 2.0\n",
      "Step 257 (289792) @ Episode 1178/10000, loss: 0.00031357636908069253\n",
      "Episode Reward: 2.0\n",
      "Step 317 (290109) @ Episode 1179/10000, loss: 0.00036600831663236024\n",
      "Episode Reward: 3.0\n",
      "Step 251 (290360) @ Episode 1180/10000, loss: 0.00057862669927999389\n",
      "Episode Reward: 1.0\n",
      "Step 209 (290569) @ Episode 1181/10000, loss: 0.00818998645991087128\n",
      "Episode Reward: 1.0\n",
      "Step 244 (290813) @ Episode 1182/10000, loss: 0.00673082703724503565\n",
      "Episode Reward: 2.0\n",
      "Step 293 (291106) @ Episode 1183/10000, loss: 0.00261640641838312153\n",
      "Episode Reward: 2.0\n",
      "Step 196 (291302) @ Episode 1184/10000, loss: 0.00021397857926785946\n",
      "Episode Reward: 0.0\n",
      "Step 287 (291589) @ Episode 1185/10000, loss: 7.45594225008972e-0574\n",
      "Episode Reward: 2.0\n",
      "Step 224 (291813) @ Episode 1186/10000, loss: 0.00011384065146557987\n",
      "Episode Reward: 1.0\n",
      "Step 179 (291992) @ Episode 1187/10000, loss: 0.00135675072669982945\n",
      "Episode Reward: 0.0\n",
      "Step 279 (292271) @ Episode 1188/10000, loss: 0.00075512402690947063\n",
      "Episode Reward: 2.0\n",
      "Step 172 (292443) @ Episode 1189/10000, loss: 0.00012005295138806105\n",
      "Episode Reward: 0.0\n",
      "Step 363 (292806) @ Episode 1190/10000, loss: 0.00068692734930664335\n",
      "Episode Reward: 4.0\n",
      "Step 188 (292994) @ Episode 1191/10000, loss: 0.00470841629430651726\n",
      "Episode Reward: 0.0\n",
      "Step 338 (293332) @ Episode 1192/10000, loss: 0.00016154139302670956\n",
      "Episode Reward: 3.0\n",
      "Step 216 (293548) @ Episode 1193/10000, loss: 0.00059949036221951253\n",
      "Episode Reward: 1.0\n",
      "Step 298 (293846) @ Episode 1194/10000, loss: 0.00031550743733532727\n",
      "Episode Reward: 2.0\n",
      "Step 234 (294080) @ Episode 1195/10000, loss: 0.00024737205239944161\n",
      "Episode Reward: 1.0\n",
      "Step 304 (294384) @ Episode 1196/10000, loss: 0.00012040566798532382\n",
      "Episode Reward: 2.0\n",
      "Step 213 (294597) @ Episode 1197/10000, loss: 0.00048524426529183984\n",
      "Episode Reward: 0.0\n",
      "Step 217 (294814) @ Episode 1198/10000, loss: 0.00052766391308978253\n",
      "Episode Reward: 0.0\n",
      "Step 215 (295029) @ Episode 1199/10000, loss: 0.00033445534063503146\n",
      "Episode Reward: 1.0\n",
      "Step 259 (295288) @ Episode 1200/10000, loss: 0.00021716044284403324\n",
      "Episode Reward: 1.0\n",
      "Step 295 (295583) @ Episode 1201/10000, loss: 0.00077633571345359094\n",
      "Episode Reward: 2.0\n",
      "Step 219 (295802) @ Episode 1202/10000, loss: 0.00212662527337670337\n",
      "Episode Reward: 1.0\n",
      "Step 285 (296087) @ Episode 1203/10000, loss: 0.00010233563079964373\n",
      "Episode Reward: 2.0\n",
      "Step 208 (296295) @ Episode 1204/10000, loss: 0.00021520600421354175\n",
      "Episode Reward: 1.0\n",
      "Step 190 (296485) @ Episode 1205/10000, loss: 0.00012720955419354148\n",
      "Episode Reward: 0.0\n",
      "Step 209 (296694) @ Episode 1206/10000, loss: 0.00043328071478754284\n",
      "Episode Reward: 1.0\n",
      "Step 382 (297076) @ Episode 1207/10000, loss: 0.00039360532537102773\n",
      "Episode Reward: 4.0\n",
      "Step 190 (297266) @ Episode 1208/10000, loss: 0.00028057958115823567\n",
      "Episode Reward: 0.0\n",
      "Step 291 (297557) @ Episode 1209/10000, loss: 0.00011063920828746632\n",
      "Episode Reward: 2.0\n",
      "Step 244 (297801) @ Episode 1210/10000, loss: 0.00015597212768625468\n",
      "Episode Reward: 2.0\n",
      "Step 176 (297977) @ Episode 1211/10000, loss: 0.00012829685874748975\n",
      "Episode Reward: 0.0\n",
      "Step 195 (298172) @ Episode 1212/10000, loss: 0.00039360445225611335\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 379 (298551) @ Episode 1213/10000, loss: 0.00023338597384281456\n",
      "Episode Reward: 3.0\n",
      "Step 281 (298832) @ Episode 1214/10000, loss: 0.00100852514151483773\n",
      "Episode Reward: 1.0\n",
      "Step 252 (299084) @ Episode 1215/10000, loss: 0.00140284490771591664\n",
      "Episode Reward: 1.0\n",
      "Step 277 (299361) @ Episode 1216/10000, loss: 0.00202735443599522166\n",
      "Episode Reward: 2.0\n",
      "Step 226 (299587) @ Episode 1217/10000, loss: 0.00029955967329442583\n",
      "Episode Reward: 1.0\n",
      "Step 247 (299834) @ Episode 1218/10000, loss: 0.00687480717897415225\n",
      "Episode Reward: 2.0\n",
      "Step 206 (300040) @ Episode 1219/10000, loss: 0.00070758123183622963\n",
      "Episode Reward: 0.0\n",
      "Step 327 (300367) @ Episode 1220/10000, loss: 0.00206969701685011491\n",
      "Episode Reward: 3.0\n",
      "Step 185 (300552) @ Episode 1221/10000, loss: 0.00089639896759763364\n",
      "Episode Reward: 0.0\n",
      "Step 347 (300899) @ Episode 1222/10000, loss: 0.00029063550755381584\n",
      "Episode Reward: 3.0\n",
      "Step 368 (301267) @ Episode 1223/10000, loss: 0.00037265336140990257\n",
      "Episode Reward: 3.0\n",
      "Step 175 (301442) @ Episode 1224/10000, loss: 0.00086581980576738726\n",
      "Episode Reward: 0.0\n",
      "Step 178 (301620) @ Episode 1225/10000, loss: 0.01212660688906908734\n",
      "Episode Reward: 0.0\n",
      "Step 195 (301815) @ Episode 1226/10000, loss: 0.00152755063027143487\n",
      "Episode Reward: 0.0\n",
      "Step 317 (302132) @ Episode 1227/10000, loss: 0.00110627664253115651\n",
      "Episode Reward: 3.0\n",
      "Step 167 (302299) @ Episode 1228/10000, loss: 0.00028647511499002576\n",
      "Episode Reward: 0.0\n",
      "Step 291 (302590) @ Episode 1229/10000, loss: 0.00135938322637230163\n",
      "Episode Reward: 2.0\n",
      "Step 211 (302801) @ Episode 1230/10000, loss: 0.00033738941419869666\n",
      "Episode Reward: 1.0\n",
      "Step 308 (303109) @ Episode 1231/10000, loss: 0.00719796773046255133\n",
      "Episode Reward: 2.0\n",
      "Step 339 (303448) @ Episode 1232/10000, loss: 0.00220018881373107437\n",
      "Episode Reward: 3.0\n",
      "Step 245 (303693) @ Episode 1233/10000, loss: 0.00148033839650452148\n",
      "Episode Reward: 1.0\n",
      "Step 331 (304024) @ Episode 1234/10000, loss: 0.00122108473442494874\n",
      "Episode Reward: 3.0\n",
      "Step 240 (304264) @ Episode 1235/10000, loss: 0.00023880574735812843\n",
      "Episode Reward: 1.0\n",
      "Step 217 (304481) @ Episode 1236/10000, loss: 0.00042624206980690363\n",
      "Episode Reward: 0.0\n",
      "Step 205 (304686) @ Episode 1237/10000, loss: 0.00091425230493769055\n",
      "Episode Reward: 1.0\n",
      "Step 267 (304953) @ Episode 1238/10000, loss: 0.00049859122373163763\n",
      "Episode Reward: 2.0\n",
      "Step 212 (305165) @ Episode 1239/10000, loss: 0.00054560333956032993\n",
      "Episode Reward: 1.0\n",
      "Step 346 (305511) @ Episode 1240/10000, loss: 0.00013539164501708844\n",
      "Episode Reward: 3.0\n",
      "Step 178 (305689) @ Episode 1241/10000, loss: 0.00033675480517558753\n",
      "Episode Reward: 0.0\n",
      "Step 259 (305948) @ Episode 1242/10000, loss: 0.00030740635702386548\n",
      "Episode Reward: 2.0\n",
      "Step 387 (306335) @ Episode 1243/10000, loss: 0.00082885811571031812\n",
      "Episode Reward: 3.0\n",
      "Step 224 (306559) @ Episode 1244/10000, loss: 0.00036288273986428976\n",
      "Episode Reward: 1.0\n",
      "Step 228 (306787) @ Episode 1245/10000, loss: 0.00012431347568053752\n",
      "Episode Reward: 1.0\n",
      "Step 288 (307075) @ Episode 1246/10000, loss: 6.420745921786875e-053\n",
      "Episode Reward: 2.0\n",
      "Step 376 (307451) @ Episode 1247/10000, loss: 0.00012416718527674675\n",
      "Episode Reward: 4.0\n",
      "Step 246 (307697) @ Episode 1248/10000, loss: 8.302440255647525e-052\n",
      "Episode Reward: 2.0\n",
      "Step 176 (307873) @ Episode 1249/10000, loss: 0.00028888456290587783\n",
      "Episode Reward: 0.0\n",
      "Step 231 (308104) @ Episode 1250/10000, loss: 0.00030318886274471883\n",
      "Episode Reward: 1.0\n",
      "Step 377 (308481) @ Episode 1251/10000, loss: 0.00032451743027195334\n",
      "Episode Reward: 4.0\n",
      "Step 286 (308767) @ Episode 1252/10000, loss: 0.00121580634731799367\n",
      "Episode Reward: 2.0\n",
      "Step 245 (309012) @ Episode 1253/10000, loss: 0.00082409655442461377\n",
      "Episode Reward: 1.0\n",
      "Step 182 (309194) @ Episode 1254/10000, loss: 0.00016116042388603096\n",
      "Episode Reward: 0.0\n",
      "Step 362 (309556) @ Episode 1255/10000, loss: 0.00105747731868177652\n",
      "Episode Reward: 3.0\n",
      "Step 337 (309893) @ Episode 1256/10000, loss: 0.00191768561489880088\n",
      "Episode Reward: 3.0\n",
      "Step 199 (310092) @ Episode 1257/10000, loss: 0.00112177385017275834\n",
      "Episode Reward: 0.0\n",
      "Step 278 (310370) @ Episode 1258/10000, loss: 0.00187456456478685144\n",
      "Episode Reward: 2.0\n",
      "Step 221 (310591) @ Episode 1259/10000, loss: 0.00108933646697551011\n",
      "Episode Reward: 1.0\n",
      "Step 257 (310848) @ Episode 1260/10000, loss: 8.75723417266272e-0563\n",
      "Episode Reward: 1.0\n",
      "Step 181 (311029) @ Episode 1261/10000, loss: 0.00698807463049888651\n",
      "Episode Reward: 0.0\n",
      "Step 179 (311208) @ Episode 1262/10000, loss: 0.00468483613803982747\n",
      "Episode Reward: 0.0\n",
      "Step 195 (311403) @ Episode 1263/10000, loss: 0.00351871247403323653\n",
      "Episode Reward: 0.0\n",
      "Step 186 (311589) @ Episode 1264/10000, loss: 0.00082579109584912665\n",
      "Episode Reward: 0.0\n",
      "Step 216 (311805) @ Episode 1265/10000, loss: 0.00241762329824268834\n",
      "Episode Reward: 1.0\n",
      "Step 392 (312197) @ Episode 1266/10000, loss: 0.00093256600666791257\n",
      "Episode Reward: 4.0\n",
      "Step 378 (312575) @ Episode 1267/10000, loss: 0.00053174939239397643\n",
      "Episode Reward: 3.0\n",
      "Step 231 (312806) @ Episode 1268/10000, loss: 0.00045256904559209943\n",
      "Episode Reward: 1.0\n",
      "Step 287 (313093) @ Episode 1269/10000, loss: 0.00048543812590651214\n",
      "Episode Reward: 2.0\n",
      "Step 227 (313320) @ Episode 1270/10000, loss: 0.00243679271079599867\n",
      "Episode Reward: 1.0\n",
      "Step 182 (313502) @ Episode 1271/10000, loss: 0.00026911727036349475\n",
      "Episode Reward: 0.0\n",
      "Step 174 (313676) @ Episode 1272/10000, loss: 0.00044664720189757645\n",
      "Episode Reward: 0.0\n",
      "Step 181 (313857) @ Episode 1273/10000, loss: 0.00098069687373936187\n",
      "Episode Reward: 0.0\n",
      "Step 220 (314077) @ Episode 1274/10000, loss: 4.4711345253745094e-05\n",
      "Episode Reward: 1.0\n",
      "Step 273 (314350) @ Episode 1275/10000, loss: 0.00070280139334499847\n",
      "Episode Reward: 2.0\n",
      "Step 419 (314769) @ Episode 1276/10000, loss: 0.00034237993531860412\n",
      "Episode Reward: 5.0\n",
      "Step 356 (315125) @ Episode 1277/10000, loss: 0.00309927831403911177\n",
      "Episode Reward: 2.0\n",
      "Step 234 (315359) @ Episode 1278/10000, loss: 0.00279422244057059348\n",
      "Episode Reward: 1.0\n",
      "Step 251 (315610) @ Episode 1279/10000, loss: 0.00013472681166604163\n",
      "Episode Reward: 2.0\n",
      "Step 232 (315842) @ Episode 1280/10000, loss: 0.00013391424727160484\n",
      "Episode Reward: 1.0\n",
      "Step 169 (316011) @ Episode 1281/10000, loss: 0.01366023346781730775\n",
      "Episode Reward: 0.0\n",
      "Step 223 (316234) @ Episode 1282/10000, loss: 0.00061008974444121125\n",
      "Episode Reward: 1.0\n",
      "Step 317 (316551) @ Episode 1283/10000, loss: 0.00132020388264209033\n",
      "Episode Reward: 2.0\n",
      "Step 221 (316772) @ Episode 1284/10000, loss: 9.233538003172725e-055\n",
      "Episode Reward: 1.0\n",
      "Step 179 (316951) @ Episode 1285/10000, loss: 0.00029669591458514333\n",
      "Episode Reward: 0.0\n",
      "Step 348 (317299) @ Episode 1286/10000, loss: 8.287765376735479e-054\n",
      "Episode Reward: 3.0\n",
      "Step 220 (317519) @ Episode 1287/10000, loss: 0.00018456294492352754\n",
      "Episode Reward: 1.0\n",
      "Step 226 (317745) @ Episode 1288/10000, loss: 0.00048916885862126955\n",
      "Episode Reward: 1.0\n",
      "Step 349 (318094) @ Episode 1289/10000, loss: 0.00026654038811102514\n",
      "Episode Reward: 3.0\n",
      "Step 208 (318302) @ Episode 1290/10000, loss: 0.00083221407840028412\n",
      "Episode Reward: 1.0\n",
      "Step 190 (318492) @ Episode 1291/10000, loss: 0.00129537610337138188\n",
      "Episode Reward: 0.0\n",
      "Step 183 (318675) @ Episode 1292/10000, loss: 0.00021683910745196044\n",
      "Episode Reward: 0.0\n",
      "Step 252 (318927) @ Episode 1293/10000, loss: 0.00351384398527443477\n",
      "Episode Reward: 2.0\n",
      "Step 334 (319261) @ Episode 1294/10000, loss: 6.20890932623297e-0533\n",
      "Episode Reward: 3.0\n",
      "Step 255 (319516) @ Episode 1295/10000, loss: 0.00031649792799726136\n",
      "Episode Reward: 2.0\n",
      "Step 231 (319747) @ Episode 1296/10000, loss: 0.00040644838009029627\n",
      "Episode Reward: 1.0\n",
      "Step 172 (319919) @ Episode 1297/10000, loss: 0.00136532227043062452\n",
      "Episode Reward: 0.0\n",
      "Step 292 (320211) @ Episode 1298/10000, loss: 0.00068076257593929774\n",
      "Episode Reward: 2.0\n",
      "Step 225 (320436) @ Episode 1299/10000, loss: 0.00030915005481801927\n",
      "Episode Reward: 1.0\n",
      "Step 262 (320698) @ Episode 1300/10000, loss: 0.00041423918446525934\n",
      "Episode Reward: 2.0\n",
      "Step 281 (320979) @ Episode 1301/10000, loss: 0.00024419688270427287\n",
      "Episode Reward: 2.0\n",
      "Step 445 (321424) @ Episode 1302/10000, loss: 0.00221154326573014265\n",
      "Episode Reward: 4.0\n",
      "Step 222 (321646) @ Episode 1303/10000, loss: 0.00013928688713349402\n",
      "Episode Reward: 1.0\n",
      "Step 194 (321840) @ Episode 1304/10000, loss: 0.00226263352669775567\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 246 (322086) @ Episode 1305/10000, loss: 0.00220681750215594138\n",
      "Episode Reward: 1.0\n",
      "Step 334 (322420) @ Episode 1306/10000, loss: 0.00024243965162895626\n",
      "Episode Reward: 3.0\n",
      "Step 185 (322605) @ Episode 1307/10000, loss: 0.00062177865765988836\n",
      "Episode Reward: 0.0\n",
      "Step 379 (322984) @ Episode 1308/10000, loss: 0.00812666770070791228\n",
      "Episode Reward: 4.0\n",
      "Step 186 (323170) @ Episode 1309/10000, loss: 0.00058397330576553942\n",
      "Episode Reward: 0.0\n",
      "Step 240 (323410) @ Episode 1310/10000, loss: 0.00853012874722480889\n",
      "Episode Reward: 1.0\n",
      "Step 330 (323740) @ Episode 1311/10000, loss: 0.00045692158164456487\n",
      "Episode Reward: 3.0\n",
      "Step 324 (324064) @ Episode 1312/10000, loss: 0.00028844605549238627\n",
      "Episode Reward: 2.0\n",
      "Step 274 (324338) @ Episode 1313/10000, loss: 0.00146028352901339535\n",
      "Episode Reward: 2.0\n",
      "Step 266 (324604) @ Episode 1314/10000, loss: 0.00019676394003909086\n",
      "Episode Reward: 1.0\n",
      "Step 251 (324855) @ Episode 1315/10000, loss: 0.00080308149335905915\n",
      "Episode Reward: 1.0\n",
      "Step 428 (325283) @ Episode 1316/10000, loss: 0.00014081946574151516\n",
      "Episode Reward: 5.0\n",
      "Step 222 (325505) @ Episode 1317/10000, loss: 0.00024297120398841798\n",
      "Episode Reward: 0.0\n",
      "Step 253 (325758) @ Episode 1318/10000, loss: 7.21245669410564e-0515\n",
      "Episode Reward: 2.0\n",
      "Step 500 (326258) @ Episode 1319/10000, loss: 7.378899317700416e-055\n",
      "Episode Reward: 6.0\n",
      "Step 311 (326569) @ Episode 1320/10000, loss: 0.00025886809453368187\n",
      "Episode Reward: 2.0\n",
      "Step 331 (326900) @ Episode 1321/10000, loss: 0.00016033774591051042\n",
      "Episode Reward: 3.0\n",
      "Step 583 (327483) @ Episode 1322/10000, loss: 0.00049951492110267285\n",
      "Episode Reward: 8.0\n",
      "Step 321 (327804) @ Episode 1323/10000, loss: 0.00015363545389845967\n",
      "Episode Reward: 2.0\n",
      "Step 185 (327989) @ Episode 1324/10000, loss: 0.00031918988679535687\n",
      "Episode Reward: 0.0\n",
      "Step 356 (328345) @ Episode 1325/10000, loss: 0.00229247333481907846\n",
      "Episode Reward: 3.0\n",
      "Step 262 (328607) @ Episode 1326/10000, loss: 0.00085658527677878745\n",
      "Episode Reward: 2.0\n",
      "Step 361 (328968) @ Episode 1327/10000, loss: 0.00023155289818532765\n",
      "Episode Reward: 3.0\n",
      "Step 177 (329145) @ Episode 1328/10000, loss: 0.00154269998893141751\n",
      "Episode Reward: 0.0\n",
      "Step 315 (329460) @ Episode 1329/10000, loss: 0.00034343198058195415\n",
      "Episode Reward: 2.0\n",
      "Step 379 (329839) @ Episode 1330/10000, loss: 0.00134206062648445376\n",
      "Episode Reward: 3.0\n",
      "Step 435 (330274) @ Episode 1331/10000, loss: 0.00896506570279598264\n",
      "Episode Reward: 4.0\n",
      "Step 214 (330488) @ Episode 1332/10000, loss: 0.00161679950542747973\n",
      "Episode Reward: 1.0\n",
      "Step 288 (330776) @ Episode 1333/10000, loss: 0.00012937393330503255\n",
      "Episode Reward: 2.0\n",
      "Step 183 (330959) @ Episode 1334/10000, loss: 0.00337945297360420233\n",
      "Episode Reward: 0.0\n",
      "Step 242 (331201) @ Episode 1335/10000, loss: 0.00029949372401461005\n",
      "Episode Reward: 1.0\n",
      "Step 189 (331390) @ Episode 1336/10000, loss: 0.00045361212687566876\n",
      "Episode Reward: 0.0\n",
      "Step 392 (331782) @ Episode 1337/10000, loss: 0.00136349000968039043\n",
      "Episode Reward: 4.0\n",
      "Step 377 (332159) @ Episode 1338/10000, loss: 0.00231758598238229753\n",
      "Episode Reward: 4.0\n",
      "Step 256 (332415) @ Episode 1339/10000, loss: 0.00069743231870234013\n",
      "Episode Reward: 2.0\n",
      "Step 260 (332675) @ Episode 1340/10000, loss: 0.00053643382852897058\n",
      "Episode Reward: 2.0\n",
      "Step 240 (332915) @ Episode 1341/10000, loss: 0.00094981188885867695\n",
      "Episode Reward: 2.0\n",
      "Step 443 (333358) @ Episode 1342/10000, loss: 0.00049458374269306662\n",
      "Episode Reward: 5.0\n",
      "Step 402 (333760) @ Episode 1343/10000, loss: 0.00174741877708584074\n",
      "Episode Reward: 4.0\n",
      "Step 231 (333991) @ Episode 1344/10000, loss: 0.00133905047550797468\n",
      "Episode Reward: 1.0\n",
      "Step 331 (334322) @ Episode 1345/10000, loss: 0.00091448368038982157\n",
      "Episode Reward: 3.0\n",
      "Step 349 (334671) @ Episode 1346/10000, loss: 0.00098065414931625134\n",
      "Episode Reward: 4.0\n",
      "Step 209 (334880) @ Episode 1347/10000, loss: 0.00051916157826781275\n",
      "Episode Reward: 0.0\n",
      "Step 211 (335091) @ Episode 1348/10000, loss: 0.00038547307485714555\n",
      "Episode Reward: 1.0\n",
      "Step 328 (335419) @ Episode 1349/10000, loss: 0.00296703772619366651\n",
      "Episode Reward: 3.0\n",
      "Step 335 (335754) @ Episode 1350/10000, loss: 0.00173078221268951929\n",
      "Episode Reward: 3.0\n",
      "Step 395 (336149) @ Episode 1351/10000, loss: 0.00093844649381935653\n",
      "Episode Reward: 3.0\n",
      "Step 318 (336467) @ Episode 1352/10000, loss: 0.00189163244795054274\n",
      "Episode Reward: 3.0\n",
      "Step 301 (336768) @ Episode 1353/10000, loss: 0.00033057929249480367\n",
      "Episode Reward: 2.0\n",
      "Step 339 (337107) @ Episode 1354/10000, loss: 0.00234949309378862456\n",
      "Episode Reward: 3.0\n",
      "Step 335 (337442) @ Episode 1355/10000, loss: 0.00032506845309399078\n",
      "Episode Reward: 3.0\n",
      "Step 254 (337696) @ Episode 1356/10000, loss: 0.00081764231435954577\n",
      "Episode Reward: 1.0\n",
      "Step 241 (337937) @ Episode 1357/10000, loss: 0.00227962736971676356\n",
      "Episode Reward: 1.0\n",
      "Step 258 (338195) @ Episode 1358/10000, loss: 0.00052936724387109283\n",
      "Episode Reward: 1.0\n",
      "Step 292 (338487) @ Episode 1359/10000, loss: 0.00074829568620771173\n",
      "Episode Reward: 2.0\n",
      "Step 269 (338756) @ Episode 1360/10000, loss: 0.00024418003158643846\n",
      "Episode Reward: 2.0\n",
      "Step 493 (339249) @ Episode 1361/10000, loss: 0.00063144130399450664\n",
      "Episode Reward: 5.0\n",
      "Step 434 (339683) @ Episode 1362/10000, loss: 0.00162687862757593462\n",
      "Episode Reward: 4.0\n",
      "Step 324 (340007) @ Episode 1363/10000, loss: 0.00164825702086091045\n",
      "Episode Reward: 3.0\n",
      "Step 438 (340445) @ Episode 1364/10000, loss: 0.00257260049693286493\n",
      "Episode Reward: 5.0\n",
      "Step 225 (340670) @ Episode 1365/10000, loss: 0.00017161045980174094\n",
      "Episode Reward: 1.0\n",
      "Step 329 (340999) @ Episode 1366/10000, loss: 0.00165614078287035236\n",
      "Episode Reward: 2.0\n",
      "Step 329 (341328) @ Episode 1367/10000, loss: 0.00026745471404865384\n",
      "Episode Reward: 3.0\n",
      "Step 261 (341589) @ Episode 1368/10000, loss: 0.00178163719829171986\n",
      "Episode Reward: 1.0\n",
      "Step 243 (341832) @ Episode 1369/10000, loss: 0.00453221704810857873\n",
      "Episode Reward: 1.0\n",
      "Step 349 (342181) @ Episode 1370/10000, loss: 0.00156844430603086954\n",
      "Episode Reward: 3.0\n",
      "Step 408 (342589) @ Episode 1371/10000, loss: 0.00136454275343567135\n",
      "Episode Reward: 4.0\n",
      "Step 276 (342865) @ Episode 1372/10000, loss: 0.00056210253387689594\n",
      "Episode Reward: 2.0\n",
      "Step 257 (343122) @ Episode 1373/10000, loss: 0.00011740456102415919\n",
      "Episode Reward: 1.0\n",
      "Step 373 (343495) @ Episode 1374/10000, loss: 0.00103069026954472063\n",
      "Episode Reward: 4.0\n",
      "Step 420 (343915) @ Episode 1375/10000, loss: 0.00064390333136543637\n",
      "Episode Reward: 4.0\n",
      "Step 344 (344259) @ Episode 1376/10000, loss: 0.00035516766365617514\n",
      "Episode Reward: 3.0\n",
      "Step 380 (344639) @ Episode 1377/10000, loss: 0.00058156612794846357\n",
      "Episode Reward: 3.0\n",
      "Step 438 (345077) @ Episode 1378/10000, loss: 0.00222271028906106957\n",
      "Episode Reward: 8.0\n",
      "Step 296 (345373) @ Episode 1379/10000, loss: 0.00014757504686713224\n",
      "Episode Reward: 2.0\n",
      "Step 458 (345831) @ Episode 1380/10000, loss: 0.00122161966282874357\n",
      "Episode Reward: 4.0\n",
      "Step 413 (346244) @ Episode 1381/10000, loss: 0.00088756333570927386\n",
      "Episode Reward: 5.0\n",
      "Step 302 (346546) @ Episode 1382/10000, loss: 0.00050175201613456015\n",
      "Episode Reward: 2.0\n",
      "Step 474 (347020) @ Episode 1383/10000, loss: 0.00101579842157661916\n",
      "Episode Reward: 6.0\n",
      "Step 220 (347240) @ Episode 1384/10000, loss: 0.00010482352809049189\n",
      "Episode Reward: 0.0\n",
      "Step 366 (347606) @ Episode 1385/10000, loss: 8.947265450842679e-056\n",
      "Episode Reward: 3.0\n",
      "Step 487 (348093) @ Episode 1386/10000, loss: 0.00136220396962016823\n",
      "Episode Reward: 5.0\n",
      "Step 354 (348447) @ Episode 1387/10000, loss: 0.00037827310734428465\n",
      "Episode Reward: 3.0\n",
      "Step 572 (349019) @ Episode 1388/10000, loss: 0.00126709998585283763\n",
      "Episode Reward: 5.0\n",
      "Step 338 (349357) @ Episode 1389/10000, loss: 0.00036377692595124245\n",
      "Episode Reward: 2.0\n",
      "Step 383 (349740) @ Episode 1390/10000, loss: 0.00030652925488539046\n",
      "Episode Reward: 4.0\n",
      "Step 257 (349997) @ Episode 1391/10000, loss: 0.00438988069072365894\n",
      "Episode Reward: 2.0\n",
      "Step 194 (350191) @ Episode 1392/10000, loss: 0.00112429261207580574\n",
      "Episode Reward: 0.0\n",
      "Step 313 (350504) @ Episode 1393/10000, loss: 0.00053049752023071055\n",
      "Episode Reward: 2.0\n",
      "Step 318 (350822) @ Episode 1394/10000, loss: 0.00888965744525194296\n",
      "Episode Reward: 2.0\n",
      "Step 251 (351073) @ Episode 1395/10000, loss: 0.00044979588710702956\n",
      "Episode Reward: 2.0\n",
      "Step 260 (351333) @ Episode 1396/10000, loss: 0.00121465371921658524\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 247 (351580) @ Episode 1397/10000, loss: 0.00070993037661537536\n",
      "Episode Reward: 1.0\n",
      "Step 268 (351848) @ Episode 1398/10000, loss: 0.00062215246725827466\n",
      "Episode Reward: 2.0\n",
      "Step 220 (352068) @ Episode 1399/10000, loss: 0.00157511513680219654\n",
      "Episode Reward: 1.0\n",
      "Step 372 (352440) @ Episode 1400/10000, loss: 0.00054895348148420454\n",
      "Episode Reward: 3.0\n",
      "Step 268 (352708) @ Episode 1401/10000, loss: 0.00107964873313903855\n",
      "Episode Reward: 1.0\n",
      "Step 243 (352951) @ Episode 1402/10000, loss: 0.00216936809010803753\n",
      "Episode Reward: 0.0\n",
      "Step 285 (353236) @ Episode 1403/10000, loss: 0.00044655782403424386\n",
      "Episode Reward: 2.0\n",
      "Step 282 (353518) @ Episode 1404/10000, loss: 0.00083718157839030037\n",
      "Episode Reward: 1.0\n",
      "Step 309 (353827) @ Episode 1405/10000, loss: 0.00080464815255254518\n",
      "Episode Reward: 3.0\n",
      "Step 282 (354109) @ Episode 1406/10000, loss: 0.00154860434122383644\n",
      "Episode Reward: 1.0\n",
      "Step 259 (354368) @ Episode 1407/10000, loss: 0.00138324860017746697\n",
      "Episode Reward: 1.0\n",
      "Step 281 (354649) @ Episode 1408/10000, loss: 0.00067992624826729383\n",
      "Episode Reward: 2.0\n",
      "Step 479 (355128) @ Episode 1409/10000, loss: 0.00286366813816130164\n",
      "Episode Reward: 4.0\n",
      "Step 277 (355405) @ Episode 1410/10000, loss: 0.00051209935918450366\n",
      "Episode Reward: 2.0\n",
      "Step 256 (355661) @ Episode 1411/10000, loss: 0.00033816171344369656\n",
      "Episode Reward: 1.0\n",
      "Step 427 (356088) @ Episode 1412/10000, loss: 0.00113927212078124287\n",
      "Episode Reward: 5.0\n",
      "Step 221 (356309) @ Episode 1413/10000, loss: 0.00213660695590078838\n",
      "Episode Reward: 1.0\n",
      "Step 277 (356586) @ Episode 1414/10000, loss: 0.00057596608530730013\n",
      "Episode Reward: 1.0\n",
      "Step 499 (357085) @ Episode 1415/10000, loss: 0.00087379914475604894\n",
      "Episode Reward: 5.0\n",
      "Step 359 (357444) @ Episode 1416/10000, loss: 0.00126146455295383934\n",
      "Episode Reward: 3.0\n",
      "Step 218 (357662) @ Episode 1417/10000, loss: 0.00073249795241281394\n",
      "Episode Reward: 1.0\n",
      "Step 221 (357883) @ Episode 1418/10000, loss: 0.00039040320552885537\n",
      "Episode Reward: 0.0\n",
      "Step 195 (358078) @ Episode 1419/10000, loss: 0.00970153417438268754\n",
      "Episode Reward: 0.0\n",
      "Step 276 (358354) @ Episode 1420/10000, loss: 0.00181322160642594117\n",
      "Episode Reward: 1.0\n",
      "Step 281 (358635) @ Episode 1421/10000, loss: 0.00234189163893461234\n",
      "Episode Reward: 2.0\n",
      "Step 378 (359013) @ Episode 1422/10000, loss: 0.00063804897945374254\n",
      "Episode Reward: 4.0\n",
      "Step 237 (359250) @ Episode 1423/10000, loss: 0.00082267326069995767\n",
      "Episode Reward: 1.0\n",
      "Step 291 (359541) @ Episode 1424/10000, loss: 0.00309611205011606267\n",
      "Episode Reward: 1.0\n",
      "Step 274 (359815) @ Episode 1425/10000, loss: 0.00067370000761002332\n",
      "Episode Reward: 1.0\n",
      "Step 177 (359992) @ Episode 1426/10000, loss: 0.00045528495684266094\n",
      "Episode Reward: 0.0\n",
      "Step 194 (360186) @ Episode 1427/10000, loss: 0.00126511743292212493\n",
      "Episode Reward: 0.0\n",
      "Step 461 (360647) @ Episode 1428/10000, loss: 0.01562212500721216294\n",
      "Episode Reward: 5.0\n",
      "Step 280 (360927) @ Episode 1429/10000, loss: 0.00030829687602818013\n",
      "Episode Reward: 1.0\n",
      "Step 179 (361106) @ Episode 1430/10000, loss: 0.00066148384939879187\n",
      "Episode Reward: 0.0\n",
      "Step 345 (361451) @ Episode 1431/10000, loss: 0.00050288566853851085\n",
      "Episode Reward: 2.0\n",
      "Step 199 (361650) @ Episode 1432/10000, loss: 0.00106192636303603657\n",
      "Episode Reward: 0.0\n",
      "Step 248 (361898) @ Episode 1433/10000, loss: 0.00294118048623204237\n",
      "Episode Reward: 1.0\n",
      "Step 211 (362109) @ Episode 1434/10000, loss: 0.00858027208596468426\n",
      "Episode Reward: 1.0\n",
      "Step 177 (362286) @ Episode 1435/10000, loss: 0.00134462781716138124\n",
      "Episode Reward: 0.0\n",
      "Step 352 (362638) @ Episode 1436/10000, loss: 0.00110981741454452287\n",
      "Episode Reward: 3.0\n",
      "Step 236 (362874) @ Episode 1437/10000, loss: 0.00046233611647039651\n",
      "Episode Reward: 0.0\n",
      "Step 279 (363153) @ Episode 1438/10000, loss: 0.00037581697688438534\n",
      "Episode Reward: 2.0\n",
      "Step 178 (363331) @ Episode 1439/10000, loss: 0.0012299750233069062\n",
      "Episode Reward: 0.0\n",
      "Step 327 (363658) @ Episode 1440/10000, loss: 0.00280768424272537236\n",
      "Episode Reward: 3.0\n",
      "Step 245 (363903) @ Episode 1441/10000, loss: 0.00611708220094442445\n",
      "Episode Reward: 1.0\n",
      "Step 219 (364122) @ Episode 1442/10000, loss: 0.00099565298296511176\n",
      "Episode Reward: 0.0\n",
      "Step 228 (364350) @ Episode 1443/10000, loss: 0.00239474396221339714\n",
      "Episode Reward: 0.0\n",
      "Step 320 (364670) @ Episode 1444/10000, loss: 0.01181269623339176247\n",
      "Episode Reward: 3.0\n",
      "Step 460 (365130) @ Episode 1445/10000, loss: 0.00050951482262462387\n",
      "Episode Reward: 5.0\n",
      "Step 255 (365385) @ Episode 1446/10000, loss: 0.00150968576781451745\n",
      "Episode Reward: 2.0\n",
      "Step 185 (365570) @ Episode 1447/10000, loss: 0.00068103644298389555\n",
      "Episode Reward: 0.0\n",
      "Step 402 (365972) @ Episode 1448/10000, loss: 0.00244204071350395716\n",
      "Episode Reward: 4.0\n",
      "Step 271 (366243) @ Episode 1449/10000, loss: 0.00084823020733892923\n",
      "Episode Reward: 1.0\n",
      "Step 333 (366576) @ Episode 1450/10000, loss: 0.00379286007955670367\n",
      "Episode Reward: 1.0\n",
      "Step 299 (366875) @ Episode 1451/10000, loss: 0.00034675834467634566\n",
      "Episode Reward: 2.0\n",
      "Step 214 (367089) @ Episode 1452/10000, loss: 0.00091795739717781546\n",
      "Episode Reward: 1.0\n",
      "Step 410 (367499) @ Episode 1453/10000, loss: 0.00285307364538311966\n",
      "Episode Reward: 4.0\n",
      "Step 202 (367701) @ Episode 1454/10000, loss: 0.00479073030874133177\n",
      "Episode Reward: 1.0\n",
      "Step 211 (367912) @ Episode 1455/10000, loss: 0.00135454838164150713\n",
      "Episode Reward: 1.0\n",
      "Step 237 (368149) @ Episode 1456/10000, loss: 0.00239897542633116256\n",
      "Episode Reward: 1.0\n",
      "Step 221 (368370) @ Episode 1457/10000, loss: 0.00104384112637490036\n",
      "Episode Reward: 1.0\n",
      "Step 299 (368669) @ Episode 1458/10000, loss: 0.00205693743191659457\n",
      "Episode Reward: 1.0\n",
      "Step 262 (368931) @ Episode 1459/10000, loss: 0.00082838372327387334\n",
      "Episode Reward: 2.0\n",
      "Step 264 (369195) @ Episode 1460/10000, loss: 0.00056570593733340565\n",
      "Episode Reward: 2.0\n",
      "Step 246 (369441) @ Episode 1461/10000, loss: 0.00192365283146500595\n",
      "Episode Reward: 2.0\n",
      "Step 341 (369782) @ Episode 1462/10000, loss: 0.00340503337793052237\n",
      "Episode Reward: 3.0\n",
      "Step 329 (370111) @ Episode 1463/10000, loss: 0.00121215311810374266\n",
      "Episode Reward: 3.0\n",
      "Step 331 (370442) @ Episode 1464/10000, loss: 0.00290522817522287375\n",
      "Episode Reward: 2.0\n",
      "Step 266 (370708) @ Episode 1465/10000, loss: 0.00256090401671826846\n",
      "Episode Reward: 2.0\n",
      "Step 308 (371016) @ Episode 1466/10000, loss: 0.00181322067510336643\n",
      "Episode Reward: 3.0\n",
      "Step 447 (371463) @ Episode 1467/10000, loss: 0.00612477352842688634\n",
      "Episode Reward: 5.0\n",
      "Step 265 (371728) @ Episode 1468/10000, loss: 0.00611867103725671886\n",
      "Episode Reward: 1.0\n",
      "Step 219 (371947) @ Episode 1469/10000, loss: 0.00536619732156395954\n",
      "Episode Reward: 1.0\n",
      "Step 258 (372205) @ Episode 1470/10000, loss: 0.00615547457709908573\n",
      "Episode Reward: 2.0\n",
      "Step 484 (372689) @ Episode 1471/10000, loss: 0.00185210269410163164\n",
      "Episode Reward: 7.0\n",
      "Step 407 (373096) @ Episode 1472/10000, loss: 0.00550386635586619465\n",
      "Episode Reward: 4.0\n",
      "Step 254 (373350) @ Episode 1473/10000, loss: 0.00251880893483757973\n",
      "Episode Reward: 2.0\n",
      "Step 353 (373703) @ Episode 1474/10000, loss: 0.00169938011094927797\n",
      "Episode Reward: 3.0\n",
      "Step 272 (373975) @ Episode 1475/10000, loss: 0.00353748467750847347\n",
      "Episode Reward: 2.0\n",
      "Step 232 (374207) @ Episode 1476/10000, loss: 0.00123044732026755864\n",
      "Episode Reward: 1.0\n",
      "Step 232 (374439) @ Episode 1477/10000, loss: 0.00072103185812011365\n",
      "Episode Reward: 1.0\n",
      "Step 227 (374666) @ Episode 1478/10000, loss: 0.00145731051452457977\n",
      "Episode Reward: 1.0\n",
      "Step 215 (374881) @ Episode 1479/10000, loss: 0.00455981865525245745\n",
      "Episode Reward: 1.0\n",
      "Step 306 (375187) @ Episode 1480/10000, loss: 0.00391826871782541316\n",
      "Episode Reward: 2.0\n",
      "Step 303 (375490) @ Episode 1481/10000, loss: 0.00205888552591204644\n",
      "Episode Reward: 2.0\n",
      "Step 305 (375795) @ Episode 1482/10000, loss: 0.00661814026534557327\n",
      "Episode Reward: 2.0\n",
      "Step 243 (376038) @ Episode 1483/10000, loss: 0.00046067283255979423\n",
      "Episode Reward: 1.0\n",
      "Step 252 (376290) @ Episode 1484/10000, loss: 0.00303727039135992533\n",
      "Episode Reward: 1.0\n",
      "Step 302 (376592) @ Episode 1485/10000, loss: 0.00190754595678299674\n",
      "Episode Reward: 2.0\n",
      "Step 384 (376976) @ Episode 1486/10000, loss: 0.00056541041703894732\n",
      "Episode Reward: 4.0\n",
      "Step 486 (377462) @ Episode 1487/10000, loss: 0.00026617167168296874\n",
      "Episode Reward: 5.0\n",
      "Step 205 (377667) @ Episode 1488/10000, loss: 0.00810892879962921134\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 253 (377920) @ Episode 1489/10000, loss: 0.00129112112335860734\n",
      "Episode Reward: 2.0\n",
      "Step 378 (378298) @ Episode 1490/10000, loss: 0.00043189863208681345\n",
      "Episode Reward: 3.0\n",
      "Step 294 (378592) @ Episode 1491/10000, loss: 0.00326689891517162323\n",
      "Episode Reward: 2.0\n",
      "Step 266 (378858) @ Episode 1492/10000, loss: 0.00842995755374431666\n",
      "Episode Reward: 1.0\n",
      "Step 310 (379168) @ Episode 1493/10000, loss: 0.00114357681013643746\n",
      "Episode Reward: 2.0\n",
      "Step 221 (379389) @ Episode 1494/10000, loss: 0.00110341014806181213\n",
      "Episode Reward: 1.0\n",
      "Step 278 (379667) @ Episode 1495/10000, loss: 0.00041237717960029843\n",
      "Episode Reward: 1.0\n",
      "Step 223 (379890) @ Episode 1496/10000, loss: 0.00139145459979772574\n",
      "Episode Reward: 1.0\n",
      "Step 439 (380329) @ Episode 1497/10000, loss: 0.00129516911692917356\n",
      "Episode Reward: 4.0\n",
      "Step 326 (380655) @ Episode 1498/10000, loss: 0.00816211197525262856\n",
      "Episode Reward: 3.0\n",
      "Step 176 (380831) @ Episode 1499/10000, loss: 0.0016005041543394327\n",
      "Episode Reward: 0.0\n",
      "Step 355 (381186) @ Episode 1500/10000, loss: 0.00287653412669897185\n",
      "Episode Reward: 3.0\n",
      "Step 414 (381600) @ Episode 1501/10000, loss: 0.00113396695815026767\n",
      "Episode Reward: 4.0\n",
      "Step 382 (381982) @ Episode 1502/10000, loss: 0.00962796993553638536\n",
      "Episode Reward: 3.0\n",
      "Step 301 (382283) @ Episode 1503/10000, loss: 0.00148046715185046244\n",
      "Episode Reward: 2.0\n",
      "Step 311 (382594) @ Episode 1504/10000, loss: 0.00161473779007792477\n",
      "Episode Reward: 2.0\n",
      "Step 239 (382833) @ Episode 1505/10000, loss: 0.00190476072020828724\n",
      "Episode Reward: 1.0\n",
      "Step 371 (383204) @ Episode 1506/10000, loss: 0.00927575957030057934\n",
      "Episode Reward: 4.0\n",
      "Step 296 (383500) @ Episode 1507/10000, loss: 0.00268213218078017234\n",
      "Episode Reward: 2.0\n",
      "Step 228 (383728) @ Episode 1508/10000, loss: 0.00067490286892279984\n",
      "Episode Reward: 0.0\n",
      "Step 427 (384155) @ Episode 1509/10000, loss: 0.00439705932512879425\n",
      "Episode Reward: 4.0\n",
      "Step 257 (384412) @ Episode 1510/10000, loss: 0.00668143155053257976\n",
      "Episode Reward: 2.0\n",
      "Step 303 (384715) @ Episode 1511/10000, loss: 0.00120146386325359343\n",
      "Episode Reward: 3.0\n",
      "Step 424 (385139) @ Episode 1512/10000, loss: 0.00299211498349905376\n",
      "Episode Reward: 5.0\n",
      "Step 525 (385664) @ Episode 1513/10000, loss: 0.00533487414941191746\n",
      "Episode Reward: 7.0\n",
      "Step 455 (386119) @ Episode 1514/10000, loss: 0.00548318726941943282\n",
      "Episode Reward: 4.0\n",
      "Step 424 (386543) @ Episode 1515/10000, loss: 0.00140070565976202495\n",
      "Episode Reward: 4.0\n",
      "Step 588 (387131) @ Episode 1516/10000, loss: 0.00406121555715799343\n",
      "Episode Reward: 7.0\n",
      "Step 725 (387856) @ Episode 1517/10000, loss: 0.00066957517992705114\n",
      "Episode Reward: 8.0\n",
      "Step 426 (388282) @ Episode 1518/10000, loss: 0.00143506890162825584\n",
      "Episode Reward: 5.0\n",
      "Step 281 (388563) @ Episode 1519/10000, loss: 0.00067048845812678345\n",
      "Episode Reward: 1.0\n",
      "Step 260 (388823) @ Episode 1520/10000, loss: 0.00061382399871945385\n",
      "Episode Reward: 2.0\n",
      "Step 342 (389165) @ Episode 1521/10000, loss: 0.00026795937446877365\n",
      "Episode Reward: 4.0\n",
      "Step 457 (389622) @ Episode 1522/10000, loss: 0.00075152574572712186\n",
      "Episode Reward: 5.0\n",
      "Step 407 (390029) @ Episode 1523/10000, loss: 0.00342137273401021963\n",
      "Episode Reward: 4.0\n",
      "Step 437 (390466) @ Episode 1524/10000, loss: 0.00673263799399137586\n",
      "Episode Reward: 4.0\n",
      "Step 589 (391055) @ Episode 1525/10000, loss: 0.00293621886521577847\n",
      "Episode Reward: 7.0\n",
      "Step 399 (391454) @ Episode 1526/10000, loss: 0.00163895136211067447\n",
      "Episode Reward: 5.0\n",
      "Step 493 (391947) @ Episode 1527/10000, loss: 0.00147385662421584135\n",
      "Episode Reward: 5.0\n",
      "Step 450 (392397) @ Episode 1528/10000, loss: 0.00602196156978607267\n",
      "Episode Reward: 5.0\n",
      "Step 414 (392811) @ Episode 1529/10000, loss: 0.00075382628710940485\n",
      "Episode Reward: 5.0\n",
      "Step 394 (393205) @ Episode 1530/10000, loss: 0.00229698815383017067\n",
      "Episode Reward: 3.0\n",
      "Step 337 (393542) @ Episode 1531/10000, loss: 0.00546838529407978126\n",
      "Episode Reward: 3.0\n",
      "Step 413 (393955) @ Episode 1532/10000, loss: 0.00064023217419162396\n",
      "Episode Reward: 4.0\n",
      "Step 338 (394293) @ Episode 1533/10000, loss: 0.00480209989473223797\n",
      "Episode Reward: 3.0\n",
      "Step 766 (395059) @ Episode 1534/10000, loss: 0.00186782644595950847\n",
      "Episode Reward: 10.0\n",
      "Step 515 (395574) @ Episode 1535/10000, loss: 0.00064848019974306235\n",
      "Episode Reward: 7.0\n",
      "Step 677 (396251) @ Episode 1536/10000, loss: 0.00467409240081906363\n",
      "Episode Reward: 13.0\n",
      "Step 368 (396619) @ Episode 1537/10000, loss: 0.00150160118937492374\n",
      "Episode Reward: 4.0\n",
      "Step 587 (397206) @ Episode 1538/10000, loss: 0.00580948404967784936\n",
      "Episode Reward: 9.0\n",
      "Step 485 (397691) @ Episode 1539/10000, loss: 0.00119781517423689376\n",
      "Episode Reward: 5.0\n",
      "Step 259 (397950) @ Episode 1540/10000, loss: 0.00384462112560868264\n",
      "Episode Reward: 1.0\n",
      "Step 535 (398485) @ Episode 1541/10000, loss: 0.00272953743115067593\n",
      "Episode Reward: 6.0\n",
      "Step 370 (398855) @ Episode 1542/10000, loss: 0.00423690490424633357\n",
      "Episode Reward: 4.0\n",
      "Step 393 (399248) @ Episode 1543/10000, loss: 0.00120324175804853446\n",
      "Episode Reward: 4.0\n",
      "Step 477 (399725) @ Episode 1544/10000, loss: 0.00038194231456145644\n",
      "Episode Reward: 6.0\n",
      "Step 323 (400048) @ Episode 1545/10000, loss: 0.00074463768396526584\n",
      "Episode Reward: 3.0\n",
      "Step 592 (400640) @ Episode 1546/10000, loss: 0.00472583342343568863\n",
      "Episode Reward: 8.0\n",
      "Step 290 (400930) @ Episode 1547/10000, loss: 0.00183353666216135036\n",
      "Episode Reward: 2.0\n",
      "Step 403 (401333) @ Episode 1548/10000, loss: 0.00171304831746965656\n",
      "Episode Reward: 4.0\n",
      "Step 275 (401608) @ Episode 1549/10000, loss: 0.00053757044952362787\n",
      "Episode Reward: 2.0\n",
      "Step 320 (401928) @ Episode 1550/10000, loss: 0.00188482133671641357\n",
      "Episode Reward: 3.0\n",
      "Step 313 (402241) @ Episode 1551/10000, loss: 0.00130010955035686576\n",
      "Episode Reward: 3.0\n",
      "Step 563 (402804) @ Episode 1552/10000, loss: 0.00071404501795768746\n",
      "Episode Reward: 7.0\n",
      "Step 503 (403307) @ Episode 1553/10000, loss: 0.00065151334274560214\n",
      "Episode Reward: 6.0\n",
      "Step 502 (403809) @ Episode 1554/10000, loss: 0.00250375829637050635\n",
      "Episode Reward: 6.0\n",
      "Step 739 (404548) @ Episode 1555/10000, loss: 0.00087725277990102775\n",
      "Episode Reward: 9.0\n",
      "Step 708 (405256) @ Episode 1556/10000, loss: 0.00145087740384042264\n",
      "Episode Reward: 10.0\n",
      "Step 636 (405892) @ Episode 1557/10000, loss: 0.00255085248500108755\n",
      "Episode Reward: 8.0\n",
      "Step 529 (406421) @ Episode 1558/10000, loss: 0.00259301951155066516\n",
      "Episode Reward: 6.0\n",
      "Step 410 (406831) @ Episode 1559/10000, loss: 0.00046976818703114986\n",
      "Episode Reward: 5.0\n",
      "Step 510 (407341) @ Episode 1560/10000, loss: 0.00349726481363177334\n",
      "Episode Reward: 5.0\n",
      "Step 459 (407800) @ Episode 1561/10000, loss: 0.00345774483866989665\n",
      "Episode Reward: 5.0\n",
      "Step 382 (408182) @ Episode 1562/10000, loss: 0.00176004040986299517\n",
      "Episode Reward: 3.0\n",
      "Step 455 (408637) @ Episode 1563/10000, loss: 0.00220391293987631873\n",
      "Episode Reward: 5.0\n",
      "Step 522 (409159) @ Episode 1564/10000, loss: 0.00218739104457199573\n",
      "Episode Reward: 5.0\n",
      "Step 709 (409868) @ Episode 1565/10000, loss: 0.00067265494726598266\n",
      "Episode Reward: 9.0\n",
      "Step 434 (410302) @ Episode 1566/10000, loss: 0.00774816330522298854\n",
      "Episode Reward: 5.0\n",
      "Step 564 (410866) @ Episode 1567/10000, loss: 0.00379419652745127686\n",
      "Episode Reward: 7.0\n",
      "Step 738 (411604) @ Episode 1568/10000, loss: 0.00180110032670199877\n",
      "Episode Reward: 11.0\n",
      "Step 661 (412265) @ Episode 1569/10000, loss: 0.00651584565639495853\n",
      "Episode Reward: 9.0\n",
      "Step 556 (412821) @ Episode 1570/10000, loss: 0.00476085999980568964\n",
      "Episode Reward: 7.0\n",
      "Step 686 (413507) @ Episode 1571/10000, loss: 0.00136748794466257173\n",
      "Episode Reward: 8.0\n",
      "Step 519 (414026) @ Episode 1572/10000, loss: 0.00297208200208842755\n",
      "Episode Reward: 5.0\n",
      "Step 668 (414694) @ Episode 1573/10000, loss: 0.00073167949449270964\n",
      "Episode Reward: 10.0\n",
      "Step 1061 (415755) @ Episode 1574/10000, loss: 0.0012723997933790088\n",
      "Episode Reward: 19.0\n",
      "Step 648 (416403) @ Episode 1575/10000, loss: 0.00336481165140867236\n",
      "Episode Reward: 8.0\n",
      "Step 624 (417027) @ Episode 1576/10000, loss: 0.00825208239257335754\n",
      "Episode Reward: 8.0\n",
      "Step 571 (417598) @ Episode 1577/10000, loss: 0.00714060757309198476\n",
      "Episode Reward: 7.0\n",
      "Step 599 (418197) @ Episode 1578/10000, loss: 0.00056084961397573354\n",
      "Episode Reward: 8.0\n",
      "Step 611 (418808) @ Episode 1579/10000, loss: 0.00435176724568009484\n",
      "Episode Reward: 8.0\n",
      "Step 483 (419291) @ Episode 1580/10000, loss: 0.00212917639873921876\n",
      "Episode Reward: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 637 (419928) @ Episode 1581/10000, loss: 0.00139140104874968536\n",
      "Episode Reward: 9.0\n",
      "Step 513 (420441) @ Episode 1582/10000, loss: 0.00086243881378322844\n",
      "Episode Reward: 6.0\n",
      "Step 721 (421162) @ Episode 1583/10000, loss: 0.00148081535007804636\n",
      "Episode Reward: 14.0\n",
      "Step 482 (421644) @ Episode 1584/10000, loss: 0.00189465528819710023\n",
      "Episode Reward: 6.0\n",
      "Step 544 (422188) @ Episode 1585/10000, loss: 0.00077609840082004674\n",
      "Episode Reward: 7.0\n",
      "Step 433 (422621) @ Episode 1586/10000, loss: 0.00347640179097652446\n",
      "Episode Reward: 4.0\n",
      "Step 588 (423209) @ Episode 1587/10000, loss: 0.00215789093635976385\n",
      "Episode Reward: 7.0\n",
      "Step 719 (423928) @ Episode 1588/10000, loss: 0.00121061294339597233\n",
      "Episode Reward: 11.0\n",
      "Step 607 (424535) @ Episode 1589/10000, loss: 0.00264433771371841436\n",
      "Episode Reward: 8.0\n",
      "Step 639 (425174) @ Episode 1590/10000, loss: 0.00075349991675466354\n",
      "Episode Reward: 9.0\n",
      "Step 711 (425885) @ Episode 1591/10000, loss: 0.01235209871083498244\n",
      "Episode Reward: 9.0\n",
      "Step 785 (426670) @ Episode 1592/10000, loss: 0.00106204929761588574\n",
      "Episode Reward: 11.0\n",
      "Step 538 (427208) @ Episode 1593/10000, loss: 0.00300691835582256386\n",
      "Episode Reward: 7.0\n",
      "Step 557 (427765) @ Episode 1594/10000, loss: 0.00076822232222184547\n",
      "Episode Reward: 7.0\n",
      "Step 510 (428275) @ Episode 1595/10000, loss: 0.00435061240568757164\n",
      "Episode Reward: 6.0\n",
      "Step 575 (428850) @ Episode 1596/10000, loss: 0.00143944588489830525\n",
      "Episode Reward: 6.0\n",
      "Step 726 (429576) @ Episode 1597/10000, loss: 0.00245535280555486736\n",
      "Episode Reward: 11.0\n",
      "Step 749 (430325) @ Episode 1598/10000, loss: 0.00115587073378264978\n",
      "Episode Reward: 11.0\n",
      "Step 644 (430969) @ Episode 1599/10000, loss: 0.00332275428809225564\n",
      "Episode Reward: 9.0\n",
      "Step 711 (431680) @ Episode 1600/10000, loss: 0.00146699300967156896\n",
      "Episode Reward: 10.0\n",
      "Step 479 (432159) @ Episode 1601/10000, loss: 0.00286907562986016276\n",
      "Episode Reward: 9.0\n",
      "Step 749 (432908) @ Episode 1602/10000, loss: 0.00529650785028934535\n",
      "Episode Reward: 11.0\n",
      "Step 728 (433636) @ Episode 1603/10000, loss: 0.00344067602418363137\n",
      "Episode Reward: 13.0\n",
      "Step 597 (434233) @ Episode 1604/10000, loss: 0.00222727679647505366\n",
      "Episode Reward: 7.0\n",
      "Step 638 (434871) @ Episode 1605/10000, loss: 0.00129927857778966435\n",
      "Episode Reward: 8.0\n",
      "Step 825 (435696) @ Episode 1606/10000, loss: 0.00216363044455647473\n",
      "Episode Reward: 12.0\n",
      "Step 786 (436482) @ Episode 1607/10000, loss: 0.00172702025156468156\n",
      "Episode Reward: 12.0\n",
      "Step 1047 (437529) @ Episode 1608/10000, loss: 0.0020233122631907463\n",
      "Episode Reward: 21.0\n",
      "Step 758 (438287) @ Episode 1609/10000, loss: 0.00253555434755980975\n",
      "Episode Reward: 9.0\n",
      "Step 873 (439160) @ Episode 1610/10000, loss: 0.00073788664303726984\n",
      "Episode Reward: 15.0\n",
      "Step 805 (439965) @ Episode 1611/10000, loss: 0.00220966595225036145\n",
      "Episode Reward: 14.0\n",
      "Step 979 (440944) @ Episode 1612/10000, loss: 0.00473393592983484354\n",
      "Episode Reward: 15.0\n",
      "Step 946 (441890) @ Episode 1613/10000, loss: 0.00096202205168083316\n",
      "Episode Reward: 16.0\n",
      "Step 943 (442833) @ Episode 1614/10000, loss: 0.00121179665438830854\n",
      "Episode Reward: 15.0\n",
      "Step 943 (443776) @ Episode 1615/10000, loss: 0.00043996918248012665\n",
      "Episode Reward: 12.0\n",
      "Step 757 (444533) @ Episode 1616/10000, loss: 0.00084521132521331315\n",
      "Episode Reward: 14.0\n",
      "Step 1023 (445556) @ Episode 1617/10000, loss: 0.0035457506310194734\n",
      "Episode Reward: 17.0\n",
      "Step 806 (446362) @ Episode 1618/10000, loss: 0.00160242873243987564\n",
      "Episode Reward: 13.0\n",
      "Step 740 (447102) @ Episode 1619/10000, loss: 0.00106584094464778924\n",
      "Episode Reward: 11.0\n",
      "Step 739 (447841) @ Episode 1620/10000, loss: 0.00296524632722139366\n",
      "Episode Reward: 11.0\n",
      "Step 658 (448499) @ Episode 1621/10000, loss: 0.00932072196155786515\n",
      "Episode Reward: 8.0\n",
      "Step 930 (449429) @ Episode 1622/10000, loss: 0.00138062296900898226\n",
      "Episode Reward: 15.0\n",
      "Step 850 (450279) @ Episode 1623/10000, loss: 0.00205956771969795234\n",
      "Episode Reward: 21.0\n",
      "Step 1050 (451329) @ Episode 1624/10000, loss: 0.0050276848487555986\n",
      "Episode Reward: 23.0\n",
      "Step 908 (452237) @ Episode 1625/10000, loss: 0.00166306877508759535\n",
      "Episode Reward: 14.0\n",
      "Step 803 (453040) @ Episode 1626/10000, loss: 0.01896304450929165265\n",
      "Episode Reward: 12.0\n",
      "Step 828 (453868) @ Episode 1627/10000, loss: 0.00105811073444783697\n",
      "Episode Reward: 11.0\n",
      "Step 818 (454686) @ Episode 1628/10000, loss: 0.01127401273697614747\n",
      "Episode Reward: 14.0\n",
      "Step 960 (455646) @ Episode 1629/10000, loss: 0.00126522080972790727\n",
      "Episode Reward: 18.0\n",
      "Step 846 (456492) @ Episode 1630/10000, loss: 0.00188787491060793485\n",
      "Episode Reward: 19.0\n",
      "Step 654 (457146) @ Episode 1631/10000, loss: 0.00220393529161810873\n",
      "Episode Reward: 9.0\n",
      "Step 1158 (458304) @ Episode 1632/10000, loss: 0.0029396205209195614\n",
      "Episode Reward: 31.0\n",
      "Step 610 (458914) @ Episode 1633/10000, loss: 0.00100959115661680767\n",
      "Episode Reward: 9.0\n",
      "Step 1225 (460139) @ Episode 1634/10000, loss: 0.00356600782833993433\n",
      "Episode Reward: 42.0\n",
      "Step 552 (460691) @ Episode 1635/10000, loss: 0.0017540296539664268\n",
      "Episode Reward: 8.0\n",
      "Step 679 (461370) @ Episode 1636/10000, loss: 0.00201317667961120627\n",
      "Episode Reward: 17.0\n",
      "Step 1041 (462411) @ Episode 1637/10000, loss: 0.0034705328289419413\n",
      "Episode Reward: 16.0\n",
      "Step 872 (463283) @ Episode 1638/10000, loss: 0.00096460082568228247\n",
      "Episode Reward: 12.0\n",
      "Step 961 (464244) @ Episode 1639/10000, loss: 0.00384929310530424173\n",
      "Episode Reward: 13.0\n",
      "Step 857 (465101) @ Episode 1640/10000, loss: 0.00308462139219045643\n",
      "Episode Reward: 12.0\n",
      "Step 1376 (466477) @ Episode 1641/10000, loss: 0.00248998962342739166\n",
      "Episode Reward: 28.0\n",
      "Step 747 (467224) @ Episode 1642/10000, loss: 0.00105479138437658553\n",
      "Episode Reward: 12.0\n",
      "Step 695 (467919) @ Episode 1643/10000, loss: 0.00147227733395993755\n",
      "Episode Reward: 11.0\n",
      "Step 910 (468829) @ Episode 1644/10000, loss: 0.00573085714131593783\n",
      "Episode Reward: 13.0\n",
      "Step 873 (469702) @ Episode 1645/10000, loss: 0.00146190007217228414\n",
      "Episode Reward: 17.0\n",
      "Step 1124 (470826) @ Episode 1646/10000, loss: 0.00373701751232147225\n",
      "Episode Reward: 24.0\n",
      "Step 1071 (471897) @ Episode 1647/10000, loss: 0.0015683993697166443\n",
      "Episode Reward: 19.0\n",
      "Step 570 (472467) @ Episode 1648/10000, loss: 0.00083491898840293295\n",
      "Episode Reward: 8.0\n",
      "Step 920 (473387) @ Episode 1649/10000, loss: 0.00207852502353489473\n",
      "Episode Reward: 16.0\n",
      "Step 1052 (474439) @ Episode 1650/10000, loss: 0.00165019382257014514\n",
      "Episode Reward: 21.0\n",
      "Step 761 (475200) @ Episode 1651/10000, loss: 0.00925990100950002736\n",
      "Episode Reward: 15.0\n",
      "Step 1327 (476527) @ Episode 1652/10000, loss: 0.00395660102367401167\n",
      "Episode Reward: 21.0\n",
      "Step 971 (477498) @ Episode 1653/10000, loss: 0.00260663544759154347\n",
      "Episode Reward: 17.0\n",
      "Step 1320 (478818) @ Episode 1654/10000, loss: 0.00487827602773904854\n",
      "Episode Reward: 22.0\n",
      "Step 1073 (479891) @ Episode 1655/10000, loss: 0.0013181552058085862\n",
      "Episode Reward: 20.0\n",
      "Step 979 (480870) @ Episode 1656/10000, loss: 0.00370943965390324654\n",
      "Episode Reward: 17.0\n",
      "Step 960 (481830) @ Episode 1657/10000, loss: 0.00809673126786947364\n",
      "Episode Reward: 16.0\n",
      "Step 599 (482429) @ Episode 1658/10000, loss: 0.00372270983643829823\n",
      "Episode Reward: 10.0\n",
      "Step 1001 (483430) @ Episode 1659/10000, loss: 0.0014996712561696768\n",
      "Episode Reward: 19.0\n",
      "Step 1405 (484835) @ Episode 1660/10000, loss: 0.00304606673307716855\n",
      "Episode Reward: 31.0\n",
      "Step 1026 (485861) @ Episode 1661/10000, loss: 0.0020815609022974972\n",
      "Episode Reward: 16.0\n",
      "Step 1080 (486941) @ Episode 1662/10000, loss: 0.0038377759046852591\n",
      "Episode Reward: 28.0\n",
      "Step 805 (487746) @ Episode 1663/10000, loss: 0.00278029916808009154\n",
      "Episode Reward: 12.0\n",
      "Step 985 (488731) @ Episode 1664/10000, loss: 0.00387187488377094276\n",
      "Episode Reward: 25.0\n",
      "Step 973 (489704) @ Episode 1665/10000, loss: 0.00446540955454111125\n",
      "Episode Reward: 18.0\n",
      "Step 743 (490447) @ Episode 1666/10000, loss: 0.00124983559362590313"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Where we save our checkpoints and graphs\n",
    "experiment_dir = os.path.abspath(\"./experiments/{}\".format(env.spec.id))\n",
    "\n",
    "# Create a glboal step variable\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    \n",
    "# Create estimators\n",
    "q_estimator = Estimator(scope=\"q\", summaries_dir=experiment_dir)\n",
    "target_estimator = Estimator(scope=\"target_q\")\n",
    "\n",
    "# State processor\n",
    "state_processor = StateProcessor()\n",
    "\n",
    "# Run it!\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for t, stats in deep_q_learning(sess,\n",
    "                                    env,\n",
    "                                    q_estimator=q_estimator,\n",
    "                                    target_estimator=target_estimator,\n",
    "                                    state_processor=state_processor,\n",
    "                                    experiment_dir=experiment_dir,\n",
    "                                    num_episodes=10000,\n",
    "                                    replay_memory_size=500000,\n",
    "                                    replay_memory_init_size=50000,\n",
    "                                    update_target_estimator_every=10000,\n",
    "                                    epsilon_start=1.0,\n",
    "                                    epsilon_end=0.1,\n",
    "                                    epsilon_decay_steps=500000,\n",
    "                                    discount_factor=0.99,\n",
    "                                    batch_size=32):\n",
    "\n",
    "        print(\"\\nEpisode Reward: {}\".format(stats.episode_rewards[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
